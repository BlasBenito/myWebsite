<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rstats | Blas M. Benito, PhD</title>
    <link>https://blasbenito.com/tag/rstats/</link>
      <atom:link href="https://blasbenito.com/tag/rstats/index.xml" rel="self" type="application/rss+xml" />
    <description>Rstats</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2023 Blas M. Benito. All Rights Reserved.</copyright><lastBuildDate>Mon, 13 Jan 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://blasbenito.com/media/avatar.jpg</url>
      <title>Rstats</title>
      <link>https://blasbenito.com/tag/rstats/</link>
    </image>
    
    <item>
      <title>Coding a Minimalistic Dynamic Time Warping Library with R</title>
      <link>https://blasbenito.com/post/dynamic-time-warping-from-scratch/</link>
      <pubDate>Mon, 13 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://blasbenito.com/post/dynamic-time-warping-from-scratch/</guid>
      <description>&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;p&gt;This post walks you through the implementation of a minimalistic yet fully functional 
&lt;a href=&#34;https://www.blasbenito.com/post/dynamic-time-warping/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dynamic Time Warping&lt;/a&gt; (DTW) library in R, built entirely from scratch without dependencies or complex abstractions. While there are many 
&lt;a href=&#34;https://blasbenito.github.io/distantia/articles/dtw_applications.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;open-source DTW implementations&lt;/a&gt; readily available, understanding the inner workings of the algorithm can be invaluable. Whether you’re simply curious or need a deeper grasp of DTW for your projects, this step-by-step guide offers a hands-on approach to demystify the method.&lt;/p&gt;
&lt;h1 id=&#34;design&#34;&gt;Design&lt;/h1&gt;
&lt;h2 id=&#34;example-data&#34;&gt;Example Data&lt;/h2&gt;
&lt;p&gt;Having good example data at hand is a must when developing new code. For this tutorial we use three multivariate time series of temperature, rainfall, and normalized vegetation index. These time series are named &lt;code&gt;zoo_germany&lt;/code&gt;, &lt;code&gt;zoo_sweden&lt;/code&gt;, and &lt;code&gt;zoo_spain&lt;/code&gt;, and are stored as objects of the class 
&lt;a href=&#34;https://CRAN.R-project.org/package=zoo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;zoo&lt;/a&gt;, which is a very robust time series management library.&lt;/p&gt;
&lt;img src=&#34;https://blasbenito.com/post/dynamic-time-warping-from-scratch/index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;Each zoo object has a &lt;em&gt;core data&lt;/em&gt; of the class &lt;code&gt;matrix&lt;/code&gt; with one observation per row and one variable per column, and an &lt;em&gt;index&lt;/em&gt;, which is a vector of dates, one per row in the time series.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;zoo::coredata(zoo_sweden)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         evi rainfall temperature
## 1092 0.1259     32.0        -4.4
## 1132 0.1901     55.6        -2.8
## 1142 0.2664     38.8         1.8
## 1152 0.2785     20.3         7.0
## 1162 0.7068     59.4        10.1
## 1172 0.7085     69.5        14.3
## 1182 0.6580     85.2        19.2
## 1192 0.5831    150.2        16.8
## 1202 0.5036     74.9        12.7
## 1103 0.3587     74.9         7.8
## 1113 0.2213    114.6         2.5
## 1122 0.1475     52.1        -4.7
## 1213 0.2140     49.5        -0.8
## attr(,&amp;quot;name&amp;quot;)
## [1] &amp;quot;zoo_sweden&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;zoo::index(zoo_sweden)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;2010-01-01&amp;quot; &amp;quot;2010-02-01&amp;quot; &amp;quot;2010-03-01&amp;quot; &amp;quot;2010-04-01&amp;quot; &amp;quot;2010-05-01&amp;quot;
##  [6] &amp;quot;2010-06-01&amp;quot; &amp;quot;2010-07-01&amp;quot; &amp;quot;2010-08-01&amp;quot; &amp;quot;2010-09-01&amp;quot; &amp;quot;2010-10-01&amp;quot;
## [11] &amp;quot;2010-11-01&amp;quot; &amp;quot;2010-12-01&amp;quot; &amp;quot;2011-01-01&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;required-library-functions&#34;&gt;Required Library Functions&lt;/h2&gt;
&lt;p&gt;The section &lt;em&gt;DTW Step by Step&lt;/em&gt; from the previous article 
&lt;a href=&#34;https://www.blasbenito.com/post/dynamic-time-warping/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Gentle Intro to Dynamic Time Warping&lt;/a&gt; describes the computational steps required by the algorithm. Below, these steps are broken down into sub-steps that will correspond to specific functions in our library:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Time Series Pre-processing&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;These steps help DTW work seamlessly with the input time series.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Linear detrending&lt;/strong&gt;: forces time series to be stationary by removing any upwards or downwards trends.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Z-score normalization&lt;/strong&gt;: equalizes the range of the time series to ensure that the different variables contribute evenly to the distance computation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Dynamic Time Warping&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;These steps perform dynamic time warping and evaluate the dissimilarity between the time series.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Multivariate distance&lt;/strong&gt;: compute distances between pairs of samples from each time series.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Distance matrix&lt;/strong&gt;: organize the multivariate distances in a matrix in which each axis represents a time series.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cost matrix&lt;/strong&gt;: this matrix accumulates the distances in the distance matrix across time and represents all possible alignments between two time series.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Least-cost path&lt;/strong&gt;: path in the cost matrix that minimizes the overall distance between two time series.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dissimilarity metric&lt;/strong&gt;: value to summarize the dissimilarity between time series.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Main function&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once all the steps above are implemented in their respective functions, we will wrap all them in a single function to streamline the DTW analysis.&lt;/p&gt;
&lt;h1 id=&#34;implementation&#34;&gt;Implementation&lt;/h1&gt;
&lt;p&gt;In this section we will be developing the library concept by concept and function by function.&lt;/p&gt;
&lt;h2 id=&#34;time-series-pre-processing&#34;&gt;Time Series Pre-processing&lt;/h2&gt;
&lt;p&gt;In this section we develop the function &lt;code&gt;ts_preprocessing()&lt;/code&gt;, which will prepare the time series data for dynamic time warping. This function contains two functionalities: &lt;strong&gt;linear detrending&lt;/strong&gt;, and &lt;strong&gt;z-score normalization&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;linear-detrending&#34;&gt;Linear Detrending&lt;/h3&gt;
&lt;p&gt;Applying linear detrending to a multivariate time series involves computing a linear model of each variable against time, and subtracting the the model prediction to the original data. This can be performed in two steps:&lt;/p&gt;
&lt;p&gt;First, the function &lt;code&gt;stats::lm()&lt;/code&gt; can be applied to all variables in one of our time series at once.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model_sweden &amp;lt;- stats::lm(
  formula = zoo_sweden ~ stats::time(zoo_sweden)
  )

model_sweden
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## stats::lm(formula = zoo_sweden ~ stats::time(zoo_sweden))
## 
## Coefficients:
##                          evi         rainfall    temperature
## (Intercept)               8.965e-01  -1.710e+03  -5.706e+01 
## stats::time(zoo_sweden)  -3.480e-05   1.202e-01   4.271e-03
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, the residuals of the linear model, which represent the differences between observations and predictions, correspond exactly with the detrended time series. As a plus, these residuals are returned as a zoo object when the &lt;code&gt;zoo&lt;/code&gt; library is loaded!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;stats::residuals(model_sweden)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                    evi     rainfall temperature
## 2010-01-01 -0.26214896 -13.62153187   -9.739028
## 2010-02-01 -0.19687011   6.25374419   -8.271433
## 2010-03-01 -0.11959566 -13.91052259   -3.791024
## 2010-04-01 -0.10641680 -36.13524652    1.276572
## 2010-05-01  0.32292725  -0.63981807    4.248439
## 2010-06-01  0.32570610   5.73545800    8.316034
## 2010-07-01  0.27625015  17.83088645   13.087901
## 2010-08-01  0.20242901  79.10616252   10.555496
## 2010-09-01  0.12400786   0.08143858    6.323092
## 2010-10-01 -0.01984809  -3.52313297    1.294959
## 2010-11-01 -0.15616924  32.45214310   -4.137446
## 2010-12-01 -0.22892518 -33.65242845  -11.465579
## 2011-01-01 -0.16134633 -39.97715238   -7.697983
## attr(,&amp;quot;name&amp;quot;)
## [1] zoo_sweden
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/post/dynamic-time-warping-from-scratch/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;
Then, the pre-processing function of our library could be something like this:
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#&#39; Linear Detrending
#&#39; @param x (required, zoo object) time series to detrend.
#&#39; @return zoo object
ts_preprocessing &amp;lt;- function(x){
  m &amp;lt;- stats::lm(formula = x ~ stats::time(x))
  y &amp;lt;- stats::residuals(object = m)
  y
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function could be more concise, but it is written to facilitate line-by-line debugging instead. I have also added minimal roxygen documentation. Future me usually appreciates this kind of extra effort. Any kind of effort actually.&lt;/p&gt;
&lt;p&gt;This function should check that &lt;code&gt;x&lt;/code&gt; is really a zoo object, and any other condition that would make it fail, but to keep code simple, in this tutorial we won&amp;rsquo;t do any error catching.&lt;/p&gt;
&lt;p&gt;We can use a mock-up time series with an ascending trend to really test the effect of our detrending function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x &amp;lt;- zoo::zoo(0:10)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/post/dynamic-time-warping-from-scratch/index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;If we apply &lt;code&gt;ts_preprocessing()&lt;/code&gt; to this time series, the result shows a horizontal line, which is a perfect linear detrending. Now we can be sure our implementation works!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x_detrended &amp;lt;- ts_preprocessing(x = x)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/post/dynamic-time-warping-from-scratch/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;
&lt;h3 id=&#34;z-score-normalization&#34;&gt;Z-score Normalization&lt;/h3&gt;
&lt;p&gt;Normalization (also named &lt;em&gt;standardization&lt;/em&gt;) consists of two operations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Centering&lt;/strong&gt;: performed by subtracting the column mean to each case, resulting in a column mean equal to zero.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scaling&lt;/strong&gt;: divides each case by the standard deviation of the column, resulting in a standard deviation equal to one.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The R base function &lt;code&gt;scale()&lt;/code&gt; implements z-score normalization, so there&amp;rsquo;s not much we have to do from scratch here. Also, when the library &lt;code&gt;zoo&lt;/code&gt; is loaded, the method &lt;code&gt;zoo:::scale.zoo&lt;/code&gt; (&lt;code&gt;:::&lt;/code&gt; denotes methods and functions that are not exported by a package) allows &lt;code&gt;scale()&lt;/code&gt; to work seamlessly with zoo objects.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;scale(
  x = zoo_germany,
  center = TRUE,
  scale = TRUE
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   evi    rainfall temperature
## 2010-01-01 -2.1072111 -0.77369778 -1.37937171
## 2010-02-01 -0.5757809 -0.44531242 -0.97212864
## 2010-03-01 -0.4963522 -0.87526026 -0.40724308
## 2010-04-01 -0.1500661 -1.49817681  0.26273747
## 2010-05-01  1.2590783  1.21354145  0.39410620
## 2010-06-01  1.3482213 -0.06614582  1.20859236
## 2010-07-01  0.9973637  0.53307282  1.61583543
## 2010-08-01  0.9990780  1.72812469  1.19545548
## 2010-09-01  0.3750773 -0.07630207  0.66998055
## 2010-10-01  0.2670772 -0.94973941  0.05254749
## 2010-11-01 -0.3477806  0.33671869 -0.38096933
## 2010-12-01 -0.7843525  1.44713515 -1.36623484
## 2011-01-01 -0.7843525 -0.57395823 -0.89330739
## attr(,&amp;quot;name&amp;quot;)
## [1] zoo_germany
## attr(,&amp;quot;scaled:center&amp;quot;)
##         evi    rainfall temperature 
##   0.4376615  60.8538462   8.8000000 
## attr(,&amp;quot;scaled:scale&amp;quot;)
##         evi    rainfall temperature 
##   0.1749998  29.5384669   7.6121613
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thanks to this seamless integration with &lt;code&gt;zoo&lt;/code&gt; time series, z-score normalization can be easily added to our pre-processing function!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#&#39; Linear Detrending and Normalization
#&#39; @param x (required, zoo object) time series to detrend.
#&#39; @return zoo object
ts_preprocessing &amp;lt;- function(x){
  m &amp;lt;- stats::lm(formula = x ~ stats::time(x))
  y &amp;lt;- stats::residuals(object = m)
  z &amp;lt;- scale(y) #new
  z
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now test &lt;code&gt;ts_preprocessing()&lt;/code&gt; and move forward with our implementation.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ts_preprocessing(x = zoo_germany)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                    evi     rainfall temperature
## 2010-01-01 -1.91389650 -0.254652344 -1.35356479
## 2010-02-01 -0.40410400 -0.001606348 -0.95069824
## 2010-03-01 -0.35682407 -0.548358009 -0.38973731
## 2010-04-01 -0.04363355 -1.310450989  0.27590451
## 2010-05-01  1.34386644  1.489002490  0.40300011
## 2010-06-01  1.39742780  0.026066230  1.21316833
## 2010-07-01  1.00791041  0.571260913  1.61617795
## 2010-08-01  0.97319785  1.749131031  1.19130241
## 2010-09-01  0.30672100 -0.273757334  0.66131677
## 2010-10-01  0.16240893 -1.300041138  0.03950285
## 2010-11-01 -0.49483667 -0.024630977 -0.39851146
## 2010-12-01 -0.97089711  1.066065435 -1.38821075
## 2011-01-01 -1.00734053 -1.188028960 -0.91965038
## attr(,&amp;quot;name&amp;quot;)
## [1] zoo_germany
## attr(,&amp;quot;scaled:center&amp;quot;)
##          evi     rainfall  temperature 
## 2.135044e-18 8.113168e-16 5.465713e-16 
## attr(,&amp;quot;scaled:scale&amp;quot;)
##         evi    rainfall temperature 
##   0.1733241  27.6809389   7.6110663
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;dynamic-time-warping-functions&#34;&gt;Dynamic Time Warping Functions&lt;/h2&gt;
&lt;p&gt;This section describes the implementation of the DTW algorithm, which requires functions to compute a distance matrix, convert it to a cost matrix, find a least-cost path maximizing the alignment between the time series, and compute their dissimilarity.&lt;/p&gt;
&lt;h3 id=&#34;distance-matrix&#34;&gt;Distance Matrix&lt;/h3&gt;
&lt;p&gt;In DTW, a distance matrix represents the distances between all pairs of samples in two time series. Hence, each time series is represented in one axis of the matrix. But before getting there, we need a function to obtain the distance between arbitrary pairs of rows from two separate zoo objects.&lt;/p&gt;
&lt;h4 id=&#34;distance-function&#34;&gt;Distance Function&lt;/h4&gt;
&lt;p&gt;Let&amp;rsquo;s say we have two vectors, &lt;code&gt;x&lt;/code&gt; with one row of &lt;code&gt;zoo_germany&lt;/code&gt;, and &lt;code&gt;y&lt;/code&gt; with one row of &lt;code&gt;zoo_sweden&lt;/code&gt;. Then, the expression to compute the Euclidean distances between &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; becomes &lt;code&gt;sqrt(sum((x-y)^2))&lt;/code&gt;. From there, implementing a distance function is kinda trivial.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#&#39; Euclidean Distance
#&#39; @param x (required, numeric) row of a zoo object.  
#&#39; @param y (required, numeric) row of a zoo object.
#&#39; @return numeric
distance_euclidean &amp;lt;- function(x, y){
  sqrt(sum((x - y)^2))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that the function does not indicate the return explicitly. Since the function&amp;rsquo;s body is a one-liner, one cannot be really worried about the function returning something unexpected. Also, implementing such a simple expression in a function might seem like too much, but it may facilitate the addition of new distance metrics to the library in the future. For example, we could create something like &lt;code&gt;distance_manhattan()&lt;/code&gt; with the Manhattan distance, and later switch between one or another depending on the user&amp;rsquo;s needs.&lt;/p&gt;
&lt;p&gt;The code below tests the function by computing the euclidean distance between the row 1 from &lt;code&gt;zoo_sweden&lt;/code&gt; and the row 2 from &lt;code&gt;zoo_germany&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;zoo_sweden[1, ]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               evi rainfall temperature
## 2010-01-01 0.1259       32        -4.4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;zoo_germany[2, ]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               evi rainfall temperature
## 2010-02-01 0.3369     47.7         1.4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;distance_euclidean(
  x = zoo_sweden[1, ],
  y = zoo_germany[2, ]
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sorry, what? That doesn&amp;rsquo;t seem right!&lt;/p&gt;
&lt;p&gt;For whatever reason, &lt;code&gt;zoo_sweden[1, ]&lt;/code&gt; and &lt;code&gt;zoo_germany[2, ]&lt;/code&gt; are not being interpreted as numeric vectors by &lt;code&gt;distance_euclidean()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s try something different:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;distance_euclidean(
  x = as.numeric(zoo_sweden[1, ]),
  y = as.numeric(zoo_germany[2, ])
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 16.73841
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, that makes more sense!&lt;/p&gt;
&lt;p&gt;Then, we just have to move these &lt;code&gt;as.numeric()&lt;/code&gt; commands inside &lt;code&gt;distance_euclidean()&lt;/code&gt; to simplify the usage of the function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#&#39; Euclidean Distance
#&#39; @param x (required, numeric) row of a zoo object.  
#&#39; @param y (required, numeric) row of a zoo object.
#&#39; @return numeric
distance_euclidean &amp;lt;- function(x, y){
  x &amp;lt;- as.numeric(x) #new
  y &amp;lt;- as.numeric(y) #new
  z &amp;lt;- sqrt(sum((x - y)^2))
  z
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new function should have no issues returning the right distance between these rows now:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;distance_euclidean(
  x = zoo_sweden[1, ],
  y = zoo_germany[2, ]
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 16.73841
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can go compute the distance matrix.&lt;/p&gt;
&lt;h4 id=&#34;distance-matrix-1&#34;&gt;Distance Matrix&lt;/h4&gt;
&lt;p&gt;To generate the distance matrix, the function &lt;code&gt;distance_euclidean()&lt;/code&gt; must be applied to all pairs of rows in the two time series.&lt;/p&gt;
&lt;p&gt;A simple yet inefficient way to do this involves creating an empty matrix, and traversing it cell by cell to compute the euclidean distances between the corresponding pair of rows.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#empty distance matrix
m_dist &amp;lt;- matrix(
  data = NA, 
  nrow = nrow(zoo_germany), 
  ncol = nrow(zoo_sweden)
)

#iterate over rows
for(row in 1:nrow(zoo_germany)){
  
  #iterate over columns
  for(col in 1:nrow(zoo_sweden)){
    
    #distance between time series rows
    m_dist[row, col] &amp;lt;- distance_euclidean(
      x = zoo_germany[col, ],
      y = zoo_sweden[row, ]
    )
    
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This code generates a matrix with &lt;code&gt;zoo_germany&lt;/code&gt; in the rows, from top to bottom, and &lt;code&gt;zoo_sweden&lt;/code&gt; in the columns, from left to right. The first five rows and columns are shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;m_dist[1:5, 1:5]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           [,1]      [,2]      [,3]      [,4]     [,5]
## [1,]  6.579761 16.738415 10.538528 21.639813 66.69942
## [2,] 17.634758  8.948271 22.285328 41.303861 43.61868
## [3,]  3.595693  8.909263  5.445835 23.955397 58.75852
## [4,] 19.723690 27.966469 14.757548  5.305437 76.55158
## [5,] 24.446000 14.584815 24.796103 42.806743 37.33875
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This matrix can be plotted with the function &lt;code&gt;graphics::image()&lt;/code&gt;, but please be aware that it rotates the distance matrix 90 degrees counter clock-wise, which can be pretty confusing at first.&lt;/p&gt;
&lt;p&gt;Remember this: &lt;strong&gt;in the matrix plot, the x axis represents the matrix rows&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;graphics::image(
  x = seq_len(nrow(m_dist)),
  y = seq_len(ncol(m_dist)),
  z = m_dist,
  xlab = &amp;quot;zoo_germany&amp;quot;,
  ylab = &amp;quot;zoo_sweden&amp;quot;,
  main = &amp;quot;Euclidean Distance&amp;quot;
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/post/dynamic-time-warping-from-scratch/index_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;Darker values indicate larger distances between pairs of samples in each time series.&lt;/p&gt;
&lt;p&gt;We can now wrap the code above (without the plot) in a new function named &lt;code&gt;distance_matrix()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#&#39; Distance Matrix Between Time Series
#&#39; @param a (required, zoo object) time series.
#&#39; @param b (required, zoo object) time series with same columns as `x`
#&#39; @return matrix
distance_matrix &amp;lt;- function(a, b){
  
  m &amp;lt;- matrix(
    data = NA, 
    nrow = nrow(b), 
    ncol = nrow(a)
  )
  
  for (row in 1:nrow(b)) {
    for (col in 1:nrow(a)) {
      m[row, col] &amp;lt;- distance_euclidean(
        x = a[col, ],
        y = b[row, ] 
      )
    }
  }
  
  m
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s run a little test before moving forward!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;m_dist &amp;lt;- distance_matrix(
  a = zoo_germany,
  b = zoo_sweden
)

m_dist[1:5, 1:5]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           [,1]      [,2]      [,3]      [,4]     [,5]
## [1,]  6.579761 16.738415 10.538528 21.639813 66.69942
## [2,] 17.634758  8.948271 22.285328 41.303861 43.61868
## [3,]  3.595693  8.909263  5.445835 23.955397 58.75852
## [4,] 19.723690 27.966469 14.757548  5.305437 76.55158
## [5,] 24.446000 14.584815 24.796103 42.806743 37.33875
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are good to go! The next function will transform this distance matrix into a &lt;em&gt;cost matrix&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id=&#34;cost-matrix&#34;&gt;Cost Matrix&lt;/h3&gt;
&lt;p&gt;Now we are getting into the important parts of the DTW algorithm!&lt;/p&gt;
&lt;p&gt;A cost matrix is like a valley&amp;rsquo;s landscape, with hills in regions where the time series are different, and ravines where they are more similar. Such landscape is built by accumulating the values of the distance matrix cell by cell, from &lt;code&gt;[1, 1]&lt;/code&gt; at the bottom of the valley (upper left corner of the matrix, but lower left in the plot), to &lt;code&gt;[m, n]&lt;/code&gt; at the top (lower right corner of the matrix, upper right in the plot).&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s see how that works!&lt;/p&gt;
&lt;p&gt;First, we use the dimensions of the distance matrix to create an empty cost matrix.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;m_cost &amp;lt;- matrix(
  data = NA, 
  nrow = nrow(m_dist), 
  ncol = ncol(m_dist)
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, to initialize the cost matrix we accumulate the values of the first row and column of the distance matrix using &lt;code&gt;cumsum()&lt;/code&gt;. This step is very important for the second part of the algorithm, as it provides the starting values of the cost matrix.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;m_cost[1, ] &amp;lt;- cumsum(m_dist[1, ])
m_cost[, 1] &amp;lt;- cumsum(m_dist[, 1])
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/post/dynamic-time-warping-from-scratch/index_files/figure-html/unnamed-chunk-29-1.png&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;Now, before going into the third step, let&amp;rsquo;s focus for a moment on the first cell of the cost matrix we need to fill, with coordinates &lt;code&gt;[2, 2]&lt;/code&gt; and value &lt;code&gt;NA&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;m_cost[1:2, 1:2]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           [,1]     [,2]
## [1,]  6.579761 23.31818
## [2,] 24.214519       NA
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new value of this cell results from the addition of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Its value in the distance matrix &lt;code&gt;m_dist&lt;/code&gt; (8.95).&lt;/li&gt;
&lt;li&gt;The minimum accumulated distance of its neighbors, which are:
&lt;ul&gt;
&lt;li&gt;Upper neighbor with coordinates &lt;code&gt;[1, 2]&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Left neighbor with coordinates &lt;code&gt;[2, 1]&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The general expression to find the value of the empty cell is shown below. It uses &lt;code&gt;min()&lt;/code&gt; to get the value of the &lt;em&gt;smallest&lt;/em&gt; neighbor, and then adds it to the vaue of the target cell in the distance matrix.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;m_cost[2, 2] &amp;lt;- min(
  m_cost[1, 2], 
  m_cost[2, 1]
  ) + m_dist[2, 2]

m_cost[1:2, 1:2]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           [,1]     [,2]
## [1,]  6.579761 23.31818
## [2,] 24.214519 32.26645
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But there are many cells to fill yet!&lt;/p&gt;
&lt;img src=&#34;https://blasbenito.com/post/dynamic-time-warping-from-scratch/index_files/figure-html/unnamed-chunk-32-1.png&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;The expression we used to fill the cell &lt;code&gt;m_cost[2, 2]&lt;/code&gt; can be generalized to fill all remaining empty cells. We just have to wrap it in a nested loop that for each new empty cell identifies the smallest neighbor in the x and y axies, and adds its cumulative cost to the distance of the new cell.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#iterate over rows of the cost matrix
for(row in 2:nrow(m_dist)){
  
  #iterate over columns of the cost matrix
  for(col in 2:ncol(m_dist)){
    
    #get cost of neighbor with minimum accumulated cost
    min_cost &amp;lt;- min(
      m_cost[row - 1, col], 
      m_cost[row, col - 1]
      )
    
    #add it to the distance of the target cell
    new_value &amp;lt;- min_cost + m_dist[row, col]
    
    #fill the empty cell with the new value
    m_cost[row, col] &amp;lt;- new_value
    
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running the code above results in a nicely filled cost matrix!&lt;/p&gt;
&lt;img src=&#34;https://blasbenito.com/post/dynamic-time-warping-from-scratch/index_files/figure-html/unnamed-chunk-34-1.png&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;Now that we have all the pieces figured out, we can define our new function to compute the cost matrix. Notice that the code within the nested loops is slightly more concise than shown before.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#&#39; Cost Matrix from Distance Matrix
#&#39; @param distance_matrix (required, matrix) distance matrix.
#&#39; @return matrix
cost_matrix &amp;lt;- function(distance_matrix){
  
  m &amp;lt;- matrix(
    data = NA, 
    nrow = nrow(distance_matrix), 
    ncol = ncol(distance_matrix)
  )
  
  m[1, ] &amp;lt;- cumsum(distance_matrix[1, ])
  m[, 1] &amp;lt;- cumsum(distance_matrix[, 1])
  
  for(row in 2:nrow(distance_matrix)){
    for(col in 2:ncol(distance_matrix)){
      
      m[row, col] &amp;lt;- min(
        m[row - 1, col], 
        m[row, col - 1]
      ) + distance_matrix[row, col]
      
    }
  }
  
  m
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s test our new function using &lt;code&gt;m_dist&lt;/code&gt; as input:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;m_cost &amp;lt;- cost_matrix(distance_matrix = m_dist)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/post/dynamic-time-warping-from-scratch/index_files/figure-html/unnamed-chunk-37-1.png&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;So far so good! We can now dive into the generation of the least-cost path.&lt;/p&gt;
&lt;h3 id=&#34;least-cost-path&#34;&gt;Least-Cost Path&lt;/h3&gt;
&lt;p&gt;If we describe the cost matrix as a valley with its hills and ravines, then the least-cost path is the river following the line of maximum slope all the way to the bottom of the valley. Following the analogy, the least-cost path starts in the terminal cell of the cost matrix (&lt;code&gt;[13, 13]&lt;/code&gt;), and ends in the first cell.&lt;/p&gt;
&lt;p&gt;To find the least-cost path we first define a data frame with the coordinates of the terminal cell in the cost matrix.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;path &amp;lt;- data.frame(
  row = ncol(m_cost),
  col = nrow(m_cost)
)

path
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   row col
## 1  13  13
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is the first step of the least cost path. From here, there are two candidate steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;one column left&lt;/em&gt;: &lt;code&gt;[row, col - 1]&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;one row up&lt;/em&gt;: &lt;code&gt;[row - 1, col]&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But before moving forward, notice that if we apply these steps indefinitely in our cost matrix, at some point a move up &lt;code&gt;row - 1&lt;/code&gt; or left &lt;code&gt;col - 1&lt;/code&gt; will go out of bounds and produce an error. That&amp;rsquo;s why it&amp;rsquo;s safer to define the next move as&amp;hellip;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;one column left&lt;/em&gt;: &lt;code&gt;[row, max(col - 1, 1)]&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;one row up&lt;/em&gt;: &lt;code&gt;[max(row - 1, 1), col]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&amp;hellip;which confines all steps within the first row and column of the cost matrix.&lt;/p&gt;
&lt;p&gt;With that out of the way, now we have to select the move towards a cell with a lower cost. There are many ways to accomplish this task! Let&amp;rsquo;s look one of them.&lt;/p&gt;
&lt;p&gt;First, we define the candidate moves using the first row of the least-cost path as reference, and generate a list with the coordinates of the candidate steps.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;steps &amp;lt;- list(
  left = c(path$row, max(path$col - 1, 1)),
  up = c(max(path$row - 1, 1), path$col)
)

steps
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $left
## [1] 13 12
## 
## $up
## [1] 12 13
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, we extract the values of the cost matrix for the coordinates of these two steps.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;costs &amp;lt;- list(
  left = m_cost[steps$left[1], steps$left[2]],
  up = m_cost[steps$up[1], steps$up[2]]
)

costs
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $left
## [1] 495.481
## 
## $up
## [1] 457.7403
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we choose the candidate step with the lower cost using &lt;code&gt;which.min()&lt;/code&gt;, a function that returns the index of the smallest value in a vector or list. Notice that we use &lt;code&gt;[1]&lt;/code&gt; in &lt;code&gt;which.min(costs)[1]&lt;/code&gt; to resolve potential ties that may be returned by &lt;code&gt;which.min()&lt;/code&gt; if the two costs are the same (unlikely, but possible).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;steps[[which.min(costs)[1]]]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 12 13
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Combining these pieces we can now build a function named &lt;code&gt;least_cost_step()&lt;/code&gt; that takes the cost matrix and the last row of a least-cost path, and returns a new row with the coordinates of the next step.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#&#39; Identify Next Step of Least-Cost Path
#&#39; @param cost_matrix (required, matrix) cost matrix.
#&#39; @param last_step (required, data frame) one row data frame with columns &amp;quot;row&amp;quot; and &amp;quot;col&amp;quot; representing the last step of a least-cost path.
#&#39; @return one row data frame, new step in least-cost path
least_cost_step &amp;lt;- function(cost_matrix, last_step){
  
  #define candidate steps
  steps &amp;lt;- list(
    left = c(last_step$row, max(last_step$col - 1, 1)),
    up = c(max(last_step$row - 1, 1), last_step$col)
  )
  
  #obtain their costs
  costs &amp;lt;- list(
    left = cost_matrix[steps$left[1], steps$left[2]],
    up = cost_matrix[steps$up[1], steps$up[2]]
  )
  
  #select the one with a smaller cost
  coords &amp;lt;- steps[[which.min(costs)[1]]]
  
  #rewrite input with new values
  last_step[,] &amp;lt;- c(coords[1], coords[2])
  
  last_step
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that the function overwrites the input data frame &lt;code&gt;step&lt;/code&gt; with the new values to avoid generating a new data frame, making the code a bit more concise.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s check how it works:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;least_cost_step(
  cost_matrix = m_cost, 
  last_step = path
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   row col
## 1  12  13
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Good, it returned the move to the upper neighbor!&lt;/p&gt;
&lt;p&gt;Now, if you think about the function for a bit, you&amp;rsquo;ll see that it takes a step in the least-cost path, and returns a new one. From there, it seems we can feed it its own result again and again until it runs out of new steps to find.&lt;/p&gt;
&lt;p&gt;We can do that in a concise way using a &lt;code&gt;repeat{}&lt;/code&gt; loop. Notice that it will keep running until both coordinates in the last row of the path are equal to 1.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;repeat{
  
  #find next step
  new.step &amp;lt;- least_cost_step(
    cost_matrix = m_cost, 
    last_step = tail(path, n = 1)
    )
  
  #join the new step with path
  path &amp;lt;- rbind(
    path, new.step,
    make.row.names = FALSE
    )
  
  #stop when step coordinates are 1, 1
  if(all(tail(path, n = 1) == 1)){break}
  
}

path
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    row col
## 1   13  13
## 2   12  13
## 3   12  12
## 4   11  12
## 5   10  12
## 6   10  11
## 7    9  11
## 8    9  10
## 9    9   9
## 10   9   8
## 11   8   8
## 12   7   8
## 13   7   7
## 14   6   7
## 15   6   6
## 16   5   6
## 17   5   5
## 18   5   4
## 19   4   4
## 20   4   3
## 21   3   3
## 22   3   2
## 23   3   1
## 24   2   1
## 25   1   1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The resulting least-cost path can be plotted on top of the cost matrix. Please, remember that the data is not pre-processed, and the plot below does not represent the real alignment (yet) between our target time series.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;graphics::image(
    x = seq_len(nrow(m_cost)),
    y = seq_len(ncol(m_cost)),
    z = m_cost,
    xlab = &amp;quot;zoo_germany&amp;quot;,
    ylab = &amp;quot;zoo_sweden&amp;quot;,
    main = &amp;quot;Cost Matrix and Least-Cost Path&amp;quot;
    )

graphics::lines(
  x = path$row, 
  y = path$col,
  lwd = 2
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/post/dynamic-time-warping-from-scratch/index_files/figure-html/unnamed-chunk-46-1.png&#34; width=&#34;672&#34; /&gt;
&lt;p&gt;At this point we have all the pieces required to write the function &lt;code&gt;least_cost_path()&lt;/code&gt;. Notice that the &lt;code&gt;repeat{}&lt;/code&gt; statement is slightly more concise than before, as &lt;code&gt;least_cost_step()&lt;/code&gt; is directly wrapped within &lt;code&gt;rbind()&lt;/code&gt;. However, using &lt;code&gt;rbind()&lt;/code&gt; in a loop to add rows to a data frame is not a computationally efficient operation, but it was used here anyway because it makes the code more concise.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#&#39; Least-Cost Path from Cost Matrix
#&#39; @param cost_matrix (required, matrix) cost matrix.
#&#39; @return data frame with least-cost path coordinates
least_cost_path &amp;lt;- function(cost_matrix){
  
  #first step of the least cost path
  path &amp;lt;- data.frame(
    row = nrow(cost_matrix),
    col = ncol(cost_matrix)
  )
  
  #iterate until path is completed
  repeat{
    
    #merge path with result of least_cost_step()
    path &amp;lt;- rbind(
      path, 
      #find next step
      least_cost_step(
        cost_matrix = cost_matrix, 
        last_step = tail(path, n = 1)
      ),
      make.row.names = FALSE
    )
    
    #stop when coordinates are 1, 1
    if(all(tail(path, n = 1) == 1)){break}
    
  }
  
  path
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can give it a go now to see that it works as expected.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;least_cost_path(cost_matrix = m_cost)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    row col
## 1   13  13
## 2   12  13
## 3   12  12
## 4   11  12
## 5   10  12
## 6   10  11
## 7    9  11
## 8    9  10
## 9    9   9
## 10   9   8
## 11   8   8
## 12   7   8
## 13   7   7
## 14   6   7
## 15   6   6
## 16   5   6
## 17   5   5
## 18   5   4
## 19   4   4
## 20   4   3
## 21   3   3
## 22   3   2
## 23   3   1
## 24   2   1
## 25   1   1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nice, it worked, and now we have a nice least-cost path.&lt;/p&gt;
&lt;p&gt;But before continuing, there is just a little detail to notice about the least-cost path. Every time the same row index (such as &lt;code&gt;9&lt;/code&gt;) is linked to different column indices (&lt;code&gt;8&lt;/code&gt; to &lt;code&gt;11&lt;/code&gt;), it means that the samples of the time series identified by these column indices are having their time &lt;em&gt;compressed&lt;/em&gt; (or &lt;em&gt;warped&lt;/em&gt;) to the time of the row index. Hence, according to the least-cost path, the samples &lt;code&gt;8&lt;/code&gt; to &lt;code&gt;11&lt;/code&gt; of &lt;code&gt;zoo_sweden&lt;/code&gt; would be aligned in time with the sample &lt;code&gt;9&lt;/code&gt; of &lt;code&gt;zoo_germany&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now it&amp;rsquo;s time to use the least-cost path to quantify the similarity between the time series.&lt;/p&gt;
&lt;h3 id=&#34;dissimilarity-metric&#34;&gt;Dissimilarity Metric&lt;/h3&gt;
&lt;p&gt;The objective of dynamic time warping is to compute a metric of &lt;em&gt;dissimilarity&lt;/em&gt; (or &lt;em&gt;similarity&lt;/em&gt;, it just depends on the side from where you are looking at the issue) between time series. This operation requires two steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Obtain the accumulated distance of the least cost path.&lt;/li&gt;
&lt;li&gt;Normalize the sum of distances by some number to help make results comparable across pairs of time series of different lengths.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, the method designed to build the cost matrix accumulates the distance of the least-cost path in the terminal cell, so we just have to extract it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;distance &amp;lt;- m_cost[nrow(m_cost), ncol(m_cost)]
distance
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 464.0019
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Second, we need to find a number to normalize this distance value to make it comparable across different time series. There are several options, such as dividing &lt;code&gt;distance&lt;/code&gt; by the sum of lengths of the two time series, or by the length of the least-cost path (&lt;code&gt;nrow(path)&lt;/code&gt;).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;distance/sum(dim(m_cost))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 17.84623
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;distance/nrow(path)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 18.56008
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another elegant normalization option requires computing the sum of distances between consecutive samples on each time series. This operation, named &lt;em&gt;auto-sum&lt;/em&gt;, requires applying &lt;code&gt;distance_euclidean()&lt;/code&gt; between the samples 1 and 2 of the given time series, then between the samples 2 and the 3, and so on until all consecutive sample pairs are processed, to finally sum all computed distances.&lt;/p&gt;
&lt;p&gt;To apply this operation to a time series we iterate between pairs of consecutive samples and save their distance in a vector (named &lt;code&gt;autodistance&lt;/code&gt; in the code below). Once the loop is done, then the auto-sum of the time series is the sum of this vector.&lt;/p&gt;
&lt;p&gt;For example, for &lt;code&gt;zoo_germany&lt;/code&gt; we would have:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#vector to store auto-distances
autodistance &amp;lt;- vector(
  mode = &amp;quot;numeric&amp;quot;, 
  length = nrow(zoo_germany) - 1
  )

#compute of row-to-row distance
for (row in 2:nrow(zoo_germany)) {
  autodistance[row - 1] &amp;lt;- distance_euclidean(
    x = zoo_germany[row, ],
    y = zoo_germany[row - 1, ]
  )
}

#compute autosum
sum(autodistance)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 425.7877
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since we&amp;rsquo;ll need to apply this operation to many time series, it&amp;rsquo;s better to formalize this logic as a function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#&#39; Time Series Autosum
#&#39; @param x (required, zoo object) time series
#&#39; @return numeric
auto_sum &amp;lt;- function(x){
  
  autodistance &amp;lt;- vector(
    mode = &amp;quot;numeric&amp;quot;, 
    length = nrow(x) - 1
  )
  
  for (row in 2:nrow(x)) {
    autodistance[row - 1] &amp;lt;- distance_euclidean(
      x = x[row, ],
      y = x[row - 1, ]
    )
  }
  
  sum(autodistance)
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now apply it to our two time series:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;zoo_germany_autosum &amp;lt;- auto_sum(
  x = zoo_germany
)

zoo_germany_autosum
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 425.7877
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;zoo_sweden_autosum &amp;lt;- auto_sum(
  x = zoo_sweden
)

zoo_sweden_autosum
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 379.9118
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have the auto-sum of both time series, we just have to add them together to obtain our normalization value.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;normalizer &amp;lt;- zoo_germany_autosum + zoo_sweden_autosum
normalizer
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 805.6995
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we obtained &lt;code&gt;distance&lt;/code&gt; from the cost matrix and the &lt;code&gt;normalizer&lt;/code&gt; from the auto-sum of the two time series, we can compute our dissimilarity score, which follows the expression below:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;((2 * distance) / normalizer) - 1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1517989
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Why this particular formula? Because it returns zero when comparing a time series with itself!&lt;/p&gt;
&lt;p&gt;When the two time series are the same, &lt;code&gt;2 * distance&lt;/code&gt; equals &lt;code&gt;normalizer&lt;/code&gt; because DTW and auto-sum are equivalent (sample-to-sample distances!), and dividing them returns one. We then subtract one to it, and get zero, which represents a perfect similarity score.&lt;/p&gt;
&lt;p&gt;The same affect cannot be achieved when using other normalization values, such as the sum of lengths of the time series, or the length of the least cost path.&lt;/p&gt;
&lt;p&gt;We can integrate these pieces into the function &lt;code&gt;dissimilarity_score()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#&#39; Similarity Metric from Least Cost Path and Cost Matrix
#&#39; @param a (required, zoo object) time series.
#&#39; @param b (required, zoo object) time series with same columns as `x`
#&#39; @param cost_path (required, data frame) least cost path with the columns &amp;quot;row&amp;quot; and &amp;quot;col&amp;quot;.
#&#39; @return numeric, similarity metric
dissimilarity_score &amp;lt;- function(a, b, cost_matrix){
  
  #distance of the least cost path
  distance &amp;lt;- cost_matrix[nrow(cost_matrix), ncol(cost_matrix)]
  
  #compute normalization factor from autosum
  autosum_a &amp;lt;- auto_sum(x = a)
    
  autosum_b &amp;lt;- auto_sum(x = b)
  
  normalizer &amp;lt;- autosum_a + autosum_b
  
  #compute dissimilarity
  psi &amp;lt;- ((2 * distance) / normalizer) - 1
  
  psi
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can give it a test run now:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dissimilarity_score(
  a = zoo_germany,
  b = zoo_sweden,
  cost_matrix = m_cost
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1517989
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the &lt;code&gt;dissimilarity_score()&lt;/code&gt; function ready, it is time to go write our main function!&lt;/p&gt;
&lt;h2 id=&#34;main-function&#34;&gt;Main Function&lt;/h2&gt;
&lt;p&gt;To recapitulate before moving forward, we have the following functions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ts_preprocessing()&lt;/code&gt; applies linear detrending and z-score normalization to a time series.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;distance_matrix()&lt;/code&gt; and &lt;code&gt;distance_euclidean()&lt;/code&gt; work together to compute a distance matrix.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cost_matrix()&lt;/code&gt; transforms the distance matrix into a cost matrix.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;least_cost_path()&lt;/code&gt; applies &lt;code&gt;least_cost_step()&lt;/code&gt; recursively to build a least-cost path.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dissimilarity_score()&lt;/code&gt;, which calls &lt;code&gt;auto_sum()&lt;/code&gt; and quantifies time series dissimilarity.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can wrap together all these functions into a new one with the unimaginative name &lt;code&gt;dynamic_time_warping()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#&#39; Similarity Between Time Series
#&#39; @param a (required, zoo object) time series.
#&#39; @param b (required, zoo object) time series with same columns as `x`
#&#39; @param plot (optional, logical) if `TRUE`, a dynamic time warping plot is produced.
#&#39; @return psi score
dynamic_time_warping &amp;lt;- function(a, b, plot = FALSE){
  
  #linear detrending and z-score normalization
  a_ &amp;lt;- ts_preprocessing(x = a)
  b_ &amp;lt;- ts_preprocessing(x = b)
  
  #distance matrix
  m_dist &amp;lt;- distance_matrix(
    a = a_,
    b = b_
  )
  
  #cost matrix
  m_cost &amp;lt;- cost_matrix(
    distance_matrix = m_dist
  )
  
  #least-cost path
  cost_path &amp;lt;- least_cost_path(
    cost_matrix = m_cost
  )
  
  #similarity metric
  score &amp;lt;- dissimilarity_score(
    a = a_,
    b = b_,
    cost_matrix = m_cost
  )
  
  #plot
  if(plot == TRUE){
    
    graphics::image(
      x = seq_len(nrow(m_cost)),
      y = seq_len(ncol(m_cost)),
      z = m_cost,
      xlab = &amp;quot;a&amp;quot;,
      ylab = &amp;quot;b&amp;quot;,
      main = paste0(&amp;quot;Similarity score = &amp;quot;, round(score, 3))
    )
    
    graphics::lines(
      x = cost_path$row, 
      y = cost_path$col,
      lwd = 2
    )
    
  }
  
  score
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before I said that one advantage of the presented dissimilarity formula is that it returns 0 when comparing a time series with itself. Let&amp;rsquo;s see if that&amp;rsquo;s true by comparing &lt;code&gt;zoo_germany&lt;/code&gt; with itself:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dynamic_time_warping(
  a = zoo_germany,
  b = zoo_germany
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That&amp;rsquo;s good, right? Perfect similarity happens at 0, which is a lovely number to start with. If we now compare &lt;code&gt;zoo_germany&lt;/code&gt; and &lt;code&gt;zoo_sweden&lt;/code&gt;, we should expect a larger number:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dynamic_time_warping(
  a = zoo_germany,
  b = zoo_sweden
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.2366642
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now, when comparing &lt;code&gt;zoo_sweden&lt;/code&gt; with &lt;code&gt;zoo_spain&lt;/code&gt; we should expect an even higher dissimilarity score, given that they are quite far apart. As a bonus, we let the function plot their alignment.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dynamic_time_warping(
  a = zoo_sweden,
  b = zoo_spain,
  plot = TRUE
)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/post/dynamic-time-warping-from-scratch/index_files/figure-html/unnamed-chunk-63-1.png&#34; width=&#34;672&#34; /&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.509285
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well, that was freaking long, but these are such nice results, aren&amp;rsquo;t they? I hope it was worth it! One minute more, and we are done.&lt;/p&gt;
&lt;h2 id=&#34;library-source&#34;&gt;Library Source&lt;/h2&gt;
&lt;p&gt;Once we have all our DTW functions written and tested, the easiest way to make them usable without any extra hassle is to write them to a source file. Having them all in a single file allows loading them at once via the &lt;code&gt;source()&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;For example, if our library file is 
&lt;a href=&#34;https://www.dropbox.com/scl/fi/z2n9hnenxwuxwol5i0zcn/dtw.R?rlkey=bhsyew12r1glnqihtnocxwri6&amp;amp;dl=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;dtw.R&lt;/code&gt;&lt;/a&gt;, running &lt;code&gt;source(&amp;quot;dtw.R&amp;quot;)&lt;/code&gt; will load all functions into your R environment and they will be readily available for your DTW analysis.&lt;/p&gt;
&lt;h2 id=&#34;closing-thoughts&#34;&gt;Closing Thoughts&lt;/h2&gt;
&lt;p&gt;I hope you found this tutorial useful in one way or another. Writing a methodological library from scratch is hard work. There are many moving parts to consider, many concepts that need to be mapped and then translated into code, that making mistakes becomes exceedingly easy. Never worry about that and take your time until things start clicking.&lt;/p&gt;
&lt;p&gt;But above everything, enjoy the learning journey!&lt;/p&gt;
&lt;h2 id=&#34;coming-next&#34;&gt;Coming Next&lt;/h2&gt;
&lt;p&gt;In my TODO list there is a post focused on identifying computational bottlenecks in the DTW library we just wrote, and optimize the parts worth optimizing. There&amp;rsquo;s no timeline yet though, so stay tuned!&lt;/p&gt;
&lt;p&gt;Blas&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R package collinear</title>
      <link>https://blasbenito.com/project/collinear/</link>
      <pubDate>Sun, 12 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://blasbenito.com/project/collinear/</guid>
      <description>&lt;!-- badges: start --&gt;
&lt;p&gt;
&lt;a href=&#34;https://doi.org/10.5281/zenodo.10039489&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/DOI/10.5281/zenodo.10039489.svg&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt;

&lt;a href=&#34;https://cran.r-project.org/package=collinear&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version/collinear&#34; alt=&#34;CRAN status&#34;&gt;&lt;/a&gt;

&lt;a href=&#34;https://CRAN.R-project.org/package=collinear&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;http://cranlogs.r-pkg.org/badges/grand-total/collinear&#34; alt=&#34;CRAN\_Download\_Badge&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;!-- badges: end --&gt;
&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.blasbenito.com/post/multicollinearity-model-interpretability/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Multicollinearity hinders the interpretability&lt;/a&gt; of linear and machine learning models.&lt;/p&gt;
&lt;p&gt;The R package 
&lt;a href=&#34;https://blasbenito.github.io/collinear/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;&lt;code&gt;collinear&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;, 
&lt;a href=&#34;https://CRAN.R-project.org/package=collinear&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;available on CRAN&lt;/a&gt;, combines four methods for easy management of multicollinearity in modelling data frames with numeric and categorical variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Target Encoding&lt;/strong&gt;: Transforms categorical predictors to numeric using a numeric response as reference.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Preference Order&lt;/strong&gt;: Ranks predictors by their association with a response variable to preserve important ones in multicollinearity filtering.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pairwise Correlation Filtering&lt;/strong&gt;: Automated multicollinearity filtering of numeric and categorical predictors based&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;main-improvements-in-version-200&#34;&gt;Main Improvements in Version 2.0.0&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Expanded Functionality&lt;/strong&gt;: Functions &lt;code&gt;collinear()&lt;/code&gt; and &lt;code&gt;preference_order()&lt;/code&gt; support both categorical and numeric responses and predictors, and can handle several responses at once.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Robust Selection Algorithms&lt;/strong&gt;: Enhanced selection in &lt;code&gt;vif_select()&lt;/code&gt; and &lt;code&gt;cor_select()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enhanced Functionality to Rank Predictors&lt;/strong&gt;: New functions to compute association between response and predictors covering most use-cases, and automated function selection depending on data features.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Simplified Target Encoding&lt;/strong&gt;: Streamlined and parallelized for better efficiency, and new default is &amp;ldquo;loo&amp;rdquo; (leave-one-out).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Parallelization and Progress Bars&lt;/strong&gt;: Utilizes &lt;code&gt;future&lt;/code&gt; and &lt;code&gt;progressr&lt;/code&gt; for enhanced performance and user experience.on pairwise correlations.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Variance Inflation Factor Filtering&lt;/strong&gt;: Automated multicollinearity filtering of numeric predictors based on Variance Inflation Factors.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The article 
&lt;a href=&#34;https://blasbenito.github.io/collinear/articles/how_it_works.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How It Works&lt;/a&gt; explains how the package works in detail.&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you find this package useful, please cite it as:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Blas M. Benito (2024). collinear: R Package for Seamless Multicollinearity Management. Version 2.0.0. doi: 10.5281/zenodo.10039489&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R package distantia</title>
      <link>https://blasbenito.com/project/distantia/</link>
      <pubDate>Sun, 12 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://blasbenito.com/project/distantia/</guid>
      <description>&lt;!-- badges: start --&gt;
&lt;p&gt;
&lt;a href=&#34;https://zenodo.org/badge/latestdoi/187805264&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/187805264.svg&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt;

&lt;a href=&#34;https://CRAN.R-project.org/package=distantia&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version-ago/distantia&#34; alt=&#34;CRAN\_Release\_Badge&#34;&gt;&lt;/a&gt;

&lt;a href=&#34;https://CRAN.R-project.org/package=distantia&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://cranlogs.r-pkg.org/badges/distantia&#34; alt=&#34;CRAN\_Download\_Badge&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;!-- badges: end --&gt;
&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;
&lt;p&gt;The R package 
&lt;a href=&#34;https://blasbenito.github.io/distantia/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;&lt;code&gt;distantia&lt;/code&gt;&lt;/strong&gt;&lt;/a&gt;, 
&lt;a href=&#34;https://CRAN.R-project.org/package=distantia&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;available on CRAN&lt;/a&gt;, offers an efficient, feature-rich toolkit for managing, comparing, and analyzing time series data. It is designed to handle a wide range of scenarios, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multivariate and univariate time series.&lt;/li&gt;
&lt;li&gt;Regular and irregular sampling.&lt;/li&gt;
&lt;li&gt;Time series of different lengths.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;key-features&#34;&gt;Key Features&lt;/h2&gt;
&lt;h3 id=&#34;comprehensive-analytical-tools&#34;&gt;Comprehensive Analytical Tools&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;10 distance metrics: see &lt;code&gt;distantia::distances&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The normalized dissimilarity metric &lt;code&gt;psi&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Free and Restricted Dynamic Time Warping (DTW) for shape-based comparison.&lt;/li&gt;
&lt;li&gt;A Lock-Step method for sample-to-sample comparison&lt;/li&gt;
&lt;li&gt;Restricted permutation tests for robust inferential support.&lt;/li&gt;
&lt;li&gt;Analysis of contribution to dissimilarity of individual variables in multivariate time series.&lt;/li&gt;
&lt;li&gt;Hierarchical and K-means clustering of time series based on dissimilarity matrices.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;computational-efficiency&#34;&gt;Computational Efficiency&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;strong&gt;C++ back-end&lt;/strong&gt; powered by 
&lt;a href=&#34;https://www.rcpp.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rcpp&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Parallel processing&lt;/strong&gt; managed through the 
&lt;a href=&#34;https://future.futureverse.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;future&lt;/a&gt; package.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Efficient data handling&lt;/strong&gt; via 
&lt;a href=&#34;https://CRAN.R-project.org/package=zoo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;zoo&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;time-series-management-tools&#34;&gt;Time Series Management Tools&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Introduces &lt;strong&gt;time series lists&lt;/strong&gt; (TSL), a versatile format for handling collections of time series stored as lists of &lt;code&gt;zoo&lt;/code&gt; objects.&lt;/li&gt;
&lt;li&gt;Includes a suite of &lt;code&gt;tsl_...()&lt;/code&gt; functions for generating, resampling, transforming, analyzing, and visualizing univariate and multivariate time series.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;citation&#34;&gt;Citation&lt;/h3&gt;
&lt;p&gt;If you find this package useful, please cite it as:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Blas M. Benito, H. John B. Birks (2020). distantia: an open-source toolset to quantify dissimilarity between multivariate ecological time-series. Ecography, 43(5), 660-667. doi: 
&lt;a href=&#34;https://nsojournals.onlinelibrary.wiley.com/doi/10.1111/ecog.04895&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.1111/ecog.04895&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Blas M. Benito (2024). distantia: A Toolset for Time Series Dissimilarity Analysis. R package version 2.0.0. url:  
&lt;a href=&#34;https://blasbenito.github.io/distantia/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://blasbenito.github.io/distantia/&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R package spatialRF</title>
      <link>https://blasbenito.com/project/post-title/</link>
      <pubDate>Tue, 26 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://blasbenito.com/project/post-title/</guid>
      <description>&lt;script src=&#34;https://blasbenito.com/project/post-title/index_files/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://blasbenito.com/project/post-title/index_files/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://blasbenito.com/project/post-title/index_files/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://blasbenito.com/project/post-title/index_files/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://blasbenito.com/project/post-title/index_files/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://blasbenito.com/project/post-title/index_files/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://blasbenito.com/project/post-title/index_files/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://blasbenito.com/project/post-title/index_files/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://blasbenito.com/project/post-title/index_files/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://blasbenito.com/project/post-title/index_files/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://blasbenito.com/project/post-title/index_files/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://blasbenito.com/project/post-title/index_files/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://blasbenito.com/project/post-title/index_files/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://blasbenito.com/project/post-title/index_files/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;https://blasbenito.com/project/post-title/index_files/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://blasbenito.com/project/post-title/index_files/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;!---
[![R-CMD-check](https://github.com/BlasBenito/spatialRF/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/BlasBenito/spatialRF/actions/workflows/R-CMD-check.yaml)
--&gt;
&lt;!-- badges: start --&gt;
&lt;p&gt;
&lt;a href=&#34;https://cran.r-project.org/package=spatialRF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version/spatialRF&#34; alt=&#34;CRAN status&#34;&gt;&lt;/a&gt;

&lt;a href=&#34;https://CRAN.R-project.org/package=spatialRF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;http://cranlogs.r-pkg.org/badges/grand-total/spatialRF&#34; alt=&#34;CRAN\_Download\_Badge&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;!-- badges: end --&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;The package &lt;strong&gt;spatialRF&lt;/strong&gt; facilitates fitting spatial regression models on regular or irregular data with Random Forest. It does so by generating &lt;em&gt;spatial predictors&lt;/em&gt; that help the model &amp;ldquo;understand&amp;rdquo; the spatial structure of the training data with the end goal of minimizing the spatial autocorrelation of the model residuals and offering honest variable importance scores.&lt;/p&gt;
&lt;p&gt;Two main methods to generate &lt;em&gt;spatial predictors&lt;/em&gt; from the distance matrix of the data points are implemented in the package:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Moran&amp;rsquo;s Eigenvector Maps 
&lt;a href=&#34;https://www.sciencedirect.com/science/article/abs/pii/S0304380006000925&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(Dray, Legendre, and Peres-Neto 2006)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Distance matrix columns as explanatory variables 
&lt;a href=&#34;https://peerj.com/articles/5518/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(Hengl et al. 2018)&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The package is designed to minimize the code required to fit a spatial model from a training dataset, the names of the response and the predictors, and a distance matrix, as shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatial.model &amp;lt;- spatialRF::rf_spatial(
  data = your_dataframe,
  dependent.variable.name = &amp;quot;your_response_variable&amp;quot;,
  predictor.variable.names = c(&amp;quot;predictor1&amp;quot;, &amp;quot;predictor2&amp;quot;, ..., &amp;quot;predictorN&amp;quot;),
  distance.matrix = your_distance_matrix
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;spatialRF&lt;/strong&gt; uses the fast and efficient &lt;code&gt;ranger&lt;/code&gt; package under the hood 
&lt;a href=&#34;https://arxiv.org/abs/1508.04409&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;(Wright and Ziegler 2017)&lt;/a&gt;, so please, cite the &lt;code&gt;ranger&lt;/code&gt; package when using &lt;code&gt;spatialRF&lt;/code&gt;!&lt;/p&gt;
&lt;p&gt;This package also provides tools to identify potentially interesting variable interactions, tune random forest hyperparameters, assess model performance on spatially independent data folds, and examine the resulting models via importance plots, response curves, and response surfaces.&lt;/p&gt;
&lt;h1 id=&#34;development&#34;&gt;Development&lt;/h1&gt;
&lt;p&gt;This package is reaching its final form, and big changes are not expected at this stage. However, it has many functions, and even though all them have been tested, only one dataset has been used for those tests. You will find bugs, and something will go wrong almost surely. If you have time to report bugs, please, do so in any of the following ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open a new issue in the 
&lt;a href=&#34;https://github.com/BlasBenito/spatialRF/issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Issues GitHub page of the package&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Send me an email explaining the issue and the error messages with enough detail at blasbenito at gmail dot com.&lt;/li&gt;
&lt;li&gt;Send a direct message to 
&lt;a href=&#34;https://twitter.com/blasbenito&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;my twitter account&lt;/a&gt; explaining the issue.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I will do my best to solve any issues ASAP!&lt;/p&gt;
&lt;h1 id=&#34;applications&#34;&gt;Applications&lt;/h1&gt;
&lt;p&gt;The goal of &lt;code&gt;spatialRF&lt;/code&gt; is to help fitting &lt;em&gt;explanatory spatial regression&lt;/em&gt;, where the target is to understand how a set of predictors and the spatial structure of the data influences response variable. Therefore, the spatial analyses implemented in the package can be applied to any spatial dataset, regular or irregular, with a sample size between ~100 and ~5000 cases (the higher end will depend on the RAM memory available), a quantitative or binary (values 0 and 1) response variable, and a more or less large set of predictive variables.&lt;/p&gt;
&lt;p&gt;All functions but &lt;code&gt;rf_spatial()&lt;/code&gt; work with non-spatial data as well if the arguments &lt;code&gt;distance.matrix&lt;/code&gt; and &lt;code&gt;distance.thresholds&lt;/code&gt; are not provided In such case, the number of training cases is no longer limited by the size of the distance matrix, and models can be trained with hundreds of thousands of rows. In such case, the spatial autocorrelation of the model&amp;rsquo;s residuals is not assessed.&lt;/p&gt;
&lt;p&gt;However, &lt;strong&gt;when the focus is on fitting spatial models&lt;/strong&gt;, and due to the nature of the &lt;em&gt;spatial predictors&lt;/em&gt; used to represent the spatial structure of the training data, &lt;strong&gt;there are many things this package cannot do&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Predict model results over raster data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Predict a model result over another region with a different spatial structure.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Work with &amp;ldquo;big data&amp;rdquo;, whatever that means.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Imputation or extrapolation (it can be done, but models based on spatial predictors are hardly transferable).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Take temporal autocorrelation into account (but this is something that might be implemented later on).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If after considering these limitations you are still interested, follow me, I will show you how it works.&lt;/p&gt;
&lt;h1 id=&#34;citation&#34;&gt;Citation&lt;/h1&gt;
&lt;p&gt;There is a paper in the making about this package. In the meantime, if you find it useful for your academic work, please cite the &lt;code&gt;ranger&lt;/code&gt; package as well, it is the true core of &lt;code&gt;spatialRF&lt;/code&gt;!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Marvin N. Wright, Andreas Ziegler (2017). ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R. Journal of Statistical Software, 77(1), 1-17. doi:10.18637/jss.v077.i01&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Blas M. Benito (2021). spatialRF: Easy Spatial Regression with Random Forest. R package version 1.1.0. doi: 10.5281/zenodo.4745208. url: 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://blasbenito.github.io/spatialRF/&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;install&#34;&gt;Install&lt;/h1&gt;
&lt;p&gt;The version 1.1.3 can be installed from CRAN:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;spatialRF&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The package can also be installed from GitHub as follows. There are several branches in the repository:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;main&lt;/code&gt;: latest stable version (1.1.0 currently).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;development&lt;/code&gt;: development version, usually very broken.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;v.1.0.9&lt;/code&gt; to &lt;code&gt;v.1.1.2&lt;/code&gt;: archived versions.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;remotes::install_github(
  repo = &amp;quot;blasbenito/spatialRF&amp;quot;, 
  ref = &amp;quot;main&amp;quot;,
  force = TRUE,
  quiet = TRUE
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are a few other libraries that will be useful during this tutorial.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(spatialRF)
library(kableExtra)
library(rnaturalearth)
library(rnaturalearthdata)
library(tidyverse)
library(randomForestExplainer)
library(pdp)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;data-requirements&#34;&gt;Data requirements&lt;/h1&gt;
&lt;p&gt;The data required to fit random forest models with &lt;code&gt;spatialRF&lt;/code&gt; must fulfill several conditions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;The input format is data.frame&lt;/strong&gt;. At the moment, tibbles are not fully supported.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The number of rows must be somewhere between 100 and ~5000&lt;/strong&gt;, at least if your target is fitting spatial models. This limitation comes from the fact that the distance matrix grows very fast with an increasing number of training records, so for large datasets, there might not be enough RAM in your machine.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The number of predictors should be larger than 3&lt;/strong&gt;. Fitting a Random Forest model is moot otherwise.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Factors in the response or the predictors are not explicitly supported in the package&lt;/strong&gt;. They may work, or they won&amp;rsquo;t, but in any case, I designed this package for quantitative data alone. However, binary responses with values 0 and 1 are partially supported.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Must be free of &lt;code&gt;NA&lt;/code&gt;&lt;/strong&gt;. You can check if there are NA records with &lt;code&gt;sum(apply(df, 2, is.na))&lt;/code&gt;. If the result is larger than 0, then just execute &lt;code&gt;df &amp;lt;- na.omit(df)&lt;/code&gt; to remove rows with empty cells.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Columns cannot have zero variance&lt;/strong&gt;. This condition can be checked with &lt;code&gt;apply(df, 2, var) == 0&lt;/code&gt;. Columns yielding TRUE should be removed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Columns must not yield &lt;code&gt;NaN&lt;/code&gt; or &lt;code&gt;Inf&lt;/code&gt; when scaled&lt;/strong&gt;. You can check each condition with &lt;code&gt;sum(apply(scale(df), 2, is.nan))&lt;/code&gt; and &lt;code&gt;sum(apply(scale(df), 2, is.infinite))&lt;/code&gt;. If higher than 0, you can find what columns are giving issues with &lt;code&gt;sapply(as.data.frame(scale(df)), function(x)any(is.nan(x)))&lt;/code&gt; and &lt;code&gt;sapply(as.data.frame(scale(df)), function(x)any(is.infinite(x)))&lt;/code&gt;. Any column yielding &lt;code&gt;TRUE&lt;/code&gt; will generate issues while trying to fit models with &lt;code&gt;spatialRF&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;example-data&#34;&gt;Example data&lt;/h1&gt;
&lt;p&gt;The package includes an example dataset that fulfills the conditions mentioned above, named 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/plant_richness_df.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;plant_richness_df&lt;/code&gt;&lt;/a&gt;. It is a data frame with plant species richness and predictors for 227 ecoregions in the Americas, and a distance matrix among the ecoregion edges named, well, 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/distance_matrix.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;distance_matrix&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The package follows a convention throughout functions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The argument &lt;code&gt;data&lt;/code&gt; requires a training data frame.&lt;/li&gt;
&lt;li&gt;The argument &lt;code&gt;dependent.variable.name&lt;/code&gt; is the column name of the response variable.&lt;/li&gt;
&lt;li&gt;The argument &lt;code&gt;predictor.variable.names&lt;/code&gt; contains the column names of the predictors.&lt;/li&gt;
&lt;li&gt;The argument &lt;code&gt;xy&lt;/code&gt; takes a data frame or matrix with two columns named &amp;ldquo;x&amp;rdquo; and &amp;ldquo;y&amp;rdquo;, in that order, with the case coordinates.&lt;/li&gt;
&lt;li&gt;The argument &lt;code&gt;distance.matrix&lt;/code&gt; requires a matrix of distances between the cases in &lt;code&gt;data&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The argument &lt;code&gt;distance.thresholds&lt;/code&gt; is a numeric vector of distances at with spatial autocorrelation wants to be computed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is convenient to define these arguments at the beginning of the workflow.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#loading training data and distance matrix from the package
data(plant_richness_df)
data(distance_matrix)

#names of the response variable and the predictors
dependent.variable.name &amp;lt;- &amp;quot;richness_species_vascular&amp;quot;
predictor.variable.names &amp;lt;- colnames(plant_richness_df)[5:21]

#coordinates of the cases
xy &amp;lt;- plant_richness_df[, c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;)]

#distance matrix
distance.matrix &amp;lt;- distance_matrix

#distance thresholds (same units as distance_matrix)
distance.thresholds &amp;lt;- c(0, 1000, 2000, 4000, 8000)

#random seed for reproducibility
random.seed &amp;lt;- 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The response variable of &lt;code&gt;plant_richness_df&lt;/code&gt; is &amp;ldquo;richness_species_vascular&amp;rdquo;, that represents the total count of vascular plant species found on each ecoregion. The figure below shows the centroids of each ecoregion along with their associated value of the response variable.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;world &amp;lt;- rnaturalearth::ne_countries(
  scale = &amp;quot;medium&amp;quot;, 
  returnclass = &amp;quot;sf&amp;quot;
  )

ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = world, 
    fill = &amp;quot;white&amp;quot;
    ) +
  ggplot2::geom_point(
    data = plant_richness_df,
    ggplot2::aes(
      x = x,
      y = y,
      color = richness_species_vascular
    ),
    size = 2.5
  ) +
  ggplot2::scale_color_viridis_c(
    direction = -1, 
    option = &amp;quot;F&amp;quot;
    ) +
  ggplot2::theme_bw() +
  ggplot2::labs(color = &amp;quot;Plant richness&amp;quot;) +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 80))  +
  ggplot2::ggtitle(&amp;quot;Plant richness of the American ecoregions&amp;quot;) + 
  ggplot2::xlab(&amp;quot;Longitude&amp;quot;) + 
  ggplot2::ylab(&amp;quot;Latitude&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;576&#34; /&gt;
&lt;p&gt;The predictors (columns 5 to 21) represent diverse factors that may influence plant richness such as sampling bias, the area of the ecoregion, climatic variables, human presence and impact, topography, geographical fragmentation, and features of the neighbors of each ecoregion. The figure below shows the scatterplots of the response variable (y axis) against each predictor (x axis).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Every plotting function in the package now allows changing the colors of their main features via specific arguments such as &lt;code&gt;point.color&lt;/code&gt;, &lt;code&gt;line.color&lt;/code&gt;, or &lt;code&gt;fill.color&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::plot_training_df(
  data = plant_richness_df,
  dependent.variable.name = dependent.variable.name,
  predictor.variable.names = predictor.variable.names,
  ncol = 3,
  point.color = viridis::viridis(100, option = &amp;quot;F&amp;quot;),
  line.color = &amp;quot;gray30&amp;quot;
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;960&#34; /&gt;
&lt;p&gt;The function 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/plot_training_df_moran.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;plot_training_df_moran()&lt;/code&gt;&lt;/a&gt; helps assessing the spatial autocorrelation of the response variable and the predictors across different distance thresholds. Low Moran&amp;rsquo;s I and p-values equal or larger than 0.05 indicate that there is no spatial autocorrelation for the given variable and distance threshold.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::plot_training_df_moran(
  data = plant_richness_df,
  dependent.variable.name = dependent.variable.name,
  predictor.variable.names = predictor.variable.names,
  distance.matrix = distance.matrix,
  distance.thresholds = distance.thresholds,
  fill.color = viridis::viridis(
    100,
    option = &amp;quot;F&amp;quot;,
    direction = -1
    ),
  point.color = &amp;quot;gray40&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;768&#34; /&gt;
&lt;h1 id=&#34;reducing-multicollinearity-in-the-predictors&#34;&gt;Reducing multicollinearity in the predictors&lt;/h1&gt;
&lt;p&gt;The functions 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/auto_cor.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;auto_cor()&lt;/code&gt;&lt;/a&gt; and 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/auto_vif.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;auto_vif()&lt;/code&gt;&lt;/a&gt; help reduce redundancy in the predictors by using different criteria (bivariate R squared vs. 
&lt;a href=&#34;https://www.statisticshowto.com/variance-inflation-factor/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;variance inflation factor&lt;/a&gt;), while allowing the user to define an &lt;em&gt;order of preference&lt;/em&gt;, which can be based either on domain expertise or on a quantitative assessment (e.g., order of preference based on variable importance scores or model coefficients). The preference order is defined as a character vector in the &lt;code&gt;preference.order&lt;/code&gt; argument of both functions, and does not need to include the names of all predictors, but just the ones the user would like to keep in the analysis.&lt;/p&gt;
&lt;p&gt;Notice that I have set &lt;code&gt;cor.threshold&lt;/code&gt; and &lt;code&gt;vif.threshold&lt;/code&gt; to low values because the predictors in &lt;code&gt;plant_richness_df&lt;/code&gt; already have little multicollinearity,. The default values (&lt;code&gt;cor.threshold = 0.75&lt;/code&gt; and &lt;code&gt;vif.threshold = 5&lt;/code&gt;) should work well when combined together for any other set of predictors.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;preference.order &amp;lt;- c(
    &amp;quot;climate_bio1_average_X_bias_area_km2&amp;quot;,
    &amp;quot;climate_aridity_index_average&amp;quot;,
    &amp;quot;climate_hypervolume&amp;quot;,
    &amp;quot;climate_bio1_average&amp;quot;,
    &amp;quot;climate_bio15_minimum&amp;quot;,
    &amp;quot;bias_area_km2&amp;quot;
  )

predictor.variable.names &amp;lt;- spatialRF::auto_cor(
  x = plant_richness_df[, predictor.variable.names],
  cor.threshold = 0.6,
  preference.order = preference.order
) %&amp;gt;% 
  spatialRF::auto_vif(
    vif.threshold = 2.5,
    preference.order = preference.order
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [auto_cor()]: Removed variables: human_footprint_average
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [auto_vif()]: Variables are not collinear.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output of &lt;code&gt;auto_cor()&lt;/code&gt; or &lt;code&gt;auto_vif()&lt;/code&gt; has the class &amp;ldquo;variable_selection&amp;rdquo;, which can be used as input in every function having the argument &lt;code&gt;predictor.variable.names&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;names(predictor.variable.names)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;vif&amp;quot;                   &amp;quot;selected.variables&amp;quot;    &amp;quot;selected.variables.df&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The slot &lt;code&gt;selected.variables&lt;/code&gt; contains the names of the selected predictors.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;predictor.variable.names$selected.variables
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;climate_aridity_index_average&amp;quot;   &amp;quot;climate_hypervolume&amp;quot;            
##  [3] &amp;quot;climate_bio1_average&amp;quot;            &amp;quot;climate_bio15_minimum&amp;quot;          
##  [5] &amp;quot;bias_area_km2&amp;quot;                   &amp;quot;bias_species_per_record&amp;quot;        
##  [7] &amp;quot;climate_velocity_lgm_average&amp;quot;    &amp;quot;neighbors_count&amp;quot;                
##  [9] &amp;quot;neighbors_percent_shared_edge&amp;quot;   &amp;quot;human_population_density&amp;quot;       
## [11] &amp;quot;topography_elevation_average&amp;quot;    &amp;quot;landcover_herbs_percent_average&amp;quot;
## [13] &amp;quot;fragmentation_cohesion&amp;quot;          &amp;quot;fragmentation_division&amp;quot;         
## [15] &amp;quot;neighbors_area&amp;quot;                  &amp;quot;human_population&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;finding-promising-variable-interactions&#34;&gt;Finding promising variable interactions&lt;/h1&gt;
&lt;p&gt;Random Forests already takes into account variable interactions of the form &amp;ldquo;variable &lt;code&gt;a&lt;/code&gt; becomes important when &lt;code&gt;b&lt;/code&gt; is higher than x&amp;rdquo;. However, Random Forest can also take advantage of variable interactions of the form &lt;code&gt;a * b&lt;/code&gt;, across the complete ranges of the predictors, as they are commonly defined in regression models, and &amp;ldquo;interactions&amp;rdquo; (not the proper name, but used here for simplicity) represented by the first component of a PCA on the predictors &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The function 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/the_feature_engineer.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;the_feature_engineer()&lt;/code&gt;&lt;/a&gt; tests all possible interactions of both types among the most important predictors, and suggesting the ones not correlated among themselves and with the other predictors inducing an increase in the model&amp;rsquo;s R squared (or AUC when the response is binary) on independent data via spatial cross-validation (see &lt;code&gt;rf_evaluate()&lt;/code&gt;).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;interactions &amp;lt;- spatialRF::the_feature_engineer(
  data = plant_richness_df,
  dependent.variable.name = dependent.variable.name,
  predictor.variable.names = predictor.variable.names,
  xy = xy,
  importance.threshold = 0.50, #uses 50% best predictors
  cor.threshold = 0.60, #max corr between interactions and predictors
  seed = random.seed,
  repetitions = 100,
  verbose = TRUE
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Fitting and evaluating a model without interactions.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Testing 28 candidate interactions.
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Interactions identified: 5
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  ┌──────────────────┬──────────────────┬──────────────────┬──────────────────┐
##  │ Interaction      │ Importance (% of │        R-squared │     Max cor with │
##  │                  │             max) │      improvement │       predictors │
##  ├──────────────────┼──────────────────┼──────────────────┼──────────────────┤
##  │ bias_area_km2..x │             60.8 │            0.096 │            0.60  │
##  │ ..bias_species_p │                  │                  │                  │
##  │ er_record        │                  │                  │                  │
##  ├──────────────────┼──────────────────┼──────────────────┼──────────────────┤
##  │ climate_bio1_ave │             97.9 │            0.067 │            0.34  │
##  │ rage..pca..human │                  │                  │                  │
##  │ _population_dens │                  │                  │                  │
##  │ ity              │                  │                  │                  │
##  ├──────────────────┼──────────────────┼──────────────────┼──────────────────┤
##  │ climate_bio1_ave │             98.7 │            0.049 │            0.24  │
##  │ rage..pca..neigh │                  │                  │                  │
##  │ bors_count       │                  │                  │                  │
##  ├──────────────────┼──────────────────┼──────────────────┼──────────────────┤
##  │ human_population │             66.5 │            0.021 │            0.55  │
##  │ ..x..bias_specie │                  │                  │                  │
##  │ s_per_record     │                  │                  │                  │
##  ├──────────────────┼──────────────────┼──────────────────┼──────────────────┤
##  │ bias_area_km2..p │             62.7 │            0.029 │            0.305 │
##  │ ca..neighbors_pe │                  │                  │                  │
##  │ rcent_shared_edg │                  │                  │                  │
##  │ e                │                  │                  │                  │
##  └──────────────────┴──────────────────┴──────────────────┴──────────────────┘
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Comparing models with and without interactions via spatial cross-validation.
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;1248&#34; /&gt;
&lt;p&gt;The upper panel in the plot plot above shows the relationship between the interaction and the response variable. It also indicates the gain in R squared (+R2), the importance, in percentage, when used in a model along the other predictors (Imp. (%)), and the maximum Pearson correlation of the interaction with the predictors. The violin-plot shows a comparison of the model with and without the selected interaction made via spatial cross-validation using 100 repetitions (see 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/rf_evaluate.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;rf_evaluate()&lt;/code&gt;&lt;/a&gt; and 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/rf_compare.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;rf_compare()&lt;/code&gt;&lt;/a&gt; for further details).&lt;/p&gt;
&lt;p&gt;The function also returns a data frame with all the interactions considered.  The columns are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;interaction.name&lt;/code&gt;: Interactions computed via multiplication are named &lt;code&gt;a..x..b&lt;/code&gt;, while interactions computed via PCA are named &lt;code&gt;a..pca..b&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;interaction.importance&lt;/code&gt;: Importance of the interaction expressed as a percentage. If &lt;code&gt;interaction.importance == 100&lt;/code&gt;, that means that the interaction is the most important predictor in the model fitted with the interaction and the predictors named in &lt;code&gt;predictor.variable.names&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;interaction.metric.gain&lt;/code&gt;: Difference in R squared (or AUC for models fitting a binary response) between a model with and a model without the interaction.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max.cor.with.predictors&lt;/code&gt;: The maximum Pearson correlation of the interaction with the predictors named in &lt;code&gt;predictor.variable.names&lt;/code&gt;. Gives an idea of the amount of multicollinearity the interaction introduces in the model.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;variable.a.name&lt;/code&gt; and &lt;code&gt;variable.b.name&lt;/code&gt;: Names of the predictors involved in the interaction.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;selected&lt;/code&gt;: &lt;code&gt;TRUE&lt;/code&gt; if the interaction fulfills the selection criteria (importance higher than a threshold, positive gain in R squared or AUC, and Pearson correlation with other predictors lower than a threshold). The selected interactions have a correlation among themselves always lower than the value of the argument &lt;code&gt;cor.threshold&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;kableExtra::kbl(
  head(interactions$screening, 10),
  format = &amp;quot;html&amp;quot;
) %&amp;gt;%
  kableExtra::kable_paper(&amp;quot;hover&amp;quot;, full_width = F)
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34; lightable-paper lightable-hover&#34; style=&#39;color: black; font-family: &#34;Arial Narrow&#34;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;&#39;&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; interaction.name &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; interaction.importance &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; interaction.metric.gain &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; max.cor.with.predictors &lt;/th&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; variable.a.name &lt;/th&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; variable.b.name &lt;/th&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; selected &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_area_km2..x..bias_species_per_record &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 60.779 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.096 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.5962899 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_area_km2 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_species_per_record &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 97.944 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.067 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.3369664 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..neighbors_count &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 98.742 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.049 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.2441858 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; neighbors_count &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..neighbors_percent_shared_edge &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 84.196 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.066 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.2215337 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; neighbors_percent_shared_edge &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; human_population..x..bias_species_per_record &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 66.512 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.021 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.5462406 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; human_population &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_species_per_record &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..bias_species_per_record &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 70.082 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.018 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.3469834 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_species_per_record &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_area_km2..pca..neighbors_percent_shared_edge &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 62.678 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.029 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.3046471 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_area_km2 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; neighbors_percent_shared_edge &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_hypervolume..x..human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 49.367 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.006 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.5599486 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_hypervolume &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; FALSE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; neighbors_count..pca..neighbors_percent_shared_edge &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 63.808 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.016 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.1584006 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; neighbors_count &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; neighbors_percent_shared_edge &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_area_km2..pca..neighbors_count &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 58.662 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.012 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.2166191 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_area_km2 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; neighbors_count &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; TRUE &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The function returns a data frame with the response variables, the predictors, and the selected interactions that can be used right away as a training data frame. However, the function cannot say whether an interaction &lt;em&gt;makes sense&lt;/em&gt;, and it is up to the user to choose wisely whether to select an interaction or not. In this particular case, and just for the sake of simplicity, we will be using the resulting data frame as training data.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#adding interaction column to the training data
plant_richness_df &amp;lt;- interactions$data

#adding interaction name to predictor.variable.names
predictor.variable.names &amp;lt;- interactions$predictor.variable.names
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;fitting-a-non-spatial-random-forest-model-with-rf&#34;&gt;Fitting a non-spatial Random Forest model with &lt;code&gt;rf()&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;The function 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/rf.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;rf()&lt;/code&gt;&lt;/a&gt; is a convenient wrapper for &lt;code&gt;ranger::ranger()&lt;/code&gt; used in every modelling function of the &lt;em&gt;spatialRF&lt;/em&gt; package. It takes the training data, the names of the response and the predictors, and optionally (to assess the spatial autocorrelation of the residuals), the distance matrix, and a vector of distance thresholds (in the same units as the distances in &lt;strong&gt;distance_matrix&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;These distance thresholds are the neighborhoods at which the model will check the spatial autocorrelation of the residuals. Their values may depend on the spatial scale of the data, and the ecological system under study.&lt;/p&gt;
&lt;p&gt;Notice that here I plug the object &lt;code&gt;predictor.variable.names&lt;/code&gt;, output of &lt;code&gt;auto_cor()&lt;/code&gt; and &lt;code&gt;auto_vif()&lt;/code&gt;, directly into the &lt;code&gt;predictor.variable.names&lt;/code&gt; argument of the &lt;code&gt;rf()&lt;/code&gt; function to fit a random forest model.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model.non.spatial &amp;lt;- spatialRF::rf(
  data = plant_richness_df,
  dependent.variable.name = dependent.variable.name,
  predictor.variable.names = predictor.variable.names,
  distance.matrix = distance.matrix,
  distance.thresholds = distance.thresholds,
  xy = xy, #not needed by rf, but other functions read it from the model
  seed = random.seed,
  verbose = FALSE
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output is a list with several slots containing the information required to interpret the model. The information available in these slots can be plotted (functions named &lt;code&gt;plot_...()&lt;/code&gt;), printed to screen (&lt;code&gt;print_...()&lt;/code&gt;) and captured for further analyses (&lt;code&gt;get_...()&lt;/code&gt;).&lt;/p&gt;
&lt;h2 id=&#34;residuals&#34;&gt;Residuals&lt;/h2&gt;
&lt;p&gt;The slot &lt;strong&gt;residuals&lt;/strong&gt; (&lt;code&gt;model.non.spatial$residuals&lt;/code&gt;) stores the values of the residuals and the results of the normality and spatial autocorrelation tests, and its content can be plotted with 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/plot_residuals_diagnostics.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;plot_residuals_diagnostics()&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::plot_residuals_diagnostics(
  model.non.spatial,
  verbose = FALSE
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;576&#34; /&gt;
&lt;p&gt;The upper panels show the results of the normality test (interpretation in the title), the middle panel shows the relationship between the residuals and the fitted values, important to understand the behavior of the residuals, and the lower panel shows the Moran&amp;rsquo;s I of the residuals across distance thresholds and their respective p-values (positive for 0 and 1000 km).&lt;/p&gt;
&lt;h2 id=&#34;variable-importance&#34;&gt;Variable importance&lt;/h2&gt;
&lt;h3 id=&#34;global-variable-importance&#34;&gt;Global variable importance&lt;/h3&gt;
&lt;p&gt;The slot &lt;strong&gt;importance&lt;/strong&gt; (&lt;code&gt;model.non.spatial$variable.importance&lt;/code&gt;) contains the variable importance scores. These can be plotted with 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/plot_importance.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;plot_importance()&lt;/code&gt;&lt;/a&gt;, printed with 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/print_importance.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;print_importance()&lt;/code&gt;&lt;/a&gt;, and the dataframe retrieved with 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/get_importance.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;get_importance()&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::plot_importance(
  model.non.spatial,
  verbose = FALSE
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;576&#34; /&gt;
&lt;p&gt;Variable importance represents the increase in mean error (computed on the out-of-bag data) across trees when a predictor is permuted. Values lower than zero would indicate that the variable performs worse than a random one.&lt;/p&gt;
&lt;p&gt;If the argument &lt;code&gt;scaled.importance = TRUE&lt;/code&gt; is used, the variable importance scores are computed from the scaled data, making the importance scores easier to compare across different models.&lt;/p&gt;
&lt;p&gt;The package 
&lt;a href=&#34;https://github.com/ModelOriented/randomForestExplainer&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;randomForestExplainer&lt;/code&gt;&lt;/a&gt; offers a couple of interesting options to deepen our understanding on variable importance scores. The first one is &lt;code&gt;measure_importance()&lt;/code&gt;, which analyzes the forest to find out the average minimum tree depth at which each variable can be found (&lt;code&gt;mean_min_depth&lt;/code&gt;), the number of nodes in which a variable was selected to make a split (&lt;code&gt;no_of_nodes&lt;/code&gt;), the number of times the variable was selected as the first one to start a tree (&lt;code&gt;times_a_root&lt;/code&gt;), and the probability of a variable to be in more nodes than what it would be expected by chance (&lt;code&gt;p_value&lt;/code&gt;).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;importance.df &amp;lt;- randomForestExplainer::measure_importance(
  model.non.spatial,
  measures = c(&amp;quot;mean_min_depth&amp;quot;, &amp;quot;no_of_nodes&amp;quot;, &amp;quot;times_a_root&amp;quot;, &amp;quot;p_value&amp;quot;)
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;kableExtra::kbl(
  importance.df %&amp;gt;% 
    dplyr::arrange(mean_min_depth) %&amp;gt;% 
    dplyr::mutate(p_value = round(p_value, 4)),
  format = &amp;quot;html&amp;quot;
) %&amp;gt;%
  kableExtra::kable_paper(&amp;quot;hover&amp;quot;, full_width = F)
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34; lightable-paper lightable-hover&#34; style=&#39;color: black; font-family: &#34;Arial Narrow&#34;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;&#39;&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; variable &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; mean_min_depth &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; no_of_nodes &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; times_a_root &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; p_value &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..neighbors_count &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 2.811087 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 2098 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 86 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; human_population &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 2.989940 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 2222 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 51 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3.117996 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1979 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 57 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_hypervolume &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3.200133 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 2072 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 44 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3.201070 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1781 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 64 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.4909 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_area_km2..x..bias_species_per_record &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3.379787 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1797 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 46 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.3406 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3.454233 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1900 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 23 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0020 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_species_per_record &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3.564676 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 2321 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 2 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_area_km2..pca..neighbors_percent_shared_edge &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3.959485 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1712 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 33 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.9519 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; human_population..x..bias_species_per_record &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3.977952 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1780 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 32 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.5006 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_area_km2 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 4.186849 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1800 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 10 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.3144 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; neighbors_count &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 4.204326 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1325 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 29 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1.0000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; topography_elevation_average &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 4.306636 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1732 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.8795 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; neighbors_percent_shared_edge &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 4.409251 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1700 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 5 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.9749 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; neighbors_area &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 4.643590 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1621 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 2 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1.0000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; fragmentation_cohesion &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 4.770930 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1518 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 8 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1.0000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_velocity_lgm_average &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 4.845155 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1658 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.9986 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_aridity_index_average &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 4.858302 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1682 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.9919 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; landcover_herbs_percent_average &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 4.984346 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1656 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.9988 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio15_minimum &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 5.057002 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1552 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 2 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1.0000 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; fragmentation_division &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 5.229187 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1468 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1.0000 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;contribution-of-predictors-to-model-transferability&#34;&gt;Contribution of predictors to model transferability&lt;/h3&gt;
&lt;p&gt;The new function &lt;code&gt;rf_importance()&lt;/code&gt; offers a way to assess to what extent each predictor contributes to model transferability (predictive ability on independent spatial folds measured with &lt;code&gt;rf_evaluate()&lt;/code&gt;, see below). It does so by comparing the performance of the full model with models fitted without each one of the predictors. The difference in performance between the full model and a model without a given predictor represents the contribution of such predictor to model transferability.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model.non.spatial &amp;lt;- spatialRF::rf_importance(
  model = model.non.spatial
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;768&#34; /&gt;
&lt;p&gt;The function results are added to the &amp;ldquo;importance&amp;rdquo; slot of the model.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;names(model.non.spatial$importance)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;per.variable&amp;quot;          &amp;quot;local&amp;quot;                 &amp;quot;oob.per.variable.plot&amp;quot;
## [4] &amp;quot;cv.per.variable.plot&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data frame &amp;ldquo;per.variable&amp;rdquo; contains the columns &amp;ldquo;importance.cv&amp;rdquo; (median importance), &amp;ldquo;importance.cv.mad&amp;rdquo; (median absolute deviation), &amp;ldquo;importance.cv.percent&amp;rdquo; (median importance in percentage), and &amp;ldquo;importance.cv.percent.mad&amp;rdquo; (median absolute deviation of the importance in percent). The ggplot object &amp;ldquo;cv.per.variable.plot&amp;rdquo; contains the importance plot with the median and the median absolute deviation shown above.&lt;/p&gt;
&lt;p&gt;The importance computed by random forest on the out-of-bag data by permutating each predictor (as computed by &lt;code&gt;rf()&lt;/code&gt;) and the contribution of each predictor to model transferability (as computed by &lt;code&gt;rf_importance()&lt;/code&gt;) show a moderate correlation, indicating that both importance measures capture different aspects of the effect of the variables on the model results.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model.non.spatial$importance$per.variable %&amp;gt;% 
  ggplot2::ggplot() +
  ggplot2::aes(
    x = importance.oob,
    y = importance.cv
  ) + 
  ggplot2::geom_point(size = 3) + 
  ggplot2::theme_bw() +
  ggplot2::xlab(&amp;quot;Importance (out-of-bag)&amp;quot;) + 
  ggplot2::ylab(&amp;quot;Contribution to transferability&amp;quot;) + 
  ggplot2::geom_smooth(method = &amp;quot;lm&amp;quot;, formula = y ~ x, color = &amp;quot;red4&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;576&#34; /&gt;
&lt;h3 id=&#34;local-variable-importance&#34;&gt;Local variable importance&lt;/h3&gt;
&lt;p&gt;Random forest also computes the average increase in error when a variable is permuted for each case. This is named &amp;ldquo;local importance&amp;rdquo;, is stored in &lt;code&gt;model.non.spatial$importance$local&lt;/code&gt; as a data frame, and can be retrieved with 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/get_importance_local.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;get_importance_local()&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;local.importance &amp;lt;- spatialRF::get_importance_local(model.non.spatial)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The table below shows the first few records and columns. Larger values indicate larger average errors when estimating a case with the permuted version of the variable, so more important variables will show larger values.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;kableExtra::kbl(
  round(local.importance[1:10, 1:5], 0),
  format = &amp;quot;html&amp;quot;
) %&amp;gt;%
  kableExtra::kable_paper(&amp;quot;hover&amp;quot;, full_width = F)
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34; lightable-paper lightable-hover&#34; style=&#39;color: black; font-family: &#34;Arial Narrow&#34;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;&#39;&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; climate_aridity_index_average &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; climate_hypervolume &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; climate_bio1_average &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; climate_bio15_minimum &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; bias_area_km2 &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -120 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 705 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 214 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 231 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -274 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 502 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -400 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -431 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 375 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 470 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -182 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -155 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1152 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 46 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -75 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 384 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 769 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 704 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 5 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -538 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -399 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -706 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -669 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 350 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -711 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 248 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1113 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 715 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 483 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 475 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 195 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 705 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 513 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 286 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 332 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -247 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -629 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 506 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -332 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -125 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 335 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -519 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1016 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 95 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -246 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 275 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1154 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 429 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 71 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 234 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;When case coordinates are joined with the local importance scores, it is possible to draw maps showing how variable importance changes over space.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#adding coordinates
local.importance &amp;lt;- cbind(
  xy,
  local.importance
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#colors
color.low &amp;lt;- viridis::viridis(
    3,
    option = &amp;quot;F&amp;quot;
    )[2]
color.high &amp;lt;- viridis::viridis(
    3,
    option = &amp;quot;F&amp;quot;
    )[1]

#plot of climate_bio1_average
p1 &amp;lt;- ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = world,
    fill = &amp;quot;white&amp;quot;
  ) +
  ggplot2::geom_point(
    data = local.importance,
    ggplot2::aes(
      x = x,
      y = y,
      color = climate_bio1_average
    )
  ) +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 80)) +
  ggplot2::scale_color_gradient2(
    low = color.low, 
    high = color.high
    ) +
  ggplot2::theme_bw() +
  ggplot2::theme(legend.position = &amp;quot;bottom&amp;quot;) + 
  ggplot2::ggtitle(&amp;quot;climate_bio1_average&amp;quot;) +
  ggplot2::theme(
    plot.title = ggplot2::element_text(hjust = 0.5),
    legend.key.width = ggplot2::unit(1,&amp;quot;cm&amp;quot;)
    ) + 
  ggplot2::labs(color = &amp;quot;Importance&amp;quot;) + 
  ggplot2::xlab(&amp;quot;Longitude&amp;quot;) + 
  ggplot2::ylab(&amp;quot;Latitude&amp;quot;)

p2 &amp;lt;- ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = world,
    fill = &amp;quot;white&amp;quot;
  ) +
  ggplot2::geom_point(
    data = local.importance,
    ggplot2::aes(
      x = x,
      y = y,
      color = human_population
    )
  ) +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 80)) +
  ggplot2::scale_color_gradient2(
    low = color.low, 
    high = color.high
    ) +
  ggplot2::theme_bw() +
  ggplot2::theme(legend.position = &amp;quot;bottom&amp;quot;) +
  ggplot2::ggtitle(&amp;quot;human_population&amp;quot;) +
  ggplot2::theme(
    plot.title = ggplot2::element_text(hjust = 0.5),
    legend.key.width = ggplot2::unit(1,&amp;quot;cm&amp;quot;)
    ) + 
  ggplot2::labs(color = &amp;quot;Importance&amp;quot;) + 
  ggplot2::xlab(&amp;quot;Longitude&amp;quot;) + 
  ggplot2::ylab(&amp;quot;Latitude&amp;quot;)

p1 + p2
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;768&#34; /&gt;
&lt;p&gt;In these maps, values lower than 0 indicate that for a given record, the permuted version of the variable led to an accuracy score even higher than the one of the non-permuted variable, so again these negative values can be interpreted as &amp;ldquo;worse than chance&amp;rdquo;.&lt;/p&gt;
&lt;h2 id=&#34;response-curves-and-surfaces&#34;&gt;Response curves and surfaces&lt;/h2&gt;
&lt;p&gt;The variable importance scores are also used by the function 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/plot_response_curves.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;plot_response_curves()&lt;/code&gt;&lt;/a&gt; to plot partial dependence curves for the predictors (by default, only the ones with an importance score above the median). Building the partial dependency curve of a predictor requires setting the other predictors to their quantiles (0.1, 0.5, and 0.9 by default). This helps to understand how the response curve of a variable changes when all the other variables have low, centered, or high values. The function also allows to see the training data&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::plot_response_curves(
  model.non.spatial,
  quantiles = c(0.1, 0.5, 0.9),
  line.color = viridis::viridis(
    3, #same number of colors as quantiles
    option = &amp;quot;F&amp;quot;, 
    end = 0.9
    ),
  ncol = 3,
  show.data = TRUE
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;864&#34; /&gt;
&lt;p&gt;Setting the argument &lt;code&gt;quantiles&lt;/code&gt; to 0.5 and setting &lt;code&gt;show.data&lt;/code&gt; to &lt;code&gt;FALSE&lt;/code&gt; (default optioin) accentuates the shape of the response curves.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::plot_response_curves(
  model.non.spatial,
  quantiles = 0.5,
  ncol = 3
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;864&#34; /&gt;
&lt;p&gt;The package 
&lt;a href=&#34;https://bgreenwell.github.io/pdp/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;pdp&lt;/code&gt;&lt;/a&gt; provides a general way to plot partial dependence plots.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pdp::partial(
  model.non.spatial, 
  train = plant_richness_df, 
  pred.var = &amp;quot;climate_bio1_average&amp;quot;, 
  plot = TRUE, 
  grid.resolution = 200
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-29-1.png&#34; width=&#34;384&#34; /&gt;
&lt;p&gt;If you need to do your own plots in a different way, the function 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/get_response_curves.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;get_response_curves()&lt;/code&gt;&lt;/a&gt; returns a data frame with the required data.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;reponse.curves.df &amp;lt;- spatialRF::get_response_curves(model.non.spatial)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;kableExtra::kbl(
  head(reponse.curves.df, n = 10),
  format = &amp;quot;html&amp;quot;
) %&amp;gt;%
  kableExtra::kable_paper(&amp;quot;hover&amp;quot;, full_width = F)
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34; lightable-paper lightable-hover&#34; style=&#39;color: black; font-family: &#34;Arial Narrow&#34;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;&#39;&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; response &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; predictor &lt;/th&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; quantile &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; model &lt;/th&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; predictor.name &lt;/th&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; response.name &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3081.941 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -4.428994 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0.1 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; richness_species_vascular &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3081.941 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -4.393562 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0.1 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; richness_species_vascular &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3081.941 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -4.358129 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0.1 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; richness_species_vascular &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3081.941 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -4.322697 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0.1 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; richness_species_vascular &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3081.941 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -4.287265 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0.1 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; richness_species_vascular &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3081.941 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -4.251833 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0.1 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; richness_species_vascular &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3081.941 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -4.216400 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0.1 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; richness_species_vascular &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3081.941 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -4.180968 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0.1 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; richness_species_vascular &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3081.941 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -4.145536 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0.1 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; richness_species_vascular &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 3081.941 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -4.110104 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; 0.1 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1 &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; richness_species_vascular &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Interactions between two variables can be plotted with 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/plot_response_surface.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;plot_response_surface()&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::plot_response_surface(
  model.non.spatial,
  a = &amp;quot;climate_bio1_average&amp;quot;,
  b = &amp;quot;neighbors_count&amp;quot;
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-32-1.png&#34; width=&#34;432&#34; /&gt;
&lt;p&gt;This can be done as well with the &lt;code&gt;pdp&lt;/code&gt; package, that uses a slightly different algorithm to plot interaction surfaces.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pdp::partial(
  model.non.spatial, 
  train = plant_richness_df, 
  pred.var = c(&amp;quot;climate_bio1_average&amp;quot;, &amp;quot;neighbors_count&amp;quot;), 
  plot = TRUE
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-33-1.png&#34; width=&#34;432&#34; /&gt;
&lt;h2 id=&#34;model-performance&#34;&gt;Model performance&lt;/h2&gt;
&lt;p&gt;The &lt;strong&gt;performance&lt;/strong&gt; slot (in &lt;code&gt;model.non.spatial$performance&lt;/code&gt;) contains the values of several performance measures. It be printed via the function 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/print_performance.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;print_performance()&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::print_performance(model.non.spatial)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model performance 
##   - R squared (oob):                  0.6075314
##   - R squared (cor(obs, pred)^2):     0.9543769
##   - Pseudo R squared (cor(obs, pred)):0.9769221
##   - RMSE (oob):                       2111.241
##   - RMSE:                             902.1424
##   - Normalized RMSE:                  0.2604337
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;R squared (oob)&lt;/code&gt; and &lt;code&gt;RMSE (oob)&lt;/code&gt; are the R squared of the model and its root mean squared error when predicting the out-of-bag data (fraction of data not used to train individual trees). From all the values available in the &lt;code&gt;performance&lt;/code&gt; slot, probably these the most honest ones, as it is the closer trying to get a performance estimate on independent data. However, out-of-bag data is not fully independent, and therefore will still be inflated, especially if the data is highly aggregated in space.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;R squared&lt;/code&gt; and &lt;code&gt;pseudo R squared&lt;/code&gt; are computed from the observations and the predictions, and indicate to what extent model outcomes represent the input data. These values will usually be high the data is highly aggregated in space.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;RMSE&lt;/code&gt; and its normalized version are computed via 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/root_mean_squared_error.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;root_mean_squared_error()&lt;/code&gt;&lt;/a&gt;, and are linear with &lt;code&gt;R squared&lt;/code&gt; and &lt;code&gt;pseudo R squared&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spatial-cross-validation&#34;&gt;Spatial cross-validation&lt;/h2&gt;
&lt;p&gt;The function 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/rf_evaluate.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;rf_evaluate()&lt;/a&gt; overcomes the limitations of the performance scores explained above by providing honest performance based on &lt;em&gt;spatial cross-validation&lt;/em&gt;. The function separates the data into a number of spatially independent training and testing folds. Then, it fits a model on each training fold, predicts over each testing fold, and computes statistics of performance measures across folds. Let&amp;rsquo;s see how it works.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model.non.spatial &amp;lt;- spatialRF::rf_evaluate(
  model = model.non.spatial,
  xy = xy,                  #data coordinates
  repetitions = 30,         #number of spatial folds
  training.fraction = 0.75, #training data fraction on each fold
  metrics = &amp;quot;r.squared&amp;quot;,
  seed = random.seed,
  verbose = FALSE
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function generates a new slot in the model named &lt;strong&gt;evaluation&lt;/strong&gt; (&lt;code&gt;model.non.spatial$evaluation&lt;/code&gt;) with several objects that summarize the spatial cross-validation results.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;names(model.non.spatial$evaluation)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;metrics&amp;quot;           &amp;quot;training.fraction&amp;quot; &amp;quot;spatial.folds&amp;quot;    
## [4] &amp;quot;per.fold&amp;quot;          &amp;quot;per.fold.long&amp;quot;     &amp;quot;per.model&amp;quot;        
## [7] &amp;quot;aggregated&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The slot &amp;ldquo;spatial.folds&amp;rdquo;, produced by 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/make_spatial_folds.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;make_spatial_folds()&lt;/code&gt;&lt;/a&gt;, contains the indices of the training and testing cases for each cross-validation repetition. The maps below show two sets of training and testing folds.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;pr &amp;lt;- plant_richness_df[, c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;)]
pr$group.2 &amp;lt;- pr$group.1 &amp;lt;- &amp;quot;Training&amp;quot;
pr[model.non.spatial$evaluation$spatial.folds[[1]]$testing, &amp;quot;group.1&amp;quot;] &amp;lt;- &amp;quot;Testing&amp;quot;
pr[model.non.spatial$evaluation$spatial.folds[[25]]$testing, &amp;quot;group.2&amp;quot;] &amp;lt;- &amp;quot;Testing&amp;quot;

p1 &amp;lt;- ggplot2::ggplot() +
  ggplot2::geom_sf(data = world, fill = &amp;quot;white&amp;quot;) +
  ggplot2::geom_point(data = pr,
          ggplot2::aes(
            x = x,
            y = y,
            color = group.1
            ),
          size = 2
          ) +
  ggplot2::scale_color_viridis_d(
    direction = -1, 
    end = 0.5, 
    alpha = 0.8, 
    option = &amp;quot;F&amp;quot;
    ) +
  ggplot2::theme_bw() +
  ggplot2::labs(color = &amp;quot;Group&amp;quot;) +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 80))  +
  ggplot2::ggtitle(&amp;quot;Spatial fold 1&amp;quot;) + 
  ggplot2::theme(
    legend.position = &amp;quot;none&amp;quot;, 
    plot.title = ggplot2::element_text(hjust = 0.5)
  ) + 
  ggplot2::xlab(&amp;quot;Longitude&amp;quot;) + 
  ggplot2::ylab(&amp;quot;Latitude&amp;quot;)

p2 &amp;lt;- ggplot2::ggplot() +
  ggplot2::geom_sf(data = world, fill = &amp;quot;white&amp;quot;) +
  ggplot2::geom_point(data = pr,
          ggplot2::aes(
            x = x,
            y = y,
            color = group.2
            ),
          size = 2
          ) +
  ggplot2::scale_color_viridis_d(
    direction = -1, 
    end = 0.5, 
    alpha = 0.8, 
    option = &amp;quot;F&amp;quot;
    ) +
  ggplot2::theme_bw() +
  ggplot2::labs(color = &amp;quot;Group&amp;quot;) +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 80)) +
  ggplot2::theme(
    plot.title = ggplot2::element_text(hjust = 0.5)
  ) + 
  ggplot2::ggtitle(&amp;quot;Spatial fold 25&amp;quot;) + 
  ggplot2::xlab(&amp;quot;Longitude&amp;quot;) + 
  ggplot2::ylab(&amp;quot;&amp;quot;)

p1 | p2
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-37-1.png&#34; width=&#34;960&#34; /&gt;
&lt;p&gt;The information available in this new slot can be accessed with the functions 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/print_evaluation.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;print_evaluation()&lt;/code&gt;&lt;/a&gt;, 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/plot_evaluation.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;plot_evaluation()&lt;/code&gt;&lt;/a&gt;, and 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/get_evaluation.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;get_evaluation()&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::plot_evaluation(model.non.spatial)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-38-1.png&#34; width=&#34;432&#34; /&gt;
&lt;p&gt;&lt;code&gt;Full&lt;/code&gt; represents the R squared of the model trained on the full dataset. &lt;code&gt;Training&lt;/code&gt; are the R-squared of the models fitted on the spatial folds (named &lt;code&gt;Training&lt;/code&gt; in the maps above), and &lt;code&gt;Testing&lt;/code&gt; are the R-squared of the same models on &amp;ldquo;unseen&amp;rdquo; data (data not used to train the model, named &lt;code&gt;Testing&lt;/code&gt; in the maps above). The median, median absolute deviation (MAD), minimum, and maximum R-squared values on the testing folds can be printed with &lt;code&gt;print_evaluation()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::print_evaluation(model.non.spatial)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Spatial evaluation 
##   - Training fraction:             0.75
##   - Spatial folds:                 29
## 
##     Metric Median   MAD Minimum Maximum
##  r.squared  0.517 0.085   0.122   0.781
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;other-important-things-stored-in-the-model&#34;&gt;Other important things stored in the model&lt;/h2&gt;
&lt;p&gt;The model predictions are stored in the slot &lt;strong&gt;predictions&lt;/strong&gt;, the arguments used to fit the model in &lt;strong&gt;ranger.arguments&lt;/strong&gt;, and the model itself, used to predict new values (see code chunk below), is in the &lt;strong&gt;forest&lt;/strong&gt; slot.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;predicted &amp;lt;- stats::predict(
  object = model.non.spatial,
  data = plant_richness_df,
  type = &amp;quot;response&amp;quot;
  )$predictions
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;fitting-a-spatial-model-with-rf_spatial&#34;&gt;Fitting a spatial model with &lt;code&gt;rf_spatial()&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;The spatial autocorrelation of the residuals of a model like &lt;code&gt;model.non.spatial&lt;/code&gt;, measured with 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Moran%27s_I&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Moran&amp;rsquo;s I&lt;/a&gt;, can be plotted with 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/plot_moran.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;plot_moran()&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::plot_moran(
  model.non.spatial, 
  verbose = FALSE
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-41-1.png&#34; width=&#34;384&#34; /&gt;
According to the plot, the spatial autocorrelation of the residuals of `model.non.spatial` is highly positive for a neighborhood of 0 and 1000 km, while it becomes non-significant (p-value \&gt; 0.05) at 2000, 4000, and 8000 km. To reduce the spatial autocorrelation of the residuals as much as possible, the non-spatial model can be transformed into a *spatial model* very easily with the function [`rf_spatial()`](https://blasbenito.github.io/spatialRF/reference/rf_spatial.html). This function is the true core of the package!
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model.spatial &amp;lt;- spatialRF::rf_spatial(
  model = model.non.spatial,
  method = &amp;quot;mem.moran.sequential&amp;quot;, #default method
  verbose = FALSE,
  seed = random.seed
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The plot below shows the Moran&amp;rsquo;s I of the residuals of the spatial model, and indicates that the residuals are not autocorrelated at any distance.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::plot_moran(
  model.spatial, 
  verbose = FALSE
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-43-1.png&#34; width=&#34;384&#34; /&gt;
&lt;p&gt;If we compare the variable importance plots of both models, we can see that the spatial model has an additional set of dots under the name &amp;ldquo;spatial_predictors&amp;rdquo;, and that the maximum importance of a few of these &lt;em&gt;spatial predictors&lt;/em&gt; matches the importance of the most relevant non-spatial predictors.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;p1 &amp;lt;- spatialRF::plot_importance(
  model.non.spatial, 
  verbose = FALSE) + 
  ggplot2::ggtitle(&amp;quot;Non-spatial model&amp;quot;) 

p2 &amp;lt;- spatialRF::plot_importance(
  model.spatial,
  verbose = FALSE) + 
  ggplot2::ggtitle(&amp;quot;Spatial model&amp;quot;)

p1 | p2 
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-44-1.png&#34; width=&#34;960&#34; /&gt;
&lt;p&gt;If we look at the ten most important variables in &lt;code&gt;model.spatial&lt;/code&gt; we will see that a few of them are &lt;em&gt;spatial predictors&lt;/em&gt;. Spatial predictors are named &lt;code&gt;spatial_predictor_X_Y&lt;/code&gt;, where &lt;code&gt;X&lt;/code&gt; is the neighborhood distance at which the predictor has been generated, and &lt;code&gt;Y&lt;/code&gt; is the index of the predictor.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;kableExtra::kbl(
  head(model.spatial$importance$per.variable, n = 10),
  format = &amp;quot;html&amp;quot;
) %&amp;gt;%
  kableExtra::kable_paper(&amp;quot;hover&amp;quot;, full_width = F)
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34; lightable-paper lightable-hover&#34; style=&#39;color: black; font-family: &#34;Arial Narrow&#34;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;&#39;&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; variable &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; importance &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..neighbors_count &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1094.792 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_hypervolume &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1067.111 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; spatial_predictor_0_2 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 1035.365 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; human_population &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 997.965 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 973.243 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_area_km2..pca..neighbors_percent_shared_edge &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 902.209 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; climate_bio1_average..pca..human_population_density &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 882.910 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; spatial_predictor_0_1 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 815.656 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_area_km2 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 750.278 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; bias_species_per_record &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 712.031 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;But what are spatial predictors? Spatial predictors, as shown below, are smooth surfaces representing neighborhood among records at different spatial scales. They are computed from the distance matrix in different ways. The ones below are the eigenvectors of the double-centered distance matrix of weights (a.k.a, Moran&amp;rsquo;s Eigenvector Maps). They represent the effect of spatial proximity among records, helping to represent biogeographic and spatial processes not considered by the non-spatial predictors.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatial.predictors &amp;lt;- spatialRF::get_spatial_predictors(model.spatial)
pr &amp;lt;- data.frame(spatial.predictors, plant_richness_df[, c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;)])

p1 &amp;lt;- ggplot2::ggplot() +
  ggplot2::geom_sf(data = world, fill = &amp;quot;white&amp;quot;) +
  ggplot2::geom_point(
    data = pr,
    ggplot2::aes(
      x = x,
      y = y,
      color = spatial_predictor_0_2
    ),
    size = 2.5
  ) +
  ggplot2::scale_color_viridis_c(option = &amp;quot;F&amp;quot;) +
  ggplot2::theme_bw() +
  ggplot2::labs(color = &amp;quot;Eigenvalue&amp;quot;) +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 80))  +
  ggplot2::ggtitle(&amp;quot;Variable: spatial_predictor_0_2&amp;quot;) + 
  ggplot2::theme(legend.position = &amp;quot;bottom&amp;quot;)+ 
  ggplot2::xlab(&amp;quot;Longitude&amp;quot;) + 
  ggplot2::ylab(&amp;quot;Latitude&amp;quot;)

p2 &amp;lt;- ggplot2::ggplot() +
  ggplot2::geom_sf(data = world, fill = &amp;quot;white&amp;quot;) +
  ggplot2::geom_point(
    data = pr,
    ggplot2::aes(
      x = x,
      y = y,
      color = spatial_predictor_0_5,
    ),
    size = 2.5
  ) +
  ggplot2::scale_color_viridis_c(option = &amp;quot;F&amp;quot;) +
  ggplot2::theme_bw() +
  ggplot2::labs(color = &amp;quot;Eigenvalue&amp;quot;) +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 80))  +
  ggplot2::ggtitle(&amp;quot;Variable: spatial_predictor_0_5&amp;quot;) + 
  ggplot2::theme(legend.position = &amp;quot;bottom&amp;quot;) + 
  ggplot2::xlab(&amp;quot;Longitude&amp;quot;) + 
  ggplot2::ylab(&amp;quot;&amp;quot;)

p1 | p2
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-46-1.png&#34; width=&#34;1152&#34; /&gt;
&lt;p&gt;The spatial predictors are included in the model one by one, in the order of their Moran&amp;rsquo;s I (spatial predictors with Moran&amp;rsquo;s I lower than 0 are removed). The selection procedure is performed by the function 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/select_spatial_predictors_sequential.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;select_spatial_predictors_sequential()&lt;/code&gt;&lt;/a&gt;, which finds the smaller subset of spatial predictors maximizing the model&amp;rsquo;s R squared, and minimizing the Moran&amp;rsquo;s I of the residuals. This is shown in the optimization plot below (dots linked by lines represent the selected spatial predictors).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;p &amp;lt;- spatialRF::plot_optimization(model.spatial)
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-47-1.png&#34; width=&#34;576&#34; /&gt;
&lt;h1 id=&#34;tuning-random-forest-hyperparameters&#34;&gt;Tuning Random Forest hyperparameters&lt;/h1&gt;
&lt;p&gt;The model fitted above was based on the default random forest hyperparameters of &lt;code&gt;ranger()&lt;/code&gt;, and those might not be the most adequate ones for a given dataset. The function 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/rf_tuning.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;rf_tuning()&lt;/code&gt;&lt;/a&gt; helps the user to choose sensible values for three Random Forest hyperparameters that are critical to model performance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;num.trees&lt;/code&gt;: number of regression trees in the forest.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mtry&lt;/code&gt;: number of variables to choose from on each tree split.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;min.node.size&lt;/code&gt;: minimum number of cases on a terminal node.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These values can be modified in any model fitted with the package using the &lt;code&gt;ranger.arguments&lt;/code&gt; argument. The example below shows how to fit a spatial model with a given set of hyperparameters.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model.spatial &amp;lt;- spatialRF::rf_spatial(
  model = model.non.spatial,
  method = &amp;quot;mem.moran.sequential&amp;quot;, #default method
  ranger.arguments = list(
    mtry = 5,
    min.node.size = 20,
    num.trees = 1000
  ),
  verbose = FALSE,
  seed = random.seed
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The usual method for model tuning relies on a grid search exploring the results of all the combinations of hyperparameters selected by the user. In &lt;code&gt;spatialRF&lt;/code&gt;,
model tuning is done via spatial cross-validation, to ensure that the selected combination of hyperparameters maximizes the ability of the model to predict over data not used to train it. &lt;strong&gt;Warning&lt;/strong&gt;: model tuning consumes a lot of computational resources, using it on large datasets might freeze your computer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: model tunning is very RAM-hungry, but you can control RAM usage by defining a lower value for the argument &lt;code&gt;n.cores&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model.spatial &amp;lt;- rf_tuning(
  model = model.spatial,
  xy = xy,
  repetitions = 30,
  num.trees = c(500, 1000),
  mtry = seq(
    2,
    length(model.spatial$ranger.arguments$predictor.variable.names), #number of predictors
    by = 9),
  min.node.size = c(5, 15),
  seed = random.seed,
  verbose = FALSE
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function returns a tuned model only if the tuning finds a solution better than the original model. Otherwise the original model is returned. The results of the tuning are stored in the model under the name &amp;ldquo;tuning&amp;rdquo;.&lt;/p&gt;
&lt;h1 id=&#34;repeating-a-model-execution&#34;&gt;Repeating a model execution&lt;/h1&gt;
&lt;p&gt;Random Forest is an stochastic algorithm that yields slightly different results on each run unless a random seed is set. This particularity has implications for the interpretation of variable importance scores and response curves. The function 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/rf_repeat.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;rf_repeat()&lt;/code&gt;&lt;/a&gt; repeats a model execution and yields the distribution of importance scores of the predictors across executions. &lt;strong&gt;NOTE&lt;/strong&gt;: this function works better when used at the end of a workflow&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model.spatial.repeat &amp;lt;- spatialRF::rf_repeat(
  model = model.spatial, 
  repetitions = 30,
  seed = random.seed,
  verbose = FALSE
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The importance scores of a model fitted with &lt;code&gt;rf_repeat()&lt;/code&gt; are plotted as a violin plot, with the distribution of the importance scores of each predictor across repetitions.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::plot_importance(
  model.spatial.repeat, 
  verbose = FALSE
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-51-1.png&#34; width=&#34;576&#34; /&gt;
&lt;p&gt;The response curves of models fitted with &lt;code&gt;rf_repeat()&lt;/code&gt; can be plotted with &lt;code&gt;plot_response_curves()&lt;/code&gt; as well. The median prediction is shown with a thicker line.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::plot_response_curves(
  model.spatial.repeat, 
  quantiles = 0.5,
  ncol = 3
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-52-1.png&#34; width=&#34;864&#34; /&gt;
&lt;p&gt;The function &lt;code&gt;print_performance()&lt;/code&gt; generates a summary of the performance scores across model repetitions. As every other function of the package involving repetitions, the provided stats are the median, and the median absolute deviation (mad).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;spatialRF::print_performance(model.spatial.repeat)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model performance (median +/- mad) 
##   - R squared (oob):              0.593 +/- 0.0098
##   - R squared (cor(obs, pred)^2): 0.957 +/- 0.0016
##   - Pseudo R squared:             0.978 +/- 8e-04
##   - RMSE (oob):                   2151.154 +/- 25.7818
##   - RMSE:                         914.973 +/- 15.5809
##   - Normalized RMSE:              0.264 +/- 0.0045
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;taking-advantage-of-the---pipe&#34;&gt;Taking advantage of the &lt;code&gt; %&amp;gt;%&lt;/code&gt; pipe&lt;/h1&gt;
&lt;p&gt;The modeling functions of &lt;code&gt;spatialRF&lt;/code&gt; are designed to facilitate using the pipe to combine them. The code below fits a spatial model, tunes its hyperparameters, evaluates it using spatial cross-validation, and repeats the execution several times, just by passing the model from one function to another. Replace &lt;code&gt;eval = FALSE&lt;/code&gt; with &lt;code&gt;eval = TRUE&lt;/code&gt; if you want to execute the code chunk.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model.full &amp;lt;- rf_spatial(
  data = plant_richness_df,
  dependent.variable.name = dependent.variable.name,
  predictor.variable.names = predictor.variable.names,
  distance.matrix = distance_matrix,
  distance.thresholds = distance.thresholds,
  xy = xy
) %&amp;gt;%
  rf_tuning() %&amp;gt;%
  rf_evaluate() %&amp;gt;%
  rf_repeat()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code structure shown above can also be used to take advantage of a custom cluster, either defined in the local host, or a Beowulf cluster.&lt;/p&gt;
&lt;p&gt;When working with a single machine, a cluster can be defined and used as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#creating and registering the cluster
local.cluster &amp;lt;- parallel::makeCluster(
  parallel::detectCores() - 1,
  type = &amp;quot;PSOCK&amp;quot;
)
doParallel::registerDoParallel(cl = local.cluster)

#fitting, tuning, evaluating, and repeating a model
model.full &amp;lt;- rf_spatial(
  data = plant_richness_df,
  dependent.variable.name = dependent.variable.name,
  predictor.variable.names = predictor.variable.names,
  distance.matrix = distance_matrix,
  distance.thresholds = distance.thresholds,
  xy = xy,
  cluster = local.cluster #is passed via pipe to the other functions
) %&amp;gt;%
  rf_tuning() %&amp;gt;%
  rf_evaluate() %&amp;gt;%
  rf_repeat()

#stopping the cluster
parallel::stopCluster(cl = local.cluster)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To facilitate working with Beowulf clusters (
&lt;a href=&#34;https://www.blasbenito.com/post/01_home_cluster/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;just several computers connected via SSH&lt;/a&gt;), the package provides the function &lt;code&gt;beowulf_cluster()&lt;/code&gt;, that generates the cluster definition from details such as the IPs of the machines, the number of cores to be used on each machine, the user name, and the connection port.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#creating and registering the cluster
beowulf.cluster &amp;lt;- beowulf_cluster(
  cluster.ips = c(
    &amp;quot;10.42.0.1&amp;quot;,
    &amp;quot;10.42.0.34&amp;quot;,
    &amp;quot;10.42.0.104&amp;quot;
  ),
  cluster.cores = c(7, 4, 4),
  cluster.user = &amp;quot;blas&amp;quot;,
  cluster.port = &amp;quot;11000&amp;quot;
)

#fitting, tuning, evaluating, and repeating a model
model.full &amp;lt;- rf_spatial(
  data = plant_richness_df,
  dependent.variable.name = dependent.variable.name,
  predictor.variable.names = predictor.variable.names,
  distance.matrix = distance_matrix,
  distance.thresholds = distance.thresholds,
  xy = xy,
  cluster = beowulf.cluster 
) %&amp;gt;%
  rf_tuning() %&amp;gt;%
  rf_evaluate() %&amp;gt;%
  rf_repeat()

doParallel::registerDoParallel(cl = beowulf.cluster)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;comparing-several-models&#34;&gt;Comparing several models&lt;/h1&gt;
&lt;p&gt;The function 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/rf_compare.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;rf_compare()&lt;/code&gt;&lt;/a&gt; takes named list with as many models as the user needs to compare, and applies &lt;code&gt;rf_evaluate()&lt;/code&gt; to each one of them to compare their predictive performances across spatial folds.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;comparison &amp;lt;- spatialRF::rf_compare(
  models = list(
    `Non-spatial` = model.non.spatial,
    `Spatial` = model.spatial
  ),
  xy = xy,
  repetitions = 30,
  training.fraction = 0.8,
  metrics = &amp;quot;r.squared&amp;quot;,
  seed = random.seed
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-57-1.png&#34; width=&#34;576&#34; /&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x &amp;lt;- comparison$comparison.df %&amp;gt;% 
    dplyr::group_by(model, metric) %&amp;gt;% 
    dplyr::summarise(value = round(median(value), 3)) %&amp;gt;% 
    dplyr::arrange(metric) %&amp;gt;% 
    as.data.frame()
colnames(x) &amp;lt;- c(&amp;quot;Model&amp;quot;, &amp;quot;Metric&amp;quot;, &amp;quot;Median&amp;quot;)
kableExtra::kbl(
  x,
  format = &amp;quot;html&amp;quot;
  ) %&amp;gt;%
  kableExtra::kable_paper(&amp;quot;hover&amp;quot;, full_width = F)
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34; lightable-paper lightable-hover&#34; style=&#39;color: black; font-family: &#34;Arial Narrow&#34;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;&#39;&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; Model &lt;/th&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; Metric &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; Median &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Non-spatial &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; r.squared &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.494 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Spatial &lt;/td&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; r.squared &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.305 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h1 id=&#34;working-with-a-binomial-response&#34;&gt;Working with a binomial response&lt;/h1&gt;
&lt;p&gt;This package can also perform binomial regression on response variables with zeros and ones. Let&amp;rsquo;s work on a quick example by turning the response variable of the previous models into a binomial one.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;plant_richness_df$response_binomial &amp;lt;- ifelse(
  plant_richness_df$richness_species_vascular &amp;gt; 5000,
  1,
  0
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new response variable, &lt;code&gt;response_binomial&lt;/code&gt;, will have ones where &lt;code&gt;richness_species_vascular &amp;gt; 5000&lt;/code&gt;, and zeros otherwise. This would be equivalent to having the classes &amp;ldquo;high richness&amp;rdquo; (represented by the ones) and &amp;ldquo;low richness&amp;rdquo;, represented by the zeros. The binomial regression model would then have as objective to compute the probability of each ecoregion to belong to the &amp;ldquo;high richness&amp;rdquo; class.&lt;/p&gt;
&lt;p&gt;There is something important to notice before moving forward though. The number of zeros in the new response variable is larger than the number of ones.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;table(plant_richness_df$response_binomial)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##   0   1 
## 165  62
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This means that there is &lt;strong&gt;class imbalance&lt;/strong&gt;, and under this scenario, any random forest model is going to get better at predicting the most abundant class, while in our case the &amp;ldquo;target&amp;rdquo; is the less abundant one. But the function &lt;code&gt;rf()&lt;/code&gt; is ready to deal with this issue. Let&amp;rsquo;s fit a model to see what am I talking about.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model.non.spatial &amp;lt;- spatialRF::rf(
  data = plant_richness_df,
  dependent.variable.name = &amp;quot;response_binomial&amp;quot;,
  predictor.variable.names = predictor.variable.names,
  distance.matrix = distance.matrix,
  distance.thresholds = distance.thresholds,
  seed = random.seed,
  verbose = FALSE
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function detects that the response variable is binary (using the function 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/is_binary.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;is_binary()&lt;/code&gt;&lt;/a&gt;), and computes &lt;em&gt;case weights&lt;/em&gt; for the ones and the zeros. These case weights are stored in the &lt;code&gt;ranger.arguments&lt;/code&gt; slot of the model, and are used to give preference to the cases with larger weights during the selection of the out-of-bag data (check the &lt;code&gt;case.weights&lt;/code&gt; argument in &lt;code&gt;ranger::ranger()&lt;/code&gt;). As a result, each individual tree in the forest is trained with a similar proportion of zeros and ones, which helps mitigate the class imbalance issue. This method is named &lt;em&gt;weighted Random Forest&lt;/em&gt;, and is very well explained in this 
&lt;a href=&#34;https://statistics.berkeley.edu/sites/default/files/tech-reports/666.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;white paper&lt;/a&gt; that includes the father of Random Forest, Leo Breiman, as coauthor.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;unique(model.non.spatial$ranger.arguments$case.weights)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.006060606 0.016129032
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This model could be projected right away onto a raster stack with maps of the predictors, so, in fact, &lt;code&gt;spatialRF&lt;/code&gt; can be used to fit Species Distribution Models, when it actually wasn&amp;rsquo;t really designed with such a purpose in mind. And as an additional advantage, the model can be evaluated with &lt;code&gt;rf_evaluate()&lt;/code&gt;, which is way better than cross-validation via random data-splitting (
&lt;a href=&#34;https://methodsblog.com/2018/11/29/blockcv-english/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this blog post&lt;/a&gt; explains explains why).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;model.non.spatial &amp;lt;- spatialRF::rf_evaluate(
  model.non.spatial,
  xy = xy,
  metrics = &amp;quot;auc&amp;quot;,
  verbose = FALSE
)

spatialRF::print_evaluation(model.non.spatial)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Spatial evaluation 
##   - Training fraction:             0.75
##   - Spatial folds:                 29
## 
##  Metric Median   MAD Minimum Maximum
##     auc  0.932 0.024    0.83   0.977
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;strong&gt;take away message&lt;/strong&gt; here is that you can work with a binomial response with &lt;code&gt;spatialRF&lt;/code&gt;, just as you would do with a continuous response, as long as it is represented with zeros and ones. Just remember that the class imbalance problem is tackled via case weights, and that predictive performance is also measured using the Area Under the ROC Curve (AUC).&lt;/p&gt;
&lt;h1 id=&#34;generating-spatial-predictors-for-other-modelling-methods&#34;&gt;Generating spatial predictors for other modelling methods&lt;/h1&gt;
&lt;p&gt;You might not love Random Forest, but &lt;code&gt;spatialRF&lt;/code&gt; loves you, and as such, it gives you tools to generate spatial predictors for other models anyway.&lt;/p&gt;
&lt;p&gt;The first step requires generating Moran&amp;rsquo;s Eigenvector Maps (MEMs) from the distance matrix. Here there are two options, computing MEMs for a single neighborhood distance with 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/mem.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;mem()&lt;/code&gt;&lt;/a&gt;, and computing MEMs for several neighborhood distances at once with 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/mem_multithreshold.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;mem_multithreshold()&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#single distance (0km by default)
mems &amp;lt;- spatialRF::mem(distance.matrix = distance_matrix)

#several distances
mems &amp;lt;- spatialRF::mem_multithreshold(
  distance.matrix = distance.matrix,
  distance.thresholds = distance.thresholds
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In either case the result is a data frame with Moran&amp;rsquo;s Eigenvector Maps (&amp;ldquo;just&amp;rdquo; the positive eigenvectors of the double-centered distance matrix).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;kableExtra::kbl(
  head(mems[, 1:4], n = 10),
  format = &amp;quot;html&amp;quot;
) %&amp;gt;%
  kableExtra::kable_paper(&amp;quot;hover&amp;quot;, full_width = F)
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34; lightable-paper lightable-hover&#34; style=&#39;color: black; font-family: &#34;Arial Narrow&#34;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;&#39;&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; spatial_predictor_0_1 &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; spatial_predictor_0_2 &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; spatial_predictor_0_3 &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; spatial_predictor_0_4 &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0259217 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0052203 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0416969 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0363324 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0996679 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0539713 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.1324480 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.3826928 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0010477 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0143046 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0443602 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0031386 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0165695 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0047991 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0307457 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0005170 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0225761 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0019595 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0230368 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0524239 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0155252 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0023742 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0197953 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0338956 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0229197 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0039860 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0312561 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0416697 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.2436009 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.1155295 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0791452 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0189996 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0150725 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0158684 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.1010284 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0095590 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.1187381 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0471879 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; -0.0359881 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.0065211 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;But not all MEMs are made equal, and you will need to rank them by their Moran&amp;rsquo;s I. The function 
&lt;a href=&#34;https://blasbenito.github.io/spatialRF/reference/rank_spatial_predictors.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;rank_spatial_predictors()&lt;/code&gt;&lt;/a&gt; will help you do so.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mem.rank &amp;lt;- spatialRF::rank_spatial_predictors(
  distance.matrix = distance_matrix,
  spatial.predictors.df = mems,
  ranking.method = &amp;quot;moran&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output of &lt;code&gt;rank_spatial_predictors()&lt;/code&gt; is a list with three slots: &amp;ldquo;method&amp;rdquo;, a character string with the name of the ranking method; &amp;ldquo;criteria&amp;rdquo;, an ordered data frame with the criteria used to rank the spatial predictors; and &amp;ldquo;ranking&amp;rdquo;, a character vector with the names of the spatial predictors in the order of their ranking (it is just the first column of the &amp;ldquo;criteria&amp;rdquo; data frame). We can use this &amp;ldquo;ranking&amp;rdquo; object to reorder or &lt;code&gt;mems&lt;/code&gt; data frame.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;mems &amp;lt;- mems[, mem.rank$ranking]

#also:
#mems &amp;lt;- mem.rank$spatial.predictors.df
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From here, spatial predictors can be included in any model one by one, in the order of the ranking, until the spatial autocorrelation of the residuals becomes neutral, if possible. A little example with a linear model follows.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#model definition
predictors &amp;lt;- c(
  &amp;quot;climate_aridity_index_average &amp;quot;,
  &amp;quot;climate_bio1_average&amp;quot;,
  &amp;quot;bias_species_per_record&amp;quot;,
  &amp;quot;human_population_density&amp;quot;,
  &amp;quot;topography_elevation_average&amp;quot;,
  &amp;quot;fragmentation_division&amp;quot;
)
model.formula &amp;lt;- as.formula(
  paste(
    dependent.variable.name,
    &amp;quot; ~ &amp;quot;,
    paste(
      predictors,
      collapse = &amp;quot; + &amp;quot;
    )
  )
)

#scaling the data
model.data &amp;lt;- scale(plant_richness_df) %&amp;gt;% 
  as.data.frame()

#fitting the model
m &amp;lt;- lm(model.formula, data = model.data)

#Moran&#39;s I test of the residuals
moran.test &amp;lt;- spatialRF::moran(
  x = residuals(m),
  distance.matrix = distance_matrix,
  verbose = FALSE
)
moran.test$plot
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-68-1.png&#34; width=&#34;480&#34; /&gt;
&lt;p&gt;According to the Moran&amp;rsquo;s I test, the model residuals show spatial autocorrelation. Let&amp;rsquo;s introduce MEMs one by one until the problem is solved.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#add mems to the data and applies scale()
model.data &amp;lt;- data.frame(
  plant_richness_df,
  mems
) %&amp;gt;%
  scale() %&amp;gt;%
  as.data.frame()

#initialize predictors.i
predictors.i &amp;lt;- predictors

#iterating through MEMs
for(mem.i in colnames(mems)){
  
  #add mem name to model definintion
  predictors.i &amp;lt;- c(predictors.i, mem.i)
  
  #generate model formula with the new spatial predictor
  model.formula.i &amp;lt;- as.formula(
    paste(
      dependent.variable.name,
      &amp;quot; ~ &amp;quot;,
      paste(
        predictors.i,
        collapse = &amp;quot; + &amp;quot;
      )
    )
  )
  
  #fit model
  m.i &amp;lt;- lm(model.formula.i, data = model.data)
  
  #Moran&#39;s I test
  moran.test.i &amp;lt;- moran(
    x = residuals(m.i),
    distance.matrix = distance_matrix,
    verbose = FALSE
  )
  
  #stop if no autocorrelation
  if(moran.test.i$test$interpretation == &amp;quot;No spatial correlation&amp;quot;){
    break
  }
  
}#end of loop

#last moran test
moran.test.i$plot
&lt;/code&gt;&lt;/pre&gt;
&lt;img src=&#34;https://blasbenito.com/project/post-title/index_files/figure-html/unnamed-chunk-69-1.png&#34; width=&#34;480&#34; /&gt;
&lt;p&gt;Now we can compare the model without spatial predictors &lt;code&gt;m&lt;/code&gt; and the model with spatial predictors &lt;code&gt;m.i&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;comparison.df &amp;lt;- data.frame(
  Model = c(&amp;quot;Non-spatial&amp;quot;, &amp;quot;Spatial&amp;quot;),
  Predictors = c(length(predictors), length(predictors.i)),
  R_squared = round(c(summary(m)$r.squared, summary(m.i)$r.squared), 2),
  AIC = round(c(AIC(m), AIC(m.i)), 0),
  BIC = round(c(BIC(m), BIC(m.i)), 0),
  `Moran I` = round(c(moran.test$test$moran.i, moran.test.i$test$moran.i), 2)
)

kableExtra::kbl(
  comparison.df,
  format = &amp;quot;html&amp;quot;
) %&amp;gt;%
  kableExtra::kable_paper(&amp;quot;hover&amp;quot;, full_width = F)
&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34; lightable-paper lightable-hover&#34; style=&#39;color: black; font-family: &#34;Arial Narrow&#34;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;&#39;&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&#34;text-align:left;&#34;&gt; Model &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; Predictors &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; R_squared &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; AIC &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; BIC &lt;/th&gt;
   &lt;th style=&#34;text-align:right;&#34;&gt; Moran.I &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Non-spatial &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 6 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.38 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 551 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 578 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.21 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&#34;text-align:left;&#34;&gt; Spatial &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 22 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.50 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 533 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 615 &lt;/td&gt;
   &lt;td style=&#34;text-align:right;&#34;&gt; 0.06 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;According to the model comparison, it can be concluded that the addition of spatial predictors, in spite of the increase in complexity, has improved the model. In any case, this is just a simple demonstration of how spatial predictors generated with functions of the &lt;code&gt;spatialRF&lt;/code&gt; package can still help you fit spatial models with other modeling methods.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Designing R Functions to Compute Betadiversity Indices</title>
      <link>https://blasbenito.com/post/betadiversity/</link>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://blasbenito.com/post/betadiversity/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    This is a tutorial written for R users needing to compute betadiversity indices from species lists rather than from presence-absence matrices, and for R beginners or intermediate users that want to start using their own functions. If you are an advanced R user, this post will likely waste your time.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We ecologists like to measure all things in nature, and compositional changes in biological communities over time or space, a.k.a &lt;em&gt;betadiversity&lt;/em&gt;, is one of these things. I am not going to explain what betadiversity is because others that know better than me have done it already. Good examples are 
&lt;a href=&#34;https://methodsblog.com/2015/05/27/beta_diversity/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this post published the blog of Methods in Ecology and Evolution&lt;/a&gt; by 
&lt;a href=&#34;https://twitter.com/andres_baselga&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Andres Baselga&lt;/a&gt;, 
&lt;a href=&#34;https://www.youtube.com/watch?v=WQGN30YSc_U&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;and this lecture by Tim Seipel&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What I am actually going to do in this post is to explain how to write functions to compute betadiversity indices in R from species lists rather than from presence-absence matrices. For the latter there are a few packages such as 
&lt;a href=&#34;https://cran.r-project.org/package=vegan&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;vegan&lt;/a&gt;, 
&lt;a href=&#34;https://cran.r-project.org/package=BAT&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;BAT&lt;/a&gt;,  
&lt;a href=&#34;https://cran.r-project.org/package=MBI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MBI&lt;/a&gt;, or 
&lt;a href=&#34;https://cran.r-project.org/package=betapart&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;betapart&lt;/a&gt;, but for the former I was unable to find anything suitable. To make this post useful for R beginners, I will go step by step on the rationale behind the design of the functions to compute betadiversity indices, and by the end of the post I will explain how to organize them to achieve a clean R workflow.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s go!&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2 id=&#34;betadiversity-indices&#34;&gt;Betadiversity indices&lt;/h2&gt;
&lt;p&gt;There are a few betadiversity indices out there, and I totally recommend you to start with 
&lt;a href=&#34;https://besjournals.onlinelibrary.wiley.com/doi/10.1046/j.1365-2656.2003.00710.x&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Koleff &lt;em&gt;et al.&lt;/em&gt; (2003)&lt;/a&gt; as a primer. They review the literature and analyze the properties of 24 different indices to provide guidance on how to use them.&lt;/p&gt;
&lt;h3 id=&#34;betadiversity-components-a-b-and-c&#34;&gt;Betadiversity components &lt;em&gt;a&lt;/em&gt;, &lt;em&gt;b&lt;/em&gt;, and &lt;em&gt;c&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Betadiversity indices are designed to compare the taxa pools of two sites at a time, and require the computation of three components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;a&lt;/strong&gt;: number of common taxa of both sites.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;b&lt;/strong&gt;: number of exclusive taxa of one site.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;c&lt;/strong&gt;: number of exclusive taxa of the other site.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let&amp;rsquo;s see how can we use these diversity components to compute betadiversity indices.&lt;/p&gt;
&lt;h3 id=&#34;sørensens-beta&#34;&gt;Sørensen&amp;rsquo;s Beta&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s start with the &lt;strong&gt;Sørensen&amp;rsquo;s Beta&lt;/strong&gt; (&lt;code&gt;\(\beta_{sor}\)&lt;/code&gt; hereafter), as presented in Koleff &lt;em&gt;et al.&lt;/em&gt; (2003).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$\beta_{sor} = \frac{2a}{2a + b + c}$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;\(\beta_{sor}\)&lt;/code&gt; is a similarity index in the range [0, 1] (the closer to one, the more similar the taxa pools of both sites are) that puts a lot of weight in the &lt;code&gt;\(a\)&lt;/code&gt; component, and is therefore a measure of &lt;em&gt;continuity&lt;/em&gt;, as it focuses the most in the common taxa among sites.&lt;/p&gt;
&lt;h3 id=&#34;simpsons-beta&#34;&gt;Simpson&amp;rsquo;s Beta&lt;/h3&gt;
&lt;p&gt;Another popular betadiversity index is the &lt;strong&gt;Simpson&amp;rsquo;s Beta&lt;/strong&gt; (&lt;code&gt;\(\beta_{sim}\)&lt;/code&gt; hereafter).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$\beta_{sim} = \frac{min(b, c)}{min(b, c) + a}$$&lt;/code&gt;
where &lt;code&gt;\(min()\)&lt;/code&gt; is a function that takes the minimum value among the diversity components within the parenthesis. &lt;code&gt;\(\beta_{sim}\)&lt;/code&gt; is a dissimilarity measure that focuses on compositional turnover among sites because it focuses the most on the values of &lt;code&gt;\(b\)&lt;/code&gt; and &lt;code&gt;\(c\)&lt;/code&gt;. It has its lower bound in zero, and an open upper value.&lt;/p&gt;
&lt;p&gt;To bring these ideas into R, first we have to load a few R packages, and generate some fake data to help us develop the functions.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(foreach, quietly = TRUE)
library(doParallel, quietly = TRUE)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code chunk below generates 15 fake taxa names, from &lt;code&gt;taxon_1&lt;/code&gt; to &lt;code&gt;taxon_15&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;taxa &amp;lt;- paste0(&amp;quot;taxon_&amp;quot;, 1:15)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With these fake taxa we are going to generate taxa lists for four hypothetical sites named &lt;em&gt;site1&lt;/em&gt;, &lt;em&gt;site2&lt;/em&gt;, &lt;em&gt;site3&lt;/em&gt;, and &lt;em&gt;site4&lt;/em&gt;. Two of the sites will have identical taxa lists, two will have non-overlapping taxa lists, and two of them will have some overlap.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;site1 &amp;lt;- site2 &amp;lt;- taxa[1:7]
site3 &amp;lt;- taxa[8:12]
site4 &amp;lt;- taxa[10:15]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So now we have these taxa lists:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;site1 #and site2
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;taxon_1&amp;quot; &amp;quot;taxon_2&amp;quot; &amp;quot;taxon_3&amp;quot; &amp;quot;taxon_4&amp;quot; &amp;quot;taxon_5&amp;quot; &amp;quot;taxon_6&amp;quot; &amp;quot;taxon_7&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;site3
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;taxon_8&amp;quot;  &amp;quot;taxon_9&amp;quot;  &amp;quot;taxon_10&amp;quot; &amp;quot;taxon_11&amp;quot; &amp;quot;taxon_12&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;site4
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;taxon_10&amp;quot; &amp;quot;taxon_11&amp;quot; &amp;quot;taxon_12&amp;quot; &amp;quot;taxon_13&amp;quot; &amp;quot;taxon_14&amp;quot; &amp;quot;taxon_15&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2 id=&#34;step-by-step-computation-of-betadiversity-indices-with-r&#34;&gt;Step-by-step computation of betadiversity indices with R&lt;/h2&gt;
&lt;p&gt;For a given pair of sites, how can we compute the diversity components &lt;em&gt;a&lt;/em&gt;, &lt;em&gt;b&lt;/em&gt;, and &lt;em&gt;c&lt;/em&gt;?&lt;/p&gt;
&lt;p&gt;Looking at it from an R perspective, each site is a character vector, so &lt;em&gt;a&lt;/em&gt; can be found by counting the number of common elements between two vectors. These common elements can be found with the function &lt;code&gt;intersect()&lt;/code&gt;, and the number of elements can be computed by applying &lt;code&gt;length()&lt;/code&gt; on the result of &lt;code&gt;intersect()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;a &amp;lt;- length(intersect(site3, site4))
a
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To compute &lt;em&gt;b&lt;/em&gt; and &lt;em&gt;c&lt;/em&gt; we can use the function &lt;code&gt;setdiff()&lt;/code&gt;, that finds the exclusive elements of one character vector when comparing it with another. In this case, &lt;em&gt;b&lt;/em&gt; is computed for the first vector introduced in the function, &lt;em&gt;site3&lt;/em&gt; in this case&amp;hellip;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;b &amp;lt;- length(setdiff(site3, site4))
b
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&amp;hellip; so to compute the &lt;em&gt;c&lt;/em&gt; component we only need to switch the sites.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;c &amp;lt;- length(setdiff(site4, site3))
c
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we know &lt;em&gt;a&lt;/em&gt;, &lt;em&gt;b&lt;/em&gt;, and &lt;em&gt;c&lt;/em&gt;, we can compute &lt;code&gt;\(\beta_{sor}\)&lt;/code&gt; and &lt;code&gt;\(\beta_{sim}\)&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Bsor &amp;lt;- 2 * a / (2 * a + b + c)
Bsor
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5454545
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Bsim&amp;lt;- min(b, c) / (min(b, c) + a)
Bsim
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of course, if we have a long list of sites, computing betadiversity indices like this can get quite boring quite fast. Let&amp;rsquo;s put everything in a set of functions to make it easier to work with.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2 id=&#34;writing-functions-to-compute-betadiversity-indices&#34;&gt;Writing functions to compute betadiversity indices&lt;/h2&gt;
&lt;p&gt;The basic structure of a function definition in R looks as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;function_name &amp;lt;- function(x, y, ...){
  output &amp;lt;- [body]
  output #also return(output)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;function_name&lt;/code&gt; is the name of your function. Ideally, a verb, or otherwise, something indicating somehow what the function will do with the input data and arguments.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;function()&lt;/code&gt; is a function to define functions, there isn&amp;rsquo;t much more to it&amp;hellip;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;x&lt;/code&gt; is the first argument of the function, and ideally, represents the input data. If that is the case, you can later use 
&lt;a href=&#34;https://r4ds.had.co.nz/pipes.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pipes&lt;/a&gt; (&lt;code&gt;|&amp;gt;&lt;/code&gt;) to chain functions together.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;y&lt;/code&gt; (it could have any other name) is another function argument, an can be either another input dataset, or an argument defining how the function has to behave.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;...&lt;/code&gt; refers to other arguments the function may require.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;body&lt;/code&gt; is the code that operates with the data and function arguments. This can be one line of code, or a thousand, it all comes down to the function&amp;rsquo;s objective. In any case, the &lt;code&gt;body&lt;/code&gt; must return an object (or an error if something went wrong) that will be the function&amp;rsquo;s &lt;code&gt;output&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;output&lt;/code&gt; is the object ultimately produced by the function. It can have any name, and can be any kind of structure, such a number, a vector, a data frame, a list, etc. R functions return one output object only. Since R functions return the last evaluated value, it is good practice to put the &lt;code&gt;output&lt;/code&gt; object at the end of the function as an explicit way to state what the actual output of the function is.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let&amp;rsquo;s start writing a function to compute &lt;em&gt;a&lt;/em&gt;, &lt;em&gt;b&lt;/em&gt;, and &lt;em&gt;c&lt;/em&gt; from a pair of sites.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#x: taxa list of one site
#y: taxa list of another site
abc &amp;lt;- function(x, y){
  
  #list to store output
  out &amp;lt;- list()
  
  #filling the list
  out$a &amp;lt;- length(intersect(x, y))
  out$b &amp;lt;- length(setdiff(x, y))
  out$c &amp;lt;- length(setdiff(y, x))
  
  #returning the output
  out
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that to to return the three values I am wrapping them in a list. Let&amp;rsquo;s run a little test.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x &amp;lt;- abc(
  x = site3,
  y = site4
)
x
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $a
## [1] 3
## 
## $b
## [1] 2
## 
## $c
## [1] 3
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So far so good! From here we build the functions &lt;code&gt;sorensen_beta()&lt;/code&gt; and &lt;code&gt;simpson_beta()&lt;/code&gt; making sure they can accept the output of &lt;code&gt;abc()&lt;/code&gt;, and return it with an added slot.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sorensen_beta &amp;lt;- function(x){
  
  x$bsor &amp;lt;- round(2 * x$a / (2 * x$a + x$b + x$c), 3)
  
  x
  
}


simpson_beta &amp;lt;- function(x){
  
  x$bsim &amp;lt;- round(min(x$b, x$c) / (min(x$b, x$c) + x$a), 3)
  
  x
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that both functions are returning the input &lt;code&gt;x&lt;/code&gt; with an added slot named after the given betadiversity index. Let&amp;rsquo;s test them first, to later see why returning the input object gives these functions a lot of flexibility.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sorensen_beta(x)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $a
## [1] 3
## 
## $b
## [1] 2
## 
## $c
## [1] 3
## 
## $bsor
## [1] 0.545
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;simpson_beta(x)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $a
## [1] 3
## 
## $b
## [1] 2
## 
## $c
## [1] 3
## 
## $bsim
## [1] 0.4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When I said that returning the input object with an added slot gave these functions a lot of flexibility I was talking about this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x &amp;lt;- abc(
  x = site3, 
  y = site4
  ) |&amp;gt; 
  sorensen_beta() |&amp;gt; 
  simpson_beta()
x
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $a
## [1] 3
## 
## $b
## [1] 2
## 
## $c
## [1] 3
## 
## $bsor
## [1] 0.545
## 
## $bsim
## [1] 0.4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Chaining the functions through the pipe &lt;code&gt;|&amp;gt;&lt;/code&gt; pipe allows us combining their results in a single output no matter whether we use &lt;code&gt;sorensen_beta()&lt;/code&gt; or &lt;code&gt;sorensen_beta()&lt;/code&gt; first, or whether we omit one of them. The only thing the pipe is doing here is moving the output of the first function into the next.&lt;/p&gt;
&lt;p&gt;We can put that idea right away into a function to compute both betadiversity indices at once from the taxa list of a pair of sites.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;betadiversity &amp;lt;- function(x, y){
  
  abc(x, y) |&amp;gt;
    sorensen_beta() |&amp;gt;
    simpson_beta()
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function now works as follows.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x &amp;lt;- betadiversity(
  x = site3, 
  y = site4
  )
x
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $a
## [1] 3
## 
## $b
## [1] 2
## 
## $c
## [1] 3
## 
## $bsor
## [1] 0.545
## 
## $bsim
## [1] 0.4
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So far we have four functions&amp;hellip;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;abc()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;simpson_beta()&lt;/code&gt;, that requires &lt;code&gt;abc()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sorensen_beta()&lt;/code&gt;, that requires &lt;code&gt;abc()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;betadiversity()&lt;/code&gt;, that requires &lt;code&gt;abc()&lt;/code&gt;, &lt;code&gt;simpson_beta()&lt;/code&gt;, and &lt;code&gt;sorensen_beta()&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&amp;hellip; and one limitation: so far we can only return betadiversity indices for two sites at a time. So at the moment, to compute betadiversity indices for all combinations of sites we have to do a pretty ridiculous thing:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;x1 &amp;lt;- betadiversity(x = site1, y = site2)
x2 &amp;lt;- betadiversity(x = site1, y = site3)
x3 &amp;lt;- betadiversity(x = site1, y = site4)
#... and so on
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If I see you doing this I&amp;rsquo;ll come to haunt you in your nightmares! Since a real analysis may involve hundreds of sites, the next step is to use the functions above to build a new one able to intake an arbitrary number of sites.&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2 id=&#34;writing-a-function-to-compute-betadiversity-indices-for-an-arbitrary-number-of-sites&#34;&gt;Writing a function to compute betadiversity indices for an arbitrary number of sites.&lt;/h2&gt;
&lt;p&gt;First we have to organize our sites in a data frame with a &lt;em&gt;long format&lt;/em&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sites &amp;lt;- data.frame(
  site = c(
    rep(&amp;quot;site1&amp;quot;, length(site1)),
    rep(&amp;quot;site2&amp;quot;, length(site2)),
    rep(&amp;quot;site3&amp;quot;, length(site3)),
    rep(&amp;quot;site4&amp;quot;, length(site4))
    ),
  taxon = c(
    site1,
    site2,
    site3,
    site4
  )
)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;site&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;taxon&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_7&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_12&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;taxon_15&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Our new function will need to do several things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generate combinations of the unique values of the column &lt;code&gt;site&lt;/code&gt; two by two without repetition.&lt;/li&gt;
&lt;li&gt;Iterate through these combinations of two sites to compute betadiversity components and indices.&lt;/li&gt;
&lt;li&gt;Return a dataframe with the results to facilitate further analyses.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The combinations of site pairs are done with &lt;code&gt;utils::combn()&lt;/code&gt; as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;site.combinations &amp;lt;- utils::combn(
  x = unique(sites$site),
  m = 2
  )
site.combinations
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1]    [,2]    [,3]    [,4]    [,5]    [,6]   
## [1,] &amp;quot;site1&amp;quot; &amp;quot;site1&amp;quot; &amp;quot;site1&amp;quot; &amp;quot;site2&amp;quot; &amp;quot;site2&amp;quot; &amp;quot;site3&amp;quot;
## [2,] &amp;quot;site2&amp;quot; &amp;quot;site3&amp;quot; &amp;quot;site4&amp;quot; &amp;quot;site3&amp;quot; &amp;quot;site4&amp;quot; &amp;quot;site4&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result is a matrix, and each pair of rows in a column contain a pair of sites. The idea now is to iterate over the matrix columns, obtain the set of taxa from each site from the &lt;code&gt;taxon&lt;/code&gt; column of the &lt;code&gt;sites&lt;/code&gt; data frame, and use these taxa lists to compute the betadiversity components and indices.&lt;/p&gt;
&lt;p&gt;To easily generate the output data frame, I use the &lt;code&gt;foreach::foreach()&lt;/code&gt; function to iterate through pairs instead of a more traditional &lt;code&gt;for&lt;/code&gt; loop. You can read more about &lt;code&gt;foreach()&lt;/code&gt; in a 
&lt;a href=&#34;https://www.blasbenito.com/post/02_parallelizing_loops_with_r/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;previous post&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;betadiversity.df &amp;lt;- foreach::foreach(
  i = 1:ncol(site.combinations), #iterates through columns of site.combinations
  .combine = &#39;rbind&#39; #to produce a data frame
  ) %do% {
  
  #site names
  site.one &amp;lt;- site.combinations[1, i] #from column i, row 1
  site.two &amp;lt;- site.combinations[2, i] #from column i, row 2
  
  #getting taxa lists
  taxa.list.one &amp;lt;- sites[sites$site %in% site.one, &amp;quot;taxon&amp;quot;]
  taxa.list.two &amp;lt;- sites[sites$site %in% site.two, &amp;quot;taxon&amp;quot;]
  
  #betadiversity
  beta &amp;lt;- betadiversity(
    x = taxa.list.one,
    y = taxa.list.two
  )
  
  #adding site names
  beta$site.one &amp;lt;- site.one
  beta$site.two &amp;lt;- site.two
  
  #returning output
  beta
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;a&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;b&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;c&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;bsor&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;bsim&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;site.one&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;site.two&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;7&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;7&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;5&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;7&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;6&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;7&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;5&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;7&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;6&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0.545&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0.4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Now that we know it works, we can put everything together in a function. Notice that to make the function more general, I have added arguments requesting the names of the columns with the site and the taxa names.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;betadiversity_multisite &amp;lt;- function(
  x, 
  site.column, #column with site names
  taxa.column #column with taxa names
){
  
  #get site combinations
  site.combinations &amp;lt;- utils::combn(
    x = unique(x[, site.column]),
    m = 2
  )
  
  #iterating through site pairs
  betadiversity.df &amp;lt;- foreach::foreach(
    i = 1:ncol(site.combinations),
    .combine = &#39;rbind&#39;
  ) %do% {
    
    #site names
    site.one &amp;lt;- site.combinations[1, i]
    site.two &amp;lt;- site.combinations[2, i]
    
    #getting taxa lists
    taxa.list.one &amp;lt;- x[x[, site.column] %in% site.one, taxa.column]
    taxa.list.two &amp;lt;- x[x[, site.column] %in% site.two, taxa.column]
    
    #betadiversity
    beta &amp;lt;- betadiversity(
      x = taxa.list.one,
      y = taxa.list.two
    )
    
    #adding site names
    beta$site.one &amp;lt;- site.one
    beta$site.two &amp;lt;- site.two
    
    #returning output
    beta
    
  }
  
  #remove bad rownames
  rownames(betadiversity.df) &amp;lt;- NULL
  
  #reordering columns
  betadiversity.df &amp;lt;- betadiversity.df[, c(
    &amp;quot;site.one&amp;quot;,
    &amp;quot;site.two&amp;quot;,
    &amp;quot;a&amp;quot;,
    &amp;quot;b&amp;quot;,
    &amp;quot;c&amp;quot;,
    &amp;quot;bsor&amp;quot;,
    &amp;quot;bsim&amp;quot;
    )]
  
  #returning output
  return(betadiversity.df)
  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the test!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sites.betadiversity &amp;lt;- betadiversity_multisite(
  x = sites, 
  site.column = &amp;quot;site&amp;quot;,
  taxa.column = &amp;quot;taxon&amp;quot;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;site.one&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;site.two&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;a&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;b&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;c&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;bsor&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;bsim&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;7&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;7&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;5&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;7&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;6&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;7&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;5&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;7&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;6&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;site4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;3&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0.545&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;0.4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;That went well!&lt;/p&gt;
&lt;p&gt;Finally, to have these functions available in my R session I always put them all in a single file in the same folder where my Rstudio project lives, name it something like &lt;code&gt;functions_betadiversity.R&lt;/code&gt;, and source it at the beginning of my script or .Rmd file by running a line like the one below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;source(&amp;quot;functions_betadiversity.R&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I have placed the file &lt;code&gt;functions_betadiversity.R&lt;/code&gt; in 
&lt;a href=&#34;https://gist.github.com/BlasBenito/4c3740b056a0c9bb3602f33dfd35990c&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this GitHub Gist&lt;/a&gt; in case you want to give it a look. You can also source it right away to your R environment by executing the following line:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;source(&amp;quot;https://gist.githubusercontent.com/BlasBenito/4c3740b056a0c9bb3602f33dfd35990c/raw/bbb40d868787fc5d10e391a2121045eb5d75f165/functions_betadiversity.R&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I hope this post helped you to better understand how to write and organize R functions!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R package memoria</title>
      <link>https://blasbenito.com/project/memoria/</link>
      <pubDate>Sat, 19 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://blasbenito.com/project/memoria/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://zenodo.org/badge/latestdoi/179102027&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/179102027.svg&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt;

&lt;a href=&#34;https://CRAN.R-project.org/package=memoria&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version-ago/memoria&#34; alt=&#34;CRAN\_Release\_Badge&#34;&gt;&lt;/a&gt;

&lt;a href=&#34;https://CRAN.R-project.org/package=memoria&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://cranlogs.r-pkg.org/badges/memoria&#34; alt=&#34;CRAN\_Download\_Badge&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The goal of &lt;em&gt;memoria&lt;/em&gt; is to provide the tools to quantify &lt;strong&gt;ecological
memory&lt;/strong&gt; in long time-series involving environmental drivers and biotic
responses, including palaeoecological datasets.&lt;/p&gt;
&lt;p&gt;Ecological memory has two main components: the &lt;em&gt;endogenous&lt;/em&gt; component,
which represents the effect of antecedent values of the response on
itself, and &lt;em&gt;endogenous&lt;/em&gt; component, which represents the effect of
antecedent values of the driver or drivers on the current state of the
biotic response. Additionally, the &lt;em&gt;concurrent effect&lt;/em&gt;, which represents
the synchronic effect of the environmental drivers over the response is
measured. The functions in the package allow the user&lt;/p&gt;
&lt;p&gt;The package &lt;em&gt;memoria&lt;/em&gt; uses the fast implementation of Random Forest
available in the 
&lt;a href=&#34;https://CRAN.R-project.org/package=ranger&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ranger&lt;/a&gt;
package to fit a model of the form shown in &lt;strong&gt;Equation 1&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Equation 1&lt;/strong&gt; (simplified from the one in the paper):
$$p_{t} = p_{t-1} +&amp;hellip;+ p_{t-n} + d_{t} + d_{t-1} +&amp;hellip;+ d_{t-n}$$&lt;/p&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$p$ is the response variable, &lt;em&gt;Pollen&lt;/em&gt; counts were used in this particular case..&lt;/li&gt;
&lt;li&gt;$d$ is an environmental &lt;em&gt;Driver&lt;/em&gt; influencing the response variable.&lt;/li&gt;
&lt;li&gt;$t$ is the time of any given value of the response $p$.&lt;/li&gt;
&lt;li&gt;$t-1$ is the lag 1.&lt;/li&gt;
&lt;li&gt;$p_{t-1} +&amp;hellip;+ p_{t-n}$ represents the endogenous component of
ecological memory.&lt;/li&gt;
&lt;li&gt;$d_{t-1} +&amp;hellip;+ d_{t-n}$ represents the exogenous component of
ecological memory.&lt;/li&gt;
&lt;li&gt;$d_{t}$ represents the concurrent effect of the driver over the
response.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Random Forest returns an importance score for each model term, and the
functions in &lt;em&gt;memoria&lt;/em&gt; let the user to plot the importance scores across
time lags for each ecological memory components, and to compute
different features of each memory component (length, strength, and
dominance).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;output.png&#34; alt=&#34;Outputs produced by memoria from the analysis of a multivariate time series&#34;&gt;&lt;/p&gt;
&lt;p&gt;The 
&lt;a href=&#34;https://github.com/BlasBenito/memoria&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub page&lt;/a&gt; of the package features complete examples on how to use the package. The 
&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/full/10.1111/ecog.04772&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper published in the Ecography journal&lt;/a&gt; describes ecological memory concepts and the method based on Random Forest used to assess ecological memory components. The code used to generate the supplementary materials can be found in 
&lt;a href=&#34;https://github.com/BlasBenito/EcologicalMemory&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt; and 
&lt;a href=&#34;https://zenodo.org/record/3236128#.X941v9Yo-1c&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zenodo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you ever use the package, please, cite it as:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Benito, B.M., Gil‐Romera, G. and Birks, H.J.B. (2020), Ecological memory at millennial time‐scales: the importance of data constraints, species longevity and niche features. Ecography, 43: 1-10. 
&lt;a href=&#34;https://doi.org/10.1111/ecog.04772&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1111/ecog.04772&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>R package virtualPollen</title>
      <link>https://blasbenito.com/project/virtualpollen/</link>
      <pubDate>Sat, 19 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://blasbenito.com/project/virtualpollen/</guid>
      <description>&lt;p&gt;
&lt;a href=&#34;https://CRAN.R-project.org/package=virtualPollen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version-ago/virtualPollen&#34; alt=&#34;CRAN\_Release\_Badge&#34;&gt;&lt;/a&gt;

&lt;a href=&#34;https://CRAN.R-project.org/package=virtualPollen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://cranlogs.r-pkg.org/badges/virtualPollen&#34; alt=&#34;CRAN\_Download\_Badge&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The goal of &lt;code&gt;virtualPollen&lt;/code&gt; is to provide the tools to simulate pollen
curves over millenial time-scales generated by virtual taxa with
different life traits (life-span, fecundity, growth-rate) and niche
features (niche position and breadth) as a response to virtual
environmental drivers with a given temporal autocorrelation. It furthers
allow to simulate specific data properties of fossil pollen datasets,
such as sediment accumulation rate, and depth intervals between
consecutive pollen samples. The simulation outcomes are useful to better
understand the role of plant traits, niche properties, and climatic
variability in defining the shape of pollen curves.&lt;/p&gt;
&lt;p&gt;The 
&lt;a href=&#34;https://github.com/BlasBenito/virtualPollen&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub page&lt;/a&gt; of the package offers a complete tutorial on how to use the package. The 
&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/full/10.1111/ecog.04772&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper published in the Ecography journal&lt;/a&gt; describes the foundations of the model in brief.&lt;/p&gt;
&lt;p&gt;If you ever use the package, please, cite it as:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Benito, B.M., Gil‐Romera, G. and Birks, H.J.B. (2020), Ecological memory at millennial time‐scales: the importance of data constraints, species longevity and niche features. Ecography, 43: 1-10. 
&lt;a href=&#34;https://doi.org/10.1111/ecog.04772&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1111/ecog.04772&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
