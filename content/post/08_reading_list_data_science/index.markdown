---
title: "My Reading List: Data Science"
author: ''
date: '2023-12-10'
slug: my-reading-list-data-science
categories: []
tags: [Data Science, Data Preprocessing, Machine Learning, Model Explainability, Model Interpretability]
subtitle: ''
summary: 'Live post with a curated list of high-quality data science posts and videos I found enlightening.'
authors: [admin]
lastmod: '2023-12-10T08:14:23+02:00'
featured: no
draft: false
image:
  caption: Image generated by [craiyon.com](https://www.craiyon.com)
  focal_point: Smart
  margin: auto
projects: []
---

This is a live post listing links to Data Science related posts and videos I consider to be interesting, high-quality, or even essential to better understand particular topics within such a wide field. 

# Data Preprocessing

## Target Encoding

[**Extending Target Encoding**](https://towardsdatascience.com/extending-target-encoding-443aa9414cae): post by [Daniele Micci-Barreca](https://www.aitimejournal.com/interview-with-daniele-micci-barreca-product-analytics-lead-data-science-google/30110/) explaining how he came up with the idea of target encoding, and its possible extensions.

[**Target encoding done the right way**](https://maxhalford.github.io/blog/target-encoding/): post by [Max Halford](https://maxhalford.github.io/bio/), Head of Data at [Carbonfact](https://www.carbonfact.com/), explaining in detail how to combine additive smoothing and target encoding.

# Analysis and Modeling

## Modeling Methods

[**Generalized Additive Models**](https://m-clark.github.io/generalized-additive-models/): A good online book on Generalized Additive Models by [Michael Clark](https://m-clark.github.io/about.html), Senior Machine Learning Scientist at [Strong Analytics](https://www.strong.io/).

## Model Explainability

[**Model-Independent Score Explanation**](https://towardsdatascience.com/a-simple-model-independent-score-explanation-method-c17002d66da7): Post by [Daniele Micci-Barreca](https://www.aitimejournal.com/interview-with-daniele-micci-barreca-product-analytics-lead-data-science-google/30110/) on model explainability. It also explains a very clever method to better understand any model just from it's predictions.

[**AI Explanations whitepaper**](https://storage.googleapis.com/cloud-ai-whitepapers/AI%20Explainability%20Whitepaper.pdf): White paper of Google's "AI Explanations" product with a pretty good overall view of the state of the art of model explainability.

[**Towards A Rigorous Science of Interpretable Machine Learning**](https://arxiv.org/abs/1702.08608): Pre-print by Finale Doshi-Velez and Been Kim offering a rigorous definition and evaluation of model interpretability.

## Spatial Analysis

[PostGEESE? Introducing The DuckDB Spatial Extension](https://duckdb.org/2023/04/28/spatial.html): In this post, the authors of [DuckDB](https://duckdb.org/) present the new PostGIS-like *spatial* extension for this popular in-process data base engine.

# Coding

[Why You Shouldn't Nest Your Code](https://youtu.be/CFRhGnuXG-4?si=7Xr3E9L7GFvoRJqA): In this wonderful video, [CodeAesthetic](https://www.youtube.com/@CodeAesthetic) explains in detail (and beautiful graphics!) a couple of methods to reduce the level of nesting in our code to improve readability and maintainability. This video has truly changed how I code in R!

# Miscellany

[What is Retrieval-Augmented Generation (RAG)?](https://youtu.be/T-D1OfcDW1M?si=sAZO-5NGD8yF2WYe): In this video, Marina Danilevsky, Senior Data Scientist at IBM, offers a pretty good explanation on how the RAG method can improve the credibility of large language models.
