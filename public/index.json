[{"authors":["admin"],"categories":null,"content":"I am biogeographer and ecological modeler with a PhD in Plant Ecology and Global Change, a Master in Geographical Information Systems, a Degree in Biology, and quite a bit of experience in applying state-of-the-art quantitative methods to better understand the processes shaping the distribution of biodiversity across space and time.\nI have developed my research career as PhD student at the Department of Botany of the University of Granada (2006 - 2009), staff researcher at IISTA, postdoctoral researcher at ECOINFO (2014 - 2017, Aarhus University, Denmark), led by Jens-Christian Svenning, postdoctoral researcher at EECRG (2017 - 2019), and currently as senior researcher at Maestre Lab, led by Fernando T. Maestre.\nMy research activity is structured around five main lines, namely biogeography, testing and development of quantitative methods, palaeoecology, range shift, and biodiversity conservation.\n Biogeography\nWhy are species where they are? is a question I have been passionate about since I was a child.\nA keystone result of my personal interest in this topic is the multidisciplinary study I led on the distribution of Neanderthals during the Last Interglacial ( Benito et al. 2016. This paper was highlighted at the Editor’s Picks section of Science ( Sugen 2017), and was among the top 20 most downloaded papers of the Journal of Bigeography during 2018. In Kellberg-Nielsen et al. (2017), led by my brilliant colleague Trine Kellberg-Nielsen we further discuss the dispersal dynamics of Neanderthals in their northern edge.\nI have also learned a a fair deal about the biogeography of plant phenological strategies through my collaboration with the outstanding Constantin Zohner. In Zohner et al. (2016) we found that plant species from lower latitudes use spring photoperiod to trigger leaf-out, while boreal species do not use photoperiod as leaf-out signal. In a complementary study ( Zohner et al. (2017)) we found that plant species from regions with high spring temperature variability have higher winter chilling requirements than species living in more predictable environments. More recently, in Zohner et al. (2020), we report increasing risks of late spring frosts in significant portions of European and Asian forests.\nLast, but not least in this section are my collaborations with the excellent biogeographer Gang Feng on the links between climatic and anthropogenetic legacies and plant distributions. In Feng et al. (2017) we found that tree assemblages with large phylogenetic age differences among species mostly inhabit areas with relatively high long‐term climate stability. The same year, in Feng et al. (2017) we evaluated the relationship between the distribution of threatened species and land-use change legacies, to find that the current distribution of threatened plants in China happens in places where historical land-use intensity was low, but has increased in the last decades.\n Testing and development of quantitative methods\nUnderstanding how quantitative methods work, developing new ones, and finding their limits of application are key axes of my research.\nHowever, this line of research started by designing and creating an infrastructure to document, store and execute the ecological models named ModeleR. This system, used to run the ecological models required by the Global Change Observatory of Sierra Nevada, is described in Perez, Benito and Bonet (2012) and Bonet et al (2014).\nIn 2013 I compared the ability of stacked species distribution models based on different statistical and machine learning methods to predict tree species richness and composition in Mesoamerica (Benito et al. 2013), and contributed to a comparison of SDMs to forecast the distribution of the seaweed Zostera marina in the Wadden Sea (Tovar et al. 2013).\nRecently I engaged in a collaboration with modelers and epidemiologists to warn against the use of species distribution models to forecast the expansion of SARS-CoV-2. In Carlson et al. (2020) we discuss the limitations of SDMs to model the direct transmission of the virus, and in Carlson et al. (2020) we point out that speculation on the relationships between the distribution of the virus and climate hinder decision making and preparedness. In the preprint Chipperfield et al. (2020) and in Contina et al. (2020, in press) we criticize two different misapplications of SDMs to the expansion of the virus.\nR packages\nAfter 10 years working with R I recently started to develop R packages. For example, the package distantia (Benito et al. 2020) implements several methods to quantify the dissimilarity among irregular multivariate time series.\nThe package memoria implements a method based on Random Forest to evaluate ecological memory (effect of antecedent conditions on a response variable) in time series data.\nI also designed a mechanistical simulation to produce virtual pollen curves in the package virtualPollen. The model uses a set of drivers, the ecological niches of a virtual species for these drivers, the traits life-span and fecundity, and the carrying capacity of the forest plot to simulate population dynamics over thousands of years.\nCurrently I am working on two other packages: sdmflow intentds to streamline the production of species distribution models based on the concept \u0026ldquo;use versus availability\u0026rdquo;, where the background data (a comprehensive sampling of the ecological conditions available in the study area) represents the availability, and the presence represents the use. The second package (still nameless) incorporates temporal and spatial autocorrelation through Moran Eigenvector Maps to machine learning models such as random forest, gradient boosting, or artificial neural networks, among others.\n Palaeoecology\nDuring the last years I have focused on applying state-of-the-art quantitative methods to better understand past ecological dynamics. Most of this work is a result of my ongoing collaboration with the bright Graciela Gil-Romera. We recently developed a framework to apply ecological memory concepts to millennial timescales in Benito et al. 2020. This paper was highlighted as an Editor\u0026rsquo;s Choice in the number 43 of the Ecography journal, and made it to the top 10% most downloaded papers of the journal in the period 2018-2019, after it was published as early view in October 22, 2019. A very kind reviewer wrote the following to the handling editor: \u0026ldquo;In my years of reviewing papers, this is by far one of the best and cleanest reviews I have encountered and the authors should be commended for that.\u0026quot;. That was a first in my research career!\nI helped implement these memory conceptsto better understand the relationship between fire and Erica spp. in the Bale Mountains of Ethiopia during the Holocene ( Gil-Romera et al. 2019) and the Pyrenees (Leunda et al. 2020).\n Range shift\nGlobal warming is changing the geographic distribution of climate, and organisms respond by either shifting their distributions through dispersal and colonization of new habitats, resisting change in situ, or going extinct. Species distribution models (SDM), with the help of future climate simulations, allow to model changes in habitat suitability over time. For example, in Benito et al. (2011) I evaluated future suitability change for four vegetation types in the Sierra Nevada mountain range (Granada, Spain). I have also contributed to future suitability change projections for the emblematic saguaro (Carnegiea gigantea) in the Sonoran Desert (Albuquerque et al. 2018), and three grouse species in Kozma et al (2018). I have also worked with mechanistic models simulating dispersal to forecast plant range shift and extinction in the southern Iberian Peninsula (Benito et al 2014).\n Biodiversity conservation\nThe first half of my PhD thesis was focused on understanding the threat posed by the expansion of greenhouses and habitat degradation on rare and endemic annual plants in the drylands of the Iberian Southwest. For example, I analyzed the historical habitat fragmentation of the habitat of Linaria nigricans using landscape fragmentation metrics ( Peñas, Benito et al. 2011), and modelled future greenhouse expansion on protected dryland habitats through correlative ( Benito et al. 2009) and mechanistic models ( Benito and Peñas 2008).\nWithin this research line I have also also engaged in collaborations to better understand the distribution and conservation status of an endemic butterfly ( Azcón, Benito et al 2014), assess how well Special Protected Areas protect birds in Europe ( Albuquerque et al. 2013), define the role of palaeoecology in conservation strategies ( Gill et al. 2015), and find conservation gaps for tree diversity in Mesoamerica ( Albuquerque, Benito et al. 2015).\n","date":1609459200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1609459200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/blas-m.-benito/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/blas-m.-benito/","section":"authors","summary":"I am biogeographer and ecological modeler with a PhD in Plant Ecology and Global Change, a Master in Geographical Information Systems, a Degree in Biology, and quite a bit of experience in applying state-of-the-art quantitative methods to better understand the processes shaping the distribution of biodiversity across space and time.","tags":null,"title":"Blas M. Benito","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Antonio J. Pérez-Luque","Blas M. Benito","Francisco J. Bonet","Regino Zamora"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"b0b95974528b688da014b913cd112f58","permalink":"/publication/2021_perez-luque_forests/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/2021_perez-luque_forests/","section":"publication","summary":"Understanding the ecology of populations located in the rear edge of their distribution is key to assessing the response of the species to changing environmental conditions. Here, we focus on rear-edge populations of Quercus pyrenaica in Sierra Nevada (southern Iberian Peninsula) to analyze their ecological and floristic diversity. We perform multivariate analyses using high-resolution environmental information and forest inventories to determine how environmental variables differ among oak populations, and to identify population groups based on environmental and floristic composition.","tags":["Biogeography","Plant Ecology"],"title":"Ecological Diversity within Rear-Edge: A Case Study from Mediterranean Quercus pyrenaica Willd.","type":"publication"},{"authors":null,"categories":null,"content":"   Note: to better follow this tutorial you can download the .Rmd file from here.\nIn a previous post I explained how to set up a small home cluster. Many things can be done with a cluster, and parallelizing loops is one of them. But there is no need of a cluster to parallelize loops and improve the efficiency of your coding!\nI believe that coding parallelized loops is an important asset for anyone working with R. That’s why this post covers the following topics:\n Beyond for: building loops with foreach. What is a parallel backend? Setup of a parallel backend for a single computer. Setup for a Beowulf cluster. Practical examples   for loops are fine, but… Many experienced R users frequently say that nobody should write loops with R because they are tacky or whatever. However, I find loops easy to write, read, and debug, and are therefore my workhorse whenever I need to repeat a task and I don’t feel like using apply() and the likes. However, regular for loops in R are highly inefficient, because they only use one of your computer cores to perform the iterations.\nFor example, the for loop below sorts vectors of random numbers a given number of times, and will only work on one of your computer cores for a few seconds, while the others are there procrastinating with no shame.\nfor(i in 1:10000){ sort(runif(10000)) } If every i could run in a different core, the operation would indeed run a bit faster, and we would get rid of lazy cores. This is were packages like foreach and doParallel come into play.\nLet’s start installing these packages and a few others that will be useful throughout this tutorial.\n#automatic install of packages if they are not installed already list.of.packages \u0026lt;- c( \u0026quot;foreach\u0026quot;, \u0026quot;doParallel\u0026quot;, \u0026quot;ranger\u0026quot;, \u0026quot;palmerpenguins\u0026quot;, \u0026quot;tidyverse\u0026quot;, \u0026quot;kableExtra\u0026quot; ) new.packages \u0026lt;- list.of.packages[!(list.of.packages %in% installed.packages()[,\u0026quot;Package\u0026quot;])] if(length(new.packages) \u0026gt; 0){ install.packages(new.packages, dep=TRUE) } #loading packages for(package.i in list.of.packages){ suppressPackageStartupMessages( library( package.i, character.only = TRUE ) ) } #loading example data data(\u0026quot;penguins\u0026quot;)   Beyond for: building loops with foreach The foreach package (the vignette is here) provides a way to build loops that support parallel execution, and easily gather the results provided by each iteration in the loop.\nFor example, this classic for loop computes the square root of the numbers 1 to 5 with sqrt() (the function is vectorized, but let’s conveniently forget that for a moment). Notice that I have to create a vector x to gather the results before executing the loop.\nx \u0026lt;- vector() for(i in 1:10){ x[i] \u0026lt;- sqrt(i) } x ## [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427 ## [9] 3.000000 3.162278 The foreach version returns a list with the results automatically. Notice that %do% operator after the loop definition, I’ll talk more about it later.\nx \u0026lt;- foreach(i = 1:10) %do% { sqrt(i) } x ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 1.414214 ## ## [[3]] ## [1] 1.732051 ## ## [[4]] ## [1] 2 ## ## [[5]] ## [1] 2.236068 ## ## [[6]] ## [1] 2.44949 ## ## [[7]] ## [1] 2.645751 ## ## [[8]] ## [1] 2.828427 ## ## [[9]] ## [1] 3 ## ## [[10]] ## [1] 3.162278 We can use the .combine argument of foreach to arrange the list as a vector. Other options such as cbind, rbind, or even custom functions can be used as well, only depending on the structure of the output of each iteration.\nx \u0026lt;- foreach( i = 1:10, .combine = \u0026#39;c\u0026#39; ) %do% { sqrt(i) } x ## [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427 ## [9] 3.000000 3.162278 Another interesting capability of foreach is that it supports several iterators of the same length at once. Notice that the values of the iterators are not combined. When the first value of one iterator is being used, the first value of the other iterators will be used as well.\nx \u0026lt;- foreach( i = 1:3, j = 1:3, k = 1:3, .combine = \u0026#39;c\u0026#39; ) %do% { i + j + k } x ## [1] 3 6 9   Running foreach loops in parallel The foreach loops shown above use the operator %do%, that processes the tasks sequentially. To run tasks in parallel, foreach uses the operator %dopar%, that has to be supported by a parallel backend. If there is no parallel backend, %dopar% warns the user that it is being run sequentially, as shown below. But what the heck is a parallel backend?\nx \u0026lt;- foreach( i = 1:10, .combine = \u0026#39;c\u0026#39; ) %dopar% { sqrt(i) } ## Warning: executing %dopar% sequentially: no parallel backend registered x ## [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427 ## [9] 3.000000 3.162278  What is a parallel backend? When running tasks in parallel, there should be a director node that tells a group of workers what to do with a given set of data and functions. The workers execute the iterations, and the director manages execution and gathers the results provided by the workers. A parallel backend provides the means for the director and workers to communicate, while allocating and managing the required computing resources (processors, RAM memory, and network bandwidth among others).\nThere are two types of parallel backends that can be used with foreach, FORK and PSOCK.\n FORK FORK backends are only available on UNIX machines (Linux, Mac, and the likes), and do not work in clusters [sad face], so only single-machine environments are appropriate for this backend. In a FORK backend, the workers share the same environment (data, loaded packages, and functions) as the director. This setup is highly efficient because the main environment doesn’t have to be copied, and only worker outputs need to be sent back to the director.\n  PSOCK PSOCK backends (Parallel Socket Cluster) are available for both UNIX and WINDOWS systems, and are the default option provided with foreach. As their main disadvantage, the environment of the director needs to be copied to the environment of each worker, which increases network overhead while decreasing the overall efficiency of the cluster. By default, all the functions available in base R are copied to each worker, and if a particular set of R packages are needed in the workers, they need to be copied to the respective environments of the workers as well.\nThis post compares both backends and concludes that FORK is about a 40% faster than PSOCK.\n   Setup of a parallel backend Here I explain how to setup the parallel backend for a simple computer and for a Beowulf cluster as the one I described in a previous post.\nSetup for a single computer Setting up a cluster in a single computer requires first to find out how many cores we want to use from the ones we have available. It is recommended to leave one free core for other tasks.\nparallel::detectCores() ## [1] 8 n.cores \u0026lt;- parallel::detectCores() - 1 Now we need to define the cluster with parallel::makeCluster() and register it so it can be used by %dopar% with doParallel::registerDoParallel(my.cluster). The type argument of parallel::makeCluster() accepts the strings “PSOCK” and “FORK” to define the type of parallel backend to be used.\n#create the cluster my.cluster \u0026lt;- parallel::makeCluster( n.cores, type = \u0026quot;PSOCK\u0026quot; ) #check cluster definition (optional) print(my.cluster) ## socket cluster with 7 nodes on host \u0026#39;localhost\u0026#39; #register it to be used by %dopar% doParallel::registerDoParallel(cl = my.cluster) #check if it is registered (optional) foreach::getDoParRegistered() ## [1] TRUE #how many workers are available? (optional) foreach::getDoParWorkers() ## [1] 7 Now we can run a set of tasks in parallel!\nx \u0026lt;- foreach( i = 1:10, .combine = \u0026#39;c\u0026#39; ) %dopar% { sqrt(i) } x ## [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427 ## [9] 3.000000 3.162278 If everything went well, now %dopar% should not be throwing the warning executing %dopar% sequentially: no parallel backend registered, meaning that the parallel execution is working as it should. In this little example there is no gain in execution speed, because the operation being executed is extremely fast, but this will change when the operations running inside of the loop take longer times to run.\nFinally, it is always recommendable to stop the cluster when we are done working with it.\nparallel::stopCluster(cl = my.cluster)  Setup for a Beowulf cluster This setup is a bit more complex, because it requires to open a port in every computer of the cluster. Ports are virtual communication channels, and are identified by a number.\nFirst, lets tell R what port we want to use:\n#define port Sys.setenv(R_PARALLEL_PORT = 11000) #check that it Sys.getenv(\u0026quot;R_PARALLEL_PORT\u0026quot;) Now, we need to open the selected port in every computer of the network. In Linux we need to setup the firewall to allow connections from the network 10.42.1.0/24 (replace this with your network range if different!) to the port 11000 by splitting the window of the Terminator console in as many computers available in your network (the figure below shows three, one for my PC and two for my Intel NUCs), opening an ssh session on each remote machine, and setting Terminator with Grouping equal to Broadcast all so we only need to type the commands once.\nOpening port 11000 in three computers at once with Terminator\n Now we have to create an object defining the IPs of the computers in the network, the number of cores to use from each computer, the user name, and the identity of the director. This will be the spec argument required by parallel::makeCluster() to create the cluster throughtout the machines in the network. It is a list of lists, with as many lists as nodes are defined. Each sub-list has a slot named host with the IP of the computer where the given node is, and user, with the name of the user in each computer.\nThe code below shows how this would be done, step by step. Yes, this is CUMBERSOME.\n#main parameters director \u0026lt;- \u0026#39;10.42.0.1\u0026#39; nuc2 \u0026lt;- \u0026#39;10.42.0.34\u0026#39; nuc1 \u0026lt;- \u0026#39;10.42.0.104\u0026#39; user \u0026lt;- \u0026quot;blas\u0026quot; #list of machines, user names, and cores spec \u0026lt;- list( list( host = director, user = user, ncore = 7 ), list( host = nuc1, user = user, ncore = 4 ), list( host = nuc2, user = user, ncore = 4 ) ) #generating nodes from the list of machines spec \u0026lt;- lapply( spec, function(spec.i) rep( list( list( host = spec.i$host, user = spec.i$user) ), spec.i$ncore ) ) #formating into a list of lists spec \u0026lt;- unlist( spec, recursive = FALSE ) Generating the spec definition is a bit easier with the function below.\n#function to generate cluster specifications from a vector of IPs, a vector with the number of cores to use on each IP, and a user name cluster_spec \u0026lt;- function( ips, cores, user ){ #creating initial list spec \u0026lt;- list() for(i in 1:length(ips)){ spec[[i]] \u0026lt;- list() spec[[i]]$host \u0026lt;- ips[i] spec[[i]]$user \u0026lt;- user spec[[i]]$ncore \u0026lt;- cores[i] } #generating nodes from the list of machines spec \u0026lt;- lapply( spec, function(spec.i) rep( list( list( host = spec.i$host, user = spec.i$user) ), spec.i$ncore ) ) #formating into a list of lists spec \u0026lt;- unlist( spec, recursive = FALSE ) return(spec) } Below I use it to generate the input to the spec argument to start the cluster with parallel::makeCluster(). Notice that I have added several arguments.\n The argument outfile determines where the workers write a log. In this case it is set to nowhere with the double quotes, but the path to a text file in the director could be provided here. The argument homogeneous = TRUE indicates that all machines have the Rscript in the same location. In this case all three machines have it at “/usr/lib/R/bin/Rscript”. Otherwise, set it up to FALSE.  #generate cluster specification spec \u0026lt;- cluster_spec( ips = c(\u0026#39;10.42.0.1\u0026#39;, \u0026#39;10.42.0.34\u0026#39;, \u0026#39;10.42.0.104\u0026#39;), cores = c(7, 4, 4), user = \u0026quot;blas\u0026quot; ) #setting up cluster my.cluster \u0026lt;- parallel::makeCluster( master = \u0026#39;10.42.0.1\u0026#39;, spec = spec, port = Sys.getenv(\u0026quot;R_PARALLEL_PORT\u0026quot;), outfile = \u0026quot;\u0026quot;, homogeneous = TRUE ) #check cluster definition (optional) print(my.cluster) #register cluster doParallel::registerDoParallel(cl = my.cluster) #how many workers are available? (optional) foreach::getDoParWorkers() Now we can use the cluster to execute a dummy operation in parallel using all machines in the network.\nx \u0026lt;- foreach( i = 1:20, .combine = \u0026#39;c\u0026#39; ) %dopar% { sqrt(i) } x Once everything is done, remember to close the cluster.\nparallel::stopCluster(cl = my.cluster)    Practical examples In this section I cover two examples on how to use parallelized loops to explore model outputs:\n Tuning random forest hyperparameters to maximize classification accuracy. Obtain a confidence interval for the importance score of each predictor from a set random forest models fitted with ranger().  In the examples I use the penguins data from the palmerpenguins package to fit classification models with random forest using species as a response, and bill_length_mm, bill_depth_mm, flipper_length_mm, and body_mass_g as predictors.\n#removing NA and subsetting columns penguins \u0026lt;- as.data.frame( na.omit( penguins[, c( \u0026quot;species\u0026quot;, \u0026quot;bill_length_mm\u0026quot;, \u0026quot;bill_depth_mm\u0026quot;, \u0026quot;flipper_length_mm\u0026quot;, \u0026quot;body_mass_g\u0026quot; )] ) )    species  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g      Adelie  39.1  18.7  181  3750    Adelie  39.5  17.4  186  3800    Adelie  40.3  18.0  195  3250    Adelie  36.7  19.3  193  3450    Adelie  39.3  20.6  190  3650    Adelie  38.9  17.8  181  3625    Adelie  39.2  19.6  195  4675    Adelie  34.1  18.1  193  3475    Adelie  42.0  20.2  190  4250    Adelie  37.8  17.1  186  3300    Adelie  37.8  17.3  180  3700    Adelie  41.1  17.6  182  3200    Adelie  38.6  21.2  191  3800    Adelie  34.6  21.1  198  4400    Adelie  36.6  17.8  185  3700    Adelie  38.7  19.0  195  3450    Adelie  42.5  20.7  197  4500    Adelie  34.4  18.4  184  3325    Adelie  46.0  21.5  194  4200    Adelie  37.8  18.3  174  3400     We’ll fit random forest models with the ranger package, which works as follows:\n#fitting classification model m \u0026lt;- ranger::ranger( data = penguins, dependent.variable.name = \u0026quot;species\u0026quot;, importance = \u0026quot;permutation\u0026quot; ) #summary m ## Ranger result ## ## Call: ## ranger::ranger(data = penguins, dependent.variable.name = \u0026quot;species\u0026quot;, importance = \u0026quot;permutation\u0026quot;) ## ## Type: Classification ## Number of trees: 500 ## Sample size: 342 ## Number of independent variables: 4 ## Mtry: 2 ## Target node size: 1 ## Variable importance mode: permutation ## Splitrule: gini ## OOB prediction error: 2.63 % #variable importance m$variable.importance ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 0.30537983 0.16399290 0.22290424 0.07972736 The output shows that the percentage of misclassified cases is 2.63, and that bill_length_mm is the variable that contributes the most to the accuracy of the classification.\nIf you are not familiar with random forest, this post and the video below do a pretty good job in explaining the basics:\n Tuning random forest hyperparameters Random forest has several hyperparameters that influence model fit:\n num.trees is the total number of trees to fit. The default value is 500. mtry is the number of variables selected by chance (from the total pool of variables) as candidates for a tree split. The minimum is 2, and the maximum is the total number of predictors. min.node.size is the minimum number of cases that shall go together in the terminal nodes of each tree. For classification models as the ones we are going to fit, 1 is the minimum.  Here we are going to explore how combinations of these values increase or decrease the prediction error of the model (percentage of misclassified cases) on the out-of-bag data (not used to train each decision tree). To create these combinations of hyperparameters we use expand.grid().\nsensitivity.df \u0026lt;- expand.grid( num.trees = c(500, 1000, 1500), mtry = 2:4, min.node.size = c(1, 10, 20) )    num.trees  mtry  min.node.size      500  2  1    1000  2  1    1500  2  1    500  3  1    1000  3  1    1500  3  1    500  4  1    1000  4  1    1500  4  1    500  2  10    1000  2  10    1500  2  10    500  3  10    1000  3  10    1500  3  10    500  4  10    1000  4  10    1500  4  10    500  2  20    1000  2  20    1500  2  20    500  3  20    1000  3  20    1500  3  20    500  4  20    1000  4  20    1500  4  20     Each row in sensitivity.df corresponds to a combination of parameters to test, so there are 27 models to fit. The code below prepares the cluster, and uses the ability of foreach to work with several iterators at once to easily introduce the right set of hyperparameters to each fitted model.\nNotice how in the foreach definition I use the .packages argument to export the ranger package to the environments of the workers.\n#create and register cluster my.cluster \u0026lt;- parallel::makeCluster(n.cores) doParallel::registerDoParallel(cl = my.cluster) #fitting each rf model with different hyperparameters prediction.error \u0026lt;- foreach( num.trees = sensitivity.df$num.trees, mtry = sensitivity.df$mtry, min.node.size = sensitivity.df$min.node.size, .combine = \u0026#39;c\u0026#39;, .packages = \u0026quot;ranger\u0026quot; ) %dopar% { #fit model m.i \u0026lt;- ranger::ranger( data = penguins, dependent.variable.name = \u0026quot;species\u0026quot;, num.trees = num.trees, mtry = mtry, min.node.size = min.node.size ) #returning prediction error as percentage return(m.i$prediction.error * 100) } #adding the prediction error column sensitivity.df$prediction.error \u0026lt;- prediction.error To plot the results:\nggplot2::ggplot(data = sensitivity.df) + ggplot2::aes( x = mtry, y = as.factor(min.node.size), fill = prediction.error ) + ggplot2::facet_wrap(as.factor(num.trees)) + ggplot2::geom_tile() + ggplot2::scale_y_discrete(breaks = c(1, 10, 20)) + ggplot2::scale_fill_viridis_c() + ggplot2::ylab(\u0026quot;min.node.size\u0026quot;) The figure shows that combinations of lower values of min.node.size and mtry generally lead to models with a lower prediction error across different numbers of trees. Retrieving the first line of sensitivity.df ordered by ascending prediction.error will give us the values of the hyperparameters we need to use to reduce the prediction error as much as possible.\nbest.hyperparameters \u0026lt;- sensitivity.df %\u0026gt;% dplyr::arrange(prediction.error) %\u0026gt;% dplyr::slice(1)    num.trees  mtry  min.node.size  prediction.error      1000  2  1  2.339181      Confidence intervals of variable importance scores Random forest has an important stochastic component during model fitting, and as consequence, the same model will return slightly different results in different runs (unless set.seed() or the seed argument of ranger are used). This variability also affects the importance scores of the predictors, and can be use to our advantage to assess whether the importance scores of different variables do really overlap or not.\nI have written a little function to transform the vector of importance scores returned by ranger into a data frame (of one row). It helps arranging the importance scores of different runs into a long format, which helps a lot to plot a boxplot with ggplot2 right away. This function could have been just some code thrown inside the foreach loop, but I want to illustrate how foreach automatically transfers functions available in the R environment into the environments of the workers when required, without the intervention of the user. The same will happen with the best.hyperparameters tiny data frame we created in the previous section.\nimportance_to_df \u0026lt;- function(model){ x \u0026lt;- as.data.frame(model$variable.importance) x$variable \u0026lt;- rownames(x) colnames(x)[1] \u0026lt;- \u0026quot;importance\u0026quot; rownames(x) \u0026lt;- NULL return(x) } The code chunk below setups the cluster and runs 1000 random forest models in parallel (using the best hyperparameters computed in the previous section) while using system.time() to assess running time.\n#we don\u0026#39;t need to create the cluster, it is still up print(my.cluster) ## socket cluster with 7 nodes on host \u0026#39;localhost\u0026#39; #assessing execution time system.time( #performing 1000 iterations in parallel importance.scores \u0026lt;- foreach( i = 1:1000, .combine = \u0026#39;rbind\u0026#39;, .packages = \u0026quot;ranger\u0026quot; ) %dopar% { #fit model m.i \u0026lt;- ranger::ranger( data = penguins, dependent.variable.name = \u0026quot;species\u0026quot;, importance = \u0026quot;permutation\u0026quot;, mtry = best.hyperparameters$mtry, num.trees = best.hyperparameters$num.trees, min.node.size = best.hyperparameters$min.node.size ) #format importance m.importance.i \u0026lt;- importance_to_df(model = m.i) #returning output return(m.importance.i) } ) ## user system elapsed ## 0.280 0.029 11.749 The output of system.time() goes as follows:\n user: seconds the R session has been using the CPU. system: seconds the operating system has been using the CPU. elapsed: the total execution time experienced by the user.  This will make sense in a minute. In the meantime, let’s plot our results!\nggplot2::ggplot(data = importance.scores) + ggplot2::aes( y = reorder(variable, importance), x = importance ) + ggplot2::geom_boxplot() + ggplot2::ylab(\u0026quot;\u0026quot;) The figure shows that the variable bill_length_mm is the most important in helping the model classifying penguin species, with no overlap with any other variable. In this particular case, since the distributions of the importance scores do not overlap, this analysis isn’t truly helpful, but now you know how to do it!\nI assessed the running time with system.time() because ranger() can run in parallel by itself just by setting the num.threads argument to the number of cores available in the machine. This capability cannot be used when executing ranger() inside a parallelized foreach loop though, and it is only useful inside classic for loops.\nWhat option is more efficient then? The code below executes a regular for loop running the function sequentially to evaluate whether it is more efficient to run ranger() in parallel using one core per model, as we did above, or sequentially while using several cores per model on each iteration.\n#list to save results importance.scores.list \u0026lt;- list() #performing 1000 iterations sequentially system.time( for(i in 1:1000){ #fit model m.i \u0026lt;- ranger::ranger( data = penguins, dependent.variable.name = \u0026quot;species\u0026quot;, importance = \u0026quot;permutation\u0026quot;, seed = i, num.threads = parallel::detectCores() - 1 ) #format importance importance.scores.list[[i]] \u0026lt;- importance_to_df(model = m.i) } ) ## user system elapsed ## 42.972 2.826 12.978 As you can see, ranger() takes longer to execute in a regular for loop using several cores at once than in a parallel foreach loop using one core at once. That’s a win for the parallelized loop!\nWe can stop our cluster now, we are done with it.\nparallel::stopCluster(cl = my.cluster)    A few things to take in mind As I have shown in this post, using parallelized foreach loops can accelerate long computing processes, even when some functions have the ability to run in parallel on their own. However, there are things to take in mind, that might vary depending on whether we are executing the parallelized task on a single computer or on a small cluster.\nIn a single computer, the communication between workers and the director is usually pretty fast, so there are no obvious bottlenecks to take into account here. The only limitation that might arise comes from the availability of RAM memory. For example, if a computer has 8 cores and 8GB of RAM, less than 1GB of RAM will be available for each worker. So, if you need to repeat a process that consumes a significant amount of RAM, the ideal number of cores running in parallel might be lower than the total number of cores available in your system. Don’t be greedy, and try to understand the capabilities of your machine while designing a parallelized task.\nWhen running foreach loops as in x \u0026lt;- foreach(...){...}, the variable x is receiving whatever results the workers are producing. For example, if you are only returning the prediction error of a model, or its importance scores, x will have a very manageable size. But if you are returning heavy objects such as complete random forest models, the size of x is going to grow VERY FAST, and at the end it will be competing for RAM resources with the workers, which might even crash your R session. Again, don’t be greedy, and size your outputs carefully.\nClusters spanning several computers are a different beast, since the workers and the director communicate through a switch and network wires and interfaces. If the amount of data going to and coming from the workers is large, the network can get clogged easily, reducing the cluster’s efficiency drastically. In general, if the amount of data produced by a worker on each iteration takes longer to arrive to the director than the time it takes the worker to produce it, then a cluster is not going to be more efficient than a single machine. But this is not important if you don’t care about efficiency.\nOther issues you might come across while parallelizing tasks in R are thoroughly commented in this post, by Imre Gera.\nThat’s all for now folks, happy parallelization!\n ","date":1608940800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608940800,"objectID":"258c4372b0dc8ca13f2e28fc8d34faa5","permalink":"/post/02_parallelizing_loops_with_r/","publishdate":"2020-12-26T00:00:00Z","relpermalink":"/post/02_parallelizing_loops_with_r/","section":"post","summary":"Note: to better follow this tutorial you can download the .Rmd file from here.\nIn a previous post I explained how to set up a small home cluster.","tags":null,"title":"Parallelized loops with R","type":"post"},{"authors":null,"categories":null,"content":"   \nThe package distantia allows to measure the dissimilarity between multivariate time-series. The package assumes that the target sequences are ordered along a given dimension, being depth and time the most common ones, but others such as latitude or elevation are also possible. Furthermore, the target time-series can be regular or irregular, and have their samples aligned (same age/time/depth) or unaligned (different age/time/depth). The only requirement is that the sequences must have at least two (but ideally more) columns with the same name and units representing different variables relevant to the dynamics of a system of interest.\nThe GitHub page of the project contains a thorough explanation of the statistics behind the method. The paper published in the Ecography journal describes the method, the package, and a couple of practical examples. The code and data used to develop the examples can be found in GitHub and Zenodo.\nPlease, if you find this package useful, please cite it as:\nBenito, B.M. and Birks, H.J.B. (2020), distantia: an open‐source toolset to quantify dissimilarity between multivariate ecological time‐series. Ecography, 43: 660-667. https://doi.org/10.1111/ecog.04895\n","date":1608336000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608336000,"objectID":"a64ca32d94825ca0e1d3efdede85f5d0","permalink":"/project/distantia/","publishdate":"2020-12-19T00:00:00Z","relpermalink":"/project/distantia/","section":"project","summary":"R package to compare multivariate time-series.","tags":["R packages","Time Series Analysis"],"title":"R package \"distantia\"","type":"project"},{"authors":null,"categories":null,"content":"   \nThe goal of memoria is to provide the tools to quantify ecological memory in long time-series involving environmental drivers and biotic responses, including palaeoecological datasets.\nEcological memory has two main components: the endogenous component, which represents the effect of antecedent values of the response on itself, and endogenous component, which represents the effect of antecedent values of the driver or drivers on the current state of the biotic response. Additionally, the concurrent effect, which represents the synchronic effect of the environmental drivers over the response is measured. The functions in the package allow the user\nThe package memoria uses the fast implementation of Random Forest available in the ranger package to fit a model of the form shown in Equation 1:\nEquation 1 (simplified from the one in the paper): $$p_{t} = p_{t-1} +\u0026hellip;+ p_{t-n} + d_{t} + d_{t-1} +\u0026hellip;+ d_{t-n}$$\nWhere:\n $p$ is the response variable, Pollen counts were used in this particular case.. $d$ is an environmental Driver influencing the response variable. $t$ is the time of any given value of the response $p$. $t-1$ is the lag 1. $p_{t-1} +\u0026hellip;+ p_{t-n}$ represents the endogenous component of ecological memory. $d_{t-1} +\u0026hellip;+ d_{t-n}$ represents the exogenous component of ecological memory. $d_{t}$ represents the concurrent effect of the driver over the response.  Random Forest returns an importance score for each model term, and the functions in memoria let the user to plot the importance scores across time lags for each ecological memory components, and to compute different features of each memory component (length, strength, and dominance).\nThe GitHub page of the package features complete examples on how to use the package. The paper published in the Ecography journal describes ecological memory concepts and the method based on Random Forest used to assess ecological memory components. The code used to generate the supplementary materials can be found in GitHub and Zenodo.\nIf you ever use the package, please, cite it as:\nBenito, B.M., Gil‐Romera, G. and Birks, H.J.B. (2020), Ecological memory at millennial time‐scales: the importance of data constraints, species longevity and niche features. Ecography, 43: 1-10. https://doi.org/10.1111/ecog.04772\n","date":1608336000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608336000,"objectID":"b2480e8e20be7bd9954b85358f24acc6","permalink":"/project/memoria/","publishdate":"2020-12-19T00:00:00Z","relpermalink":"/project/memoria/","section":"project","summary":"R package to assess ecological memory in multivariate time-series.","tags":["R packages","Ecological Memory","Time Series Analysis","Machine Learning","Random Forest"],"title":"R package \"memoria\"","type":"project"},{"authors":null,"categories":null,"content":"  \nThe goal of virtualPollen is to provide the tools to simulate pollen curves over millenial time-scales generated by virtual taxa with different life traits (life-span, fecundity, growth-rate) and niche features (niche position and breadth) as a response to virtual environmental drivers with a given temporal autocorrelation. It furthers allow to simulate specific data properties of fossil pollen datasets, such as sediment accumulation rate, and depth intervals between consecutive pollen samples. The simulation outcomes are useful to better understand the role of plant traits, niche properties, and climatic variability in defining the shape of pollen curves.\nThe GitHub page of the package offers a complete tutorial on how to use the package. The paper published in the Ecography journal describes the foundations of the model in brief.\nIf you ever use the package, please, cite it as:\nBenito, B.M., Gil‐Romera, G. and Birks, H.J.B. (2020), Ecological memory at millennial time‐scales: the importance of data constraints, species longevity and niche features. Ecography, 43: 1-10. https://doi.org/10.1111/ecog.04772\n","date":1608336000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608336000,"objectID":"f3afdae9d91edee9e3abcdfb020c263f","permalink":"/project/virtualpollen/","publishdate":"2020-12-19T00:00:00Z","relpermalink":"/project/virtualpollen/","section":"project","summary":"R package to simulate pollen production of mono-specific tree populations over millennia.","tags":["R packages","Time Series Analysis","Palaeoecology","Mechanistic simulation"],"title":"R package \"vitualPollen\"","type":"project"},{"authors":null,"categories":null,"content":"In this post I explain how to setup a small Beowulf cluster with a personal PC running Ubuntu 20.04 and a couple of Intel NUCs running Ubuntu Server 20.04, with the end-goal of parallelizing R tasks.\nThe topics I cover here are:\n Required material Network setting Installing the secure shell protocol Installing Ubuntu server in the NUCs Installing R in the NUCs Managing the cluster\u0026rsquo;s network   Preamble I have a little but nice HP ENVY model TE01-0008ns with 32 GB RAM, 8 CPUs, and 3TB of hard disk running Ubuntu 20.04 that I use to do all my computational work (and most of my tweeting). A few months ago I connected it with my two laptops (one of them deceased now, RIP my dear skynet) to create a little cluster to run parallel tasks in R.\nToday I made a home cluster to spread parallel R tasks across all my computers. That was fun! #rstats pic.twitter.com/ic4plvO3Y6\n\u0026mdash; Blas M. Benito (@BlasBenito) April 27, 2020  It was just a draft cluster running on a wireless network, but it served me to think about getting a more permanent solution not requiring two additional laptops in my desk.\nThat\u0026rsquo;s were the nice INTEL NUCs (from Next Unit of Computing) come into play. NUCs are full-fledged computers fitted in small boxes usually sold without RAM memory sticks and no hard disk (hence the term barebone). Since they have a low energy consumption footprint, I thought these would be ideal units for my soon-to-be home cluster.\n Material I gifted myself with:\n 2 Intel Barebone BOXNUC6CAYH, each with 4 cores, and a maximum RAM memory of 32GB (you might read they only accept 8GB, but that\u0026rsquo;s not the case anymore). Notice that these NUCs aren\u0026rsquo;t state-of-the-art now, they were released by the end of 2016. 2 Hard disks SSD 2.5\u0026rdquo; Western Digital WDS250G2B0A WD Blue (250GB) 4 Crucial CT102464BF186D DDR3 SODIMM (204 pins) RAM sticks with 8GB each. 1 ethernet switch Netgear GS308-300PES with 8 ports. 3 ethernet wires NanoCable 10.20.0400-BL of cat 6 quality.  The whole set came to cost around 530€, but please notice that I had a clear goal in mind: \u0026ldquo;duplicating\u0026rdquo; my computing power with the minimum number of NUCs, while preserving a share of 4GB of RAM memory per CPU throughout the cluster (based on the features of my desk computer). A more basic setting with more modest NUCs and smaller RAM would cost half of that.\nThis instructive video by David Harry shows how to install the SSD and the RAM sticks in an Intel NUC. It really takes 5 minutes tops, one only has to be a bit careful with the RAM sticks, the pins need to go all the way in into their slots before securing the sticks in place.\n   Network settings Before starting to install an operating system in the NUCS, the network setup goes as follows:\n My desktop PC is connected to a router via WIFI and dynamic IP (DHCP). The PC and each NUC are connected to the switch with cat6 ethernet wires.  To share my PC\u0026rsquo;s WIFI connection with the NUCs I have to prepare a new connection profile with the command line tool of Ubuntu\u0026rsquo;s NetworkManager, named nmcli, as follows.\nFirst, I need to find the name of my ethernet interface by checking the status of my network devices with the command line.\nnmcli device status DEVICE TYPE STATE CONNECTION wlp3s0 wifi connected my_wifi enp2s0 ethernet unavailable -- lo loopback unmanaged --  There I can see that my ethernet interface is named enp2s0.\nSecond, I have to configure the shared connection.\nnmcli connection add type ethernet ifname enp2s0 ipv4.method shared con-name cluster  Were ifname enp2s0 is the name of the interface I want to use for the new connection, ipv4.method shared is the type of connection, and con-name cluster is the name I want the connection to have. This operation adds firewall rules to manage traffic within the cluster network, starts a DHCP server in the computer that serves IPs to the NUCS, and a DNS server that allows the NUCs to translate internet addresses.\nAfter turning on the switch, I can check the connection status again with\nnmcli device status DEVICE TYPE STATE CONNECTION enp2s0 ethernet connected cluster wlp3s0 wifi connected my_wifi lo loopback unmanaged --  When checking the IP of the device with bash ifconfig it should yield 10.42.0.1. Any other computer in the cluster network will have a dynamic IP in the range 10.42.0.1/24.\nFurther details about how to set a shared connection with NetworkManager can be found in this nice post by Beniamino Galvani.\n SSH setup My PC, as the director of the cluster, needs an SSH client running, while the NUCs need an SSH server. SSH (Secure Shell) is a remote authentication protocol that allows secure connections to remote servers that I will be using all the time to manage the cluster. To install, run, and check its status I just have to run these lines in the console:\nsudo apt install ssh sudo systemctl enable --now ssh sudo systemctl status ssh  Now, a secure certificate of the identity of a given computer, named ssh-key, that grants access to remote ssh servers and services needs to be generated.\nssh-keygen \u0026quot;label\u0026quot;  Here, substitute \u0026ldquo;label\u0026rdquo; by the name of the computer to be used as cluster\u0026rsquo;s \u0026ldquo;director\u0026rdquo;. The system will ask for a file name and a passphrase that will be used to encrypt the ssh-key.\nThe ssh-key needs to be added to the ssh-agent.\nssh-add ~/.ssh/id_rsa  To copy the ssh-key to my GitHub account, I have to copy the contents of the file ~/.ssh/id_rsa.pub (can be done just opening it with gedit ~/.ssh/id_rsa.pub + Ctrl + a + Ctrl + c), and paste it on GitHub account \u0026gt; Settings \u0026gt; SSH and GPG keys \u0026gt; New SSH Key (green button in the upper right part of the window).\nNote: If you don\u0026rsquo;t use GitHub, you\u0026rsquo;ll need to copy your ssh-key to the NUCs once they are up and running with ssh-copy-id -i ~/.ssh/id_rsa.pub user_name@nuc_IP.\n Installing and preparing ubuntu server in each NUC The NUCs don\u0026rsquo;t need to waste resources in a user graphical interface I won\u0026rsquo;t be using whatsoever. Since they will work in a headless configuration once the cluster is ready, a Linux distro without graphical user interface such as Ubuntu server is the way to go.\n Installing Ubuntu server First it is important to connect a display, a keyboard, and a mouse to the NUC in preparation, and turn it on while pushing F2 to start the visual BIOS. These BIOS parameters need to be modified:\n Advanced (upper right) \u0026gt; Boot \u0026gt; Boot Configuration \u0026gt; UEFI Boot \u0026gt; OS Selection: Linux Advanced \u0026gt; Boot \u0026gt; Boot Configuration \u0026gt; UEFI Boot \u0026gt; OS Selection: mark \u0026ldquo;Boot USB Devices First\u0026rdquo;. [optional] Advanced \u0026gt; Power \u0026gt; Secondary Power Settings \u0026gt; After Power Failure: \u0026ldquo;Power On\u0026rdquo;. I have the switch and nucs connected to an outlet plug extender with an interrupter. When I switch it on, the NUCs (and the switch) boot automatically after this option is enabled, so I only need to push one button to power up the cluster. F10 to save, and shutdown.  To prepare the USB boot device with Ubuntu server 20.04 I first download the .iso from here, by choosing \u0026ldquo;Option 3\u0026rdquo;, which leads to the manual install. Once the .iso file is downloaded, I use Ubuntu\u0026rsquo;s Startup Disk Creator to prepare a bootable USB stick. Now I just have to plug the stick in the NUC and reboot it.\nThe Ubuntu server install is pretty straightforward, and only a few things need to be decided along the way:\n As user name I choose the same I have in my personal computer. As name for the NUCs I choose \u0026ldquo;nuc1\u0026rdquo; and \u0026ldquo;nuc2\u0026rdquo;, but any other option will work well. As password, for comfort I use the same I have in my personal computer. During the network setup, choose DHCP. If the network is properly configured and the switch is powered on, after a few seconds the NUC will acquire an IP in the range 10.42.0.1/24, as any other machine within the cluster network. When asked, mark the option \u0026ldquo;Install in the whole disk\u0026rdquo;, unless you have other plans for your NUC. Mark \u0026ldquo;Install OpenSSH\u0026rdquo;. Provide it with your GitHub user name if you have your ssh-key there, and it will download it right away, facilitating a lot the ssh setup.  Reboot once the install is completed. Now I keep configuring the NUC\u0026rsquo;s operating system from my PC through ssh.\n Configuring a NUC First, to learn the IP of the NUC:\nsudo arp-scan 10.42.0.1/24  Other alternatives to this command are arp -a and sudo arp-scan -I enp2s0 --localnet. Once I learn the IP of the NUC, I add it to the file etc/hosts of my personal computer as follows.\nFirst I open the file as root.\nsudo gedit /etc/hosts  Add a new line there: 10.42.0.XXX nuc1 and save the file.\nNow I access the NUC trough ssh to keep preparing it without a keyboard and a display. I do it from Tilix, that allows to open different command line tabs in the same window, which is quite handy to manage several NUCs at once.\nAnother great option to manage the NUCs through ssh is terminator, that allows to broadcast the same commands to several ssh sessions at once. I have been trying it, and it is much better for cluster management purposes than Tilix. Actually, using it would simplify this workflow a lot, because once Ubuntu server is installed on each NUC, the rest of the configuration commands can be broadcasted at once to both NUCs. It\u0026rsquo;s a bummer I discovered this possibility way too late!\nssh blas@10.42.0.XXX  The NUC\u0026rsquo;s operating system probably has a bunch of pending software updates. To install these:\nsudo apt-get upgrade  Now I have to install a set of software packages that will facilitate managing the cluster\u0026rsquo;s network and the NUC itself.\nsudo apt install net-tools arp-scan lm-sensors dirmngr gnupg apt-transport-https ca-certificates software-properties-common samba libopenmpi3 libopenmpi-dev openmpi-bin openmpi-common htop   Setting the system time To set the system time of the NUC to the same you have in your computer, just repeat these steps in every computer in the cluster network.\n#list time zones: timedatectl list-timezones #set time zone sudo timedatectl set-timezone Europe/Madrid #enable timesyncd sudo timedatectl set-ntp on   Setting the locale The operating systems of the NUCs and the PC need to have the same locale. It can be set by editing the file /etc/default/locale with either nano (in the NUCS) or gedit (in the PC) and adding these lines, just replacing en_US.UTF-8 with your preferred locale.\nLANG=\u0026quot;en_US.UTF-8\u0026rdquo;\nLANGUAGE=\u0026quot;en_US:en\u0026rdquo;\nLC_NUMERIC=\u0026quot;en_US.UTF-8\u0026rdquo;\nLC_TIME=\u0026quot;en_US.UTF-8\u0026rdquo;\nLC_MONETARY=\u0026quot;en_US.UTF-8\u0026rdquo;\nLC_PAPER=\u0026quot;en_US.UTF-8\u0026rdquo;\nLC_IDENTIFICATION=\u0026quot;en_US.UTF-8\u0026rdquo;\nLC_NAME=\u0026quot;en_US.UTF-8\u0026rdquo;\nLC_ADDRESS=\u0026quot;en_US.UTF-8\u0026rdquo;\nLC_TELEPHONE=\u0026quot;en_US.UTF-8\u0026rdquo;\nLC_MEASUREMENT=\u0026quot;en_US.UTF-8\u0026rdquo;\n Temperature monitoring NUCs are prone to overheating when under heavy loads for prolonged times. Therefore, monitoring the temperature of the NUCs CPUs is kinda important. In a step before I installed lm-sensors in the NUC, which provides the tools to do so. To setup the sensors from an ssh session in the NUC:\nsudo sensors-detect  The program will request permission to find sensors in the NUC. I answered \u0026ldquo;yes\u0026rdquo; to every request. Once all sensors are identified, to check them\nsensors iwlwifi_1-virtual-0 Adapter: Virtual device temp1: N/A acpitz-acpi-0 Adapter: ACPI interface temp1: +32.0°C (crit = +100.0°C) coretemp-isa-0000 Adapter: ISA adapter Package id 0: +30.0°C (high = +105.0°C, crit = +105.0°C) Core 0: +30.0°C (high = +105.0°C, crit = +105.0°C) Core 1: +30.0°C (high = +105.0°C, crit = +105.0°C) Core 2: +29.0°C (high = +105.0°C, crit = +105.0°C) Core 3: +30.0°C (high = +105.0°C, crit = +105.0°C)  which gives the cpu temperatures at the moment the command was executed. The command watch sensors gives continuous temperature readings instead.\nTo control overheating in my NUCs I removed their top lids, and installed them into a custom LEGO \u0026ldquo;rack\u0026rdquo; with external USB fans with velocity control, as shown in the picture at the beginning of the post.\n Installing R To install R in the NUCs I just proceed as I would when installing it in my personal computer. There is a thorough guide here.\nIn a step above I installed all the pre-required software packages. Now I only have to add the security key of the R repository, add the repository itself, update the information on the packages available in the new repository, and finally install R.\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9 sudo add-apt-repository 'deb https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/' sudo apt update sudo apt install r-base  Note: If R has issues to recognize the system locale\nnano ~/.profile  add the following lines, replacing en_US.UTF-8 with your preferred locale\nexport LANG=en_US.UTF-8 export LC_ALL=en_US.UTF-8\nsave, and execute the file to export the locale so R can read it.\n. ~/.profile   Finalizing the network configuration Each NUC needs firewall rules to grant access from other computers withinn the cluster network. To activate the NUC\u0026rsquo;s firewall and check what ports are open:\nsudo ufw enable sudo ufw status  To grant access from the PC to the NUC through ssh, and later through R for parallel computing, the ports 22 and 11000 must be open for the IP of the PC (10.42.0.1).\nsudo ufw allow ssh sudo ufw allow from 10.42.0.1 to any port 11000 sudo ufw allow from 10.42.0.1 to any port 22  Finally, the other members of the cluster network must be declared in the /etc/hosts file of each computer.\nIn each NUC edit the file through ssh with bash sudo nano /etc/hosts and add the lines\n10.42.0.1 pc_name\n10.42.0.XXX name_of_the_other_nuc\nIn the PC, add the lines\n10.42.0.XXX name_of_one_nuc\n10.42.0.XXX name_of_the_other_nuc\nAt this point, after rebooting every machine, the NUCs must be accessible through ssh by using their names (ssh username@nuc_name) instead of their IPs (ssh username@n10.42.0.XXX). Just take in mind that, since the cluster network works with dynamic IPs (and such setting cannot be changed in a shared connection), the IPs of the NUCs might change if a new device is added to the network. That\u0026rsquo;s something you need to check from the PC with sudo arp-scan 10.42.0.1/24, to update every /etc/hosts file accordingly.\nI think that\u0026rsquo;s all folks. Good luck setting your home cluster! Next time I will describe how to use it for parallel computing in R.\n","date":1607299200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607299200,"objectID":"ead52a439ba25afd3dd271401b5f5734","permalink":"/post/01_home_cluster/","publishdate":"2020-12-07T00:00:00Z","relpermalink":"/post/01_home_cluster/","section":"post","summary":"In this post I explain how to setup a small Beowulf cluster with a personal PC running Ubuntu 20.04 and a couple of Intel NUCs running Ubuntu Server 20.04, with the end-goal of parallelizing R tasks.","tags":null,"title":"Setting up a home cluster","type":"post"},{"authors":["Masahiro Ryo","Boyan Angelov","Stefano Mammola","Jamie M. Kass","Blas M. Benito","Florian Hartig"],"categories":null,"content":"","date":1605571200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605571200,"objectID":"a92328360ad8f6c7395efe736f4f34e3","permalink":"/publication/2020_ryo_ecography/","publishdate":"2020-11-17T00:00:00Z","relpermalink":"/publication/2020_ryo_ecography/","section":"publication","summary":"Here we draw attention to an emerging subdiscipline of artificial intelligence, explainable AI (xAI), as a toolbox for better interpreting SDMs. xAI aims at deciphering the behavior of complex statistical or machine learning models (e.g. neural networks, random forests, boosted regression trees), and can produce more transparent and understandable SDM predictions.","tags":["Species Distribution Models","Explainable Artificial Intelligence (xAI)"],"title":"Explainable artificial intelligence enhances the ecological interpretability of black‐box species distribution models","type":"publication"},{"authors":["Andrea Contina","Scott W. Yanco","Allison K. Pierce","Michelle DePrenger-Levin","Michael B. Wunder","Andreas M. Neophytou","C. Phoebe Lostroh","Richard J. Telford","Blas M. Benito","Joseph Chipperfield","Robert B. O'Hara","Colin J. Carlson"],"categories":null,"content":"","date":1600646400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600646400,"objectID":"70fd84519cc7f0520ad6720d1a1a28e9","permalink":"/publication/2020_contina_ecological_modelling/","publishdate":"2020-09-21T00:00:00Z","relpermalink":"/publication/2020_contina_ecological_modelling/","section":"publication","summary":"In this letter we present comments on the article “A global-scale ecological niche model to predict SARS-CoV-2 coronavirus” by Coro published in 2020.","tags":["Irresponsible Covid19 modelling","Species Distribution Models"],"title":"Comment on “A global-scale ecological niche model to predict SARS-CoV-2 coronavirus infection rate”, author Coro","type":"publication"},{"authors":["Colin J. Carlson","Joseph D. Chipperfield","Blas M. Benito","Richard J. Telford","Robert B. O'Hara"],"categories":null,"content":"","date":1595980800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595980800,"objectID":"0e2abe2a1f21b5de5d214beb5a8e28a3","permalink":"/publication/2020_carlson_nature_ecology_and_evolution/","publishdate":"2020-07-29T00:00:00Z","relpermalink":"/publication/2020_carlson_nature_ecology_and_evolution/","section":"publication","summary":"Araújo et al. have published a response to our piece ‘Species distribution models are inappropriate for COVID-19’1 entitled ‘Ecological and epidemiological models are both useful for SARS-CoV-2’2, in which they defend the idea that ecological models are likely to identify the signature of climate drivers in the R0 of COVID-19 transmission.","tags":["Irresponsible Covid19 modelling","Species Distribution Models"],"title":"Don’t gamble the COVID-19 response on ecological hypotheses","type":"publication"},{"authors":["Quai.Yu Cui","Marie-José Gaillard","Boris Vannière","Daniele Colombaroli","Geoffrey Lemdahl","Fredrik Olsson","Blas M. Benito","Yan Zhao"],"categories":null,"content":"","date":1594684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594684800,"objectID":"b0ae2a004a1861145db6167d8ae1d7f1","permalink":"/publication/2020_cui_the_holocene/","publishdate":"2020-07-14T00:00:00Z","relpermalink":"/publication/2020_cui_the_holocene/","section":"publication","summary":"In this study, we assess how representative a single charcoal record from a peat profile in small bogs (1.5–2 ha in area) is for the reconstruction of Holocene fire history.","tags":["Palaeoecology","Time Series Analysis"],"title":"Evaluating fossil charcoal representation in small peat bogs: Detailed Holocene fire records from southern Sweden","type":"publication"},{"authors":["Constantin M. Zohner","Lidong Mo","Susanne S. Renner","Jens-Christian Svenning","Yann Vitasse","Blas M. Benito","Alejandro Ordonez","Frederik Baumgarten","Jean-François Bastin","Veronica Sebald","Peter B. Reich","Jingjing Liang","Gert-Jan Nabuurs","Sergio de-Miguel","Giorgio Alberti","Clara Antón-Fernández","Radomir Balazy","Urs-Beat Brändli","Han Y. H. Chen","Chelsea Chisholm","Emil Cienciala","Selvadurai Dayanandan","Tom M. Fayle","Lorenzo Frizzera","Damiano Gianelle","Andrzej M. Jagodzinski","Bogdan Jaroszewicz","Tommaso Jucker","Sebastian Kepfer-Rojas","Mohammed Latif Khan","Hyun Seok Kim","Henn Korjus","Vivian Kvist Johannsen","Diana Laarmann","Mait Lang","Tomasz Zawila-Niedzwiecki","Pascal A. Niklaus","Alain Paquette","Hans Pretzsch","Purabi Saikia","Peter Schall","Vladimír Šebeň","Miroslav Svoboda","Elena Tikhonova","Helder Viana","Chunyu Zhang","Xiuhai Zhao","Thomas W. Crowther"],"categories":null,"content":"","date":1589155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589155200,"objectID":"a03c5f954b0fdb1d789e83f7b7821801","permalink":"/publication/2020_zohner_pnas/","publishdate":"2020-05-11T00:00:00Z","relpermalink":"/publication/2020_zohner_pnas/","section":"publication","summary":"Frost in late spring causes severe ecosystem damage in temperate and boreal regions. We here analyze late-spring frost occurrences between 1959 and 2017 and woody species’ resistance strategies to forecast forest vulnerability under climate change. Leaf-out phenology and leaf-freezing resistance data come from up to 1,500 species cultivated in common gardens. The greatest increase in leaf-damaging spring frost has occurred in Europe and East Asia, where species are more vulnerable to spring frost than in North America. The data imply that 35 and 26% of Europe’s and Asia’s forests are increasingly threatened by frost damage, while this is only true for 10% of North America. Phenological strategies that helped trees tolerate past frost frequencies will thus be increasingly mismatched to future conditions.","tags":["Phenology","Biogeography","Climate Change","Plant Ecology"],"title":"Late-spring frost risk between 1959 and 2017 decreased in North America but increased in Europe and Asia","type":"publication"},{"authors":["Colin J. Carlson","Joseph D. Chipperfield","Blas M. Benito","Richard J. Telford","Robert B. O'Hara"],"categories":null,"content":"","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588723200,"objectID":"bb8b41d7db5a51c063f7a5e33c256d3f","permalink":"/publication/2020_carlson_nature_ecology_and_evolution_b/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/publication/2020_carlson_nature_ecology_and_evolution_b/","section":"publication","summary":"Species distribution models are a powerful tool for ecological inference, but not every use is biologically justified. Applying these tools to the COVID-19 pandemic is unlikely to yield new insights, and could mislead policymakers at a critical moment.","tags":["Irresponsible Covid19 modelling","Species Distribution Models"],"title":"Species distribution models are inappropriate for COVID-19","type":"publication"},{"authors":["María Leunda","Graciela Gil-Romera","Anne-Laure Daniau","Blas M. Benito","Penélope González-Sampériz"],"categories":null,"content":"","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"48d1b269836f2685996b5ccae758bec5","permalink":"/publication/2020_leunda_catena/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/publication/2020_leunda_catena/","section":"publication","summary":"In this paper we aim to (1) reconstruct the Holocene fire history at high altitudes of the southern Central Pyrenees, (2) add evidence to the debate on fire origin, naturally or anthropogenically produced, (3) determine the importance of fire as a disturbance agent for sub-alpine and alpine vegetation, in comparison with the plant community internal dynamics.","tags":["Palaeoecology","Fire dynamics","Ecological Memory","Generalized Least Squares","Plant Ecology"],"title":"Holocene fire and vegetation dynamics in the Central Pyrenees (Spain)","type":"publication"},{"authors":["Felde, V. A.","...","Blas M. Benito","et al."],"categories":null,"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"0945150d072317bd056f82234adf52f5","permalink":"/publication/2020_felde_vegetation_history_and_archaeobotany/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/publication/2020_felde_vegetation_history_and_archaeobotany/","section":"publication","summary":"The Eemian interglacial represents a natural experiment on how past vegetation with negligible human impact responded to amplified temperature changes compared to the Holocene. Here, we assemble 47 carefully selected Eemian pollen sequences from Europe to explore geographical patterns of (1) total compositional turnover and total variation for each sequence and (2) stratigraphical turnover between samples within each sequence using detrended canonical correspondence analysis, multivariate regression trees, and principal curves. Our synthesis shows that turnover and variation are highest in central Europe (47–55°N), low in southern Europe (south of 45°N), and lowest in the north (above 60°N). These results provide a basis for developing hypotheses about causes of vegetation change during the Eemian and their possible drivers.","tags":["Palaeoecology"],"title":"Compositional turnover and variation in Eemian pollen sequences in Europe","type":"publication"},{"authors":["Joseph D. Chipperfield","Robert B. O'Hara","Blas M. Benito","Richard J. Telford","Colin J. Carlson"],"categories":null,"content":"","date":1585353600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585353600,"objectID":"33ce384276fda207d92a8cf37bd61e01","permalink":"/publication/2020_chipperfield_ecoevorxiv/","publishdate":"2020-03-28T00:00:00Z","relpermalink":"/publication/2020_chipperfield_ecoevorxiv/","section":"publication","summary":"The ongoing pandemic of the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is causing significant damage to public health and economic livelihoods, and is putting significant strains on healthcare services globally. This unfolding emergency has prompted the preparation and dissemination of the article “Spread of SARS-CoV-2 Coronavirus likely to be constrained by climate” by Araújo and Naimi (2020). The authors present the results of an ensemble forecast made from a suite of species distribution models (SDMs), where they attempt to predict the suitability of the climate for the spread of SARS-CoV-2 over the coming months. They argue that climate is likely to be a primary regulator for the spread of the infection and that people in warm-temperate and cold climates are more vulnerable than those in tropical and arid climates. A central finding of their study is that the possibility of a synchronous global pandemic of SARS-CoV-2 is unlikely. Whilst we understand that the motivations behind producing such work are grounded in trying to be helpful, we demonstrate here that there are clear conceptual and methodological deficiencies with their study that render their results and conclusions invalid.","tags":["Irresponsible Covid19 modelling","Species Distribution Models"],"title":"On the inadequacy of species distribution models for modelling the spread of SARS-CoV-2: response to Araújo and Naimi","type":"publication"},{"authors":["Blas M. Benito"],"categories":null,"content":"","date":1579737600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579737600,"objectID":"80c7b3f2edb958819795bfdb5c63cf9b","permalink":"/publication/2020_benito_ecography_distantia/","publishdate":"2020-01-23T00:00:00Z","relpermalink":"/publication/2020_benito_ecography_distantia/","section":"publication","summary":"We introduce distantia (v1.0.1), an R package providing general toolset to quantify dissimilarity between ecological time‐series, independently of their regularity and number of samples. The functions in distantia provide the means to compute dissimilarity scores by time and by shape and assess their significance, evaluate the partial contribution of each variable to dissimilarity, and align or combine sequences by similarity.","tags":["Time Series Analysis","R packages"],"title":"distantia: an open‐source toolset to quantify dissimilarity between multivariate ecological time‐series","type":"publication"},{"authors":["Blas M. Benito","Graciela Gil-Romera"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"b54d3a6bfb2beb4f27f5c5b2a798cd55","permalink":"/publication/2020_benito_ecography_memoria/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/2020_benito_ecography_memoria/","section":"publication","summary":"Paper published in the section \"Editor's Choice\" of the *Ecography* journal. It received [an award](https://www.dropbox.com/s/oacsy1xqx4omv1b/2019_BMB_Ecography_b_top_downloaded.png?dl=1) for the number of downloads during the 12 months after its publication.","tags":["Quantitative methods","R packages","Palaeoecology","Ecological Memory","Plant Ecology","Machine Learning","Random Forest"],"title":"Ecological memory at millennial time‐scales: the importance of data constraints, species longevity and niche features","type":"publication"},{"authors":["B.L Valero-Garcés","Penélope González-Sampériz","Graciela Gil-Romera","Blas M. Benito","A. Moreno","B. Oliva-Urcia","J. Aranbarri","E. García-Prieto","M. Frugone","M. Morellón","L.J. Arnold","M. Demuro","M. Hardiman","S.P.E. Blockey","C.S. Lane"],"categories":null,"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"a61e896d35882a74ae0ea224990d2ae3","permalink":"/publication/2019_valero-garces_quaternary_geochronology/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/publication/2019_valero-garces_quaternary_geochronology/","section":"publication","summary":"We present a multidisciplinary dating approach - including radiocarbon, Uranium/Thorium series (U/Th), paleomagnetism, single-grain optically stimulated luminescence (OSL), polymineral fine-grain infrared stimulated luminescence (IRSL) and tephrochronology - used for the development of an age model for the Cañizar de Villarquemado sequence (VIL) for the last ca. 135 ka.","tags":["Palaeoecology","Age-depth modelling","Bayesian models"],"title":"A multi-dating approach to age-modelling long continental records: The 135 ka El Cañizar de Villarquemado sequence (NE Spain)","type":"publication"},{"authors":["Graciela Gil-Romera","Carole Adolf","Blas M. Benito","Lucas Bittner","Maria U. Johansson","David A. Grady","Henry F. Lamb","Bruk Lemma","Mekbib Fekadu","Bruno Glaser","Betelhem Mekonnen","Miguel Sevilla-Callejo","Michael Zech","Wolfgang Zech","Georg Miaha"],"categories":null,"content":"","date":1563926400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563926400,"objectID":"691382af0f3f50780ae78edc146f99e0","permalink":"/publication/2019_gil_romera_biology_letters/","publishdate":"2019-07-24T00:00:00Z","relpermalink":"/publication/2019_gil_romera_biology_letters/","section":"publication","summary":"We hypothesize that fire has influenced Erica communities in the Bale Mountains at millennial time-scales. To test this, we (1) identify the fire history of the Bale Mountains through a pollen and charcoal record from Garba Guracha, a lake at 3950 m.a.s.l., and (2) describe the long-term bidirectional feedback between wildfire and Erica, which may control the ecosystem's resilience.","tags":["Palaeoecology","Fire dynamics","Ecological Memory","Time Series Analysis","Generalized Least Squares","Plant Ecology"],"title":"Long-term fire resilience of the Ericaceous Belt, Bale Mountains, Ethiopia","type":"publication"},{"authors":["Blas M. Benito"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab  Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata ( front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"1f184bf285911dee5df13e26218d60b2","permalink":"/post_examples/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post_examples/jupyter/","section":"post_examples","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post_examples"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Albuquerque F.","Blas M. Benito","Rodríguez MÁM.","Gray C."],"categories":null,"content":"","date":1537315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537315200,"objectID":"0dd555719b21269ebb41f0603a2e3704","permalink":"/publication/2018_albuquerque_peerj/","publishdate":"2018-09-19T00:00:00Z","relpermalink":"/publication/2018_albuquerque_peerj/","section":"publication","summary":"The goals of this study are to provide a map of actual habitat suitability (1), describe the relationships between abiotic predictors and the saguaro distribution at regional extents (2), and describe the potential effect of climate change on the spatial distribution of the saguaro (3).","tags":["Biogeography","Climate Change","Species Distribution Models","Machine Learning","Gradient Boosting","Plant Ecology"],"title":"Potential changes in the distribution of Carnegiea gigantea under future scenarios","type":"publication"},{"authors":["Radoslav Kozma","Mette Lillie","Blas M. Benito","Jens-Christian Svenning","Jacob Höglund"],"categories":null,"content":"","date":1527552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527552000,"objectID":"2a60bd7aa28feceb59407d600d738438","permalink":"/publication/2018_kozma_ecology_and_evolution/","publishdate":"2018-05-29T00:00:00Z","relpermalink":"/publication/2018_kozma_ecology_and_evolution/","section":"publication","summary":"Here we investigated the demographic history of the willow grouse (Lagopus lagopus), rock ptarmigan (Lagopus muta), and black grouse (Tetrao tetrix) through the Late Pleistocene using two complementary methods and whole genome data. Species distribution modeling (SDM) allowed us to estimate the total range size during the Last Interglacial (LIG) and Last Glacial Maximum (LGM) as well as to indicate potential population subdivisions.","tags":["Biogeography","Climate Change","Species Distribution Models","Generalized Linear Models"],"title":"Past and potential future population dynamics of three grouse species using ecological and whole genome coalescent modeling","type":"publication"},{"authors":["Gang Feng","Ziyu Ma","Blas M. Benito","Signe Normand","Alejandro Ordoñez","Yi Jin","Lingfeng Mao","Jens-Christian Svenning"],"categories":null,"content":"","date":1500249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1500249600,"objectID":"fc5bc772c0898cc6442de19eb3810539","permalink":"/publication/2017_feng_global_ecology_and_biogeography/","publishdate":"2017-07-17T00:00:00Z","relpermalink":"/publication/2017_feng_global_ecology_and_biogeography/","section":"publication","summary":"Our results show that phylogenetically diverse assemblages with large phylogenetic age differences among species are associated with relatively high long‐term climate stability, with intra‐regional links between long‐term climate variability and phylogenetic composition especially strong in the more unstable regions. These findings point to future climate change as a key risk to the preservation of the phylogenetically diverse assemblages in regions characterized by relatively high paleoclimate stability, with China as a key example.","tags":["Biogeography","Plant Ecology"],"title":"Phylogenetic age differences in tree assemblages across the Northern Hemisphere increase with long-term climate stability in unstable regions","type":"publication"},{"authors":["Gang Feng","Lingfeng Mao","Blas M. Benito","Nathan G. Swenson","Jens-Christian Svenning"],"categories":null,"content":"","date":1493596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493596800,"objectID":"02c9b25a1d6d387966133e1a58983917","permalink":"/publication/2017_feng_biological_conservation/","publishdate":"2017-05-01T00:00:00Z","relpermalink":"/publication/2017_feng_biological_conservation/","section":"publication","summary":"In this study, for the first time, we linked the distribution of threatened species across China to current and historical changes in human population densities, cropland area, and pasture area since 1700 (at a 100 km × 100 km resolution). We find that variables describing historical changes in human impacts were consistently more strongly associated with proportions of threatened plants than variables describing current changes in human impacts. Notably, threatened plant species in China tend to be concentrated where historical anthropogenic impacts were relatively small, but anthropogenic activities have intensified relatively strongly since 1700.","tags":["Biogeography","Random Forest","Machine Learning","Biodiversity Conservation"],"title":"Historical anthropogenic footprints in the distribution of threatened plants in China","type":"publication"},{"authors":["Blas M. Benito","Jens-Christian Svenning","Trine Kellberg Nielsen","Felix Riede","Graciela Gil-Romera","Thomas Mailund","Brody Sandel"],"categories":null,"content":"","date":1493596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493596800,"objectID":"3fffb042779562c60fe874bc323131de","permalink":"/publication/2017_benito_journal_of_biogeography/","publishdate":"2017-05-01T00:00:00Z","relpermalink":"/publication/2017_benito_journal_of_biogeography/","section":"publication","summary":"This paper [was highlighted in the *Editor's Picks* section of the Science Journal](https://www.dropbox.com/s/6k308eczv7i6kbj/2017_BMB_Journal_of_Biogeography_editors_choice.pdf?dl=1), and was among the [top downloaded articles](https://www.dropbox.com/s/sowq1h4bdngmipy/2017_BMB_Journal_of_Biogeography.png?dl=1) from the *Journal of Biogeography* during the 12 months after its publication.","tags":["Biogeography","Species Distribution Models","Biogeography of Neanderthals","Generalized Linear Models","Ensemble models"],"title":"The ecological niche and distribution of Neanderthals during the Last Interglacial","type":"publication"},{"authors":["Trine Kellberg Nielsen","Blas M. Benito","Jens-Christian Svenning","Brody Sandel","Luseadra McKerracher","Felix Riede"],"categories":null,"content":"","date":1488240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488240000,"objectID":"70212c1a73a4ebfe55db225953cd1f5d","permalink":"/publication/2017_kellberg-nielsen_quaternary_international/","publishdate":"2017-02-28T00:00:00Z","relpermalink":"/publication/2017_kellberg-nielsen_quaternary_international/","section":"publication","summary":"Our results are inconsistent with the claim that climatic constraint and/or a lack of suitable habitats can fully explain the absence of Neanderthals in Southern Scandinavia during the Eemian Interglacial and Early Weichselian Glaciation. We do, however, find evidence that a geographic barrier may have impeded northerly migrations during the Eemian.","tags":["Biogeography","Biogeography of Neanderthals","Species distribution models"],"title":"Investigating Neanderthal dispersal above 55°N in Europe during the Last Interglacial Complex","type":"publication"},{"authors":["Constantin M. Zohner","Blas M. Benito","Jason D. Fridley","Jens-Christian Svenning","Susanne S. Renner"],"categories":null,"content":"","date":1487030400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487030400,"objectID":"1bf8e70c8f4c03b6d059e49a3fd0bf9b","permalink":"/publication/2017_zohner_ecology_letters/","publishdate":"2017-02-14T00:00:00Z","relpermalink":"/publication/2017_zohner_ecology_letters/","section":"publication","summary":"Intuitively, interannual spring temperature variability (STV) should influence the leaf‐out strategies of temperate zone woody species, with high winter chilling requirements in species from regions where spring warming varies greatly among years. We tested this hypothesis using experiments in 215 species and leaf‐out monitoring in 1585 species from East Asia (EA), Europe (EU) and North America (NA). The results reveal that species from regions with high STV indeed have higher winter chilling requirements, and, when grown under the same conditions, leaf out later than related species from regions with lower STV. Since 1900, STV has been consistently higher in NA than in EU and EA, and under experimentally short winter conditions NA species required 84% more spring warming for bud break, EU ones 49% and EA ones only 1%. These previously unknown continental‐scale differences in phenological strategies underscore the need for considering regional climate histories in global change models.","tags":["Phenology","Biogeography","Plant Ecology"],"title":"Spring predictability explains different leaf‐out strategies in the woody floras of North America, Europe and East Asia","type":"publication"},{"authors":["Constantin M. Zohner","Blas M. Benito","Jens-Christian Svenning","Susanne S. Renner"],"categories":null,"content":"","date":1476662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1476662400,"objectID":"8bb3d0dd4e4d13b48c7b50f18f1b7e44","permalink":"/publication/2016_zohner_nature_climate_change/","publishdate":"2016-10-17T00:00:00Z","relpermalink":"/publication/2016_zohner_nature_climate_change/","section":"publication","summary":"Our results do not support previous ideas about phenological strategies in temperate woody species (the ‘high temperature variability’ hypothesis; the ‘oceanic climate’ hypothesis; the ‘high latitude’ hypothesis). In regions with long winters, trees appear to rely on cues other than day length, such as winter chilling and spring warming. By contrast, in regions with short winters, some species—mostly from lineages with a warm-temperate or subtropical background, for example, Fagus additionally rely on photoperiodism. Therefore, photoperiod may be expected to constrain climate-driven shifts in spring leaf unfolding only at lower latitudes.","tags":["Phenology","Biogeography","Plant Ecology"],"title":"Day length unlikely to constrain climate-driven shifts in leaf-out times of northern woody plants","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d337bc1d87a46134727f7fb46c0d4efc","permalink":"/project_examples/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project_examples/external-project/","section":"project_examples","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project_examples"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"875a64698311258ca5954edf3adc2327","permalink":"/project_examples/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project_examples/internal-project/","section":"project_examples","summary":"An example of using the in-built project page.","tags":[""],"title":"Internal Project","type":"project_examples"},{"authors":["Blas M. Benito","吳恩達"],"categories":["Demo","教程"],"content":"Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\n Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n 👉 Get Started 📚 View the documentation 💬 Ask a question on the forum 👥 Chat with the community 🐦 Twitter: @source_themes @GeorgeCushen #MadeWithAcademic 💡 Request a feature or report a bug ⬆️ Updating? View the Update Guide and Release Notes ❤️ Support development of Academic:  ☕️ Donate a coffee 💵 Become a backer on Patreon 🖼️ Decorate your laptop or journal with an Academic sticker 👕 Wear the T-shirt 👩‍💻 Contribute      Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.   Key features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Academic comes with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the sun/moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\n Choose a stunning theme and font for your site. Themes are fully customizable.\nEcosystem   Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site  Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n  one-click install using your web browser (recommended)  install on your computer using Git with the Command Prompt/Terminal app  install on your computer by downloading the ZIP files  install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating  View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"a25eb5ef2134a076531687948275d21e","permalink":"/post_examples/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post_examples/getting-started/","section":"post_examples","summary":"Create a beautifully simple website in under 10 minutes.","tags":null,"title":"Academic: the website builder for Hugo","type":"post_examples"},{"authors":null,"categories":["R"],"content":" R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 fit \u0026lt;- lm(dist ~ speed, data = cars) fit ## ## Call: ## lm(formula = dist ~ speed, data = cars) ## ## Coefficients: ## (Intercept) speed ## -17.579 3.932  Including Plots You can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1)) pie( c(280, 60, 20), c(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;), col = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;), init.angle = -50, border = NA )  Figure 1: A fancy pie chart.   ","date":1437703994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437703994,"objectID":"9554380237eec0879443a7c1a234a75f","permalink":"/post_examples/2015-07-23-r-rmarkdown/","publishdate":"2015-07-23T21:13:14-05:00","relpermalink":"/post_examples/2015-07-23-r-rmarkdown/","section":"post_examples","summary":"R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown","type":"post_examples"},{"authors":["Jacquelyn L. Gill","Jessica L. Blois","Blas M. Benito","Solomon Dobrowski","Malcolm L. Hunter Jr.","Jenny L. McGuire"],"categories":null,"content":"","date":1430179200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430179200,"objectID":"aebebdc92cbf3072b7bf6d150d269b6c","permalink":"/publication/2015_gill_conservation_biology/","publishdate":"2015-04-28T00:00:00Z","relpermalink":"/publication/2015_gill_conservation_biology/","section":"publication","summary":"Paleoecology provides a valuable perspective on coarse‐filter strategies by marshaling the natural experiments of the past to contextualize extinction risk due to the emerging impacts of climate change and anthropogenic threats. We reviewed examples from the paleoecological record that highlight the strengths, opportunities, and caveats of a CNS approach. We focused on the near‐time geological past of the Quaternary, during which species were subjected to widespread changes in climate and concomitant changes in the physical environment in general.","tags":["Palaeoecology","Biodiversity conservation"],"title":"A 2.5‐million‐year perspective on coarse‐filter strategies for conserving nature's stage","type":"publication"},{"authors":["Albuquerque F.","Blas M. Benito","Beier, P.","Assunção-Albuquerque, M.J.","Cayuela, L."],"categories":null,"content":"","date":1425340800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1425340800,"objectID":"d1d254ad844854fa63cf4af98860d93d","permalink":"/publication/2015_albuquerque_naturaleza_and_conservacao/","publishdate":"2015-03-03T00:00:00Z","relpermalink":"/publication/2015_albuquerque_naturaleza_and_conservacao/","section":"publication","summary":"We had three key findings. First, dry forest is the least protected biome in Mesoamerica (4.5% protected), indicating that further action to safeguard this biome is warranted. Secondly, the poor overlap between protected areas and high-value forest conservation areas found herein may provide evidence that the establishment of protected areas may not be fully accounting for tree priority rank map. Third, high percentages of forest cover and high-value forest conservation areas still need to be represented by the protected areas network. Because deforestation rates are still increasing in this region, Mesoamerica needs funding and coordinated action by policy makers, national and local governmental and non-governmental organizations, conservationists and other stakeholders.","tags":["Biodiversity Conservation","Forests","Species Distribution Models","Random Forest","Machine Learning"],"title":"Supporting underrepresented forests in Mesoamerica","type":"publication"},{"authors":["A.J. Mendoza-Fernández","F. Martínez-Hernández","F.J. Pérez-García","J.A. Garrido Becerra","Blas M. Benito","E. Salmerón Sánchez","J. Guirado","M.E. Merlo","J.F. Mota"],"categories":null,"content":"","date":1421107200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1421107200,"objectID":"65c5f86bbc46066e9c0c0c783d5667b8","permalink":"/publication/2015_mendoza-fernandez_plant_biosystems/","publishdate":"2015-01-13T00:00:00Z","relpermalink":"/publication/2015_mendoza-fernandez_plant_biosystems/","section":"publication","summary":"*Maytenus senegalensis* subsp. *europaea* communities are unique vegetal formations in Europe. In fact, they are considered Priority Habitat by Directive 92/43/EEC. These are ecologically valuable plant communities found in the southeast of Spain. By combining modeling methods of environmental variables, historical photo-interpretation, and fieldwork, a chronosequence of the evolution of their extent of occurrence (EOO) has been reconstructed in 1957 and 2011. Results showed a strong regression range of *Maytenus senegalensis* subsp. *europaea* populations. More than 26,000 ha of EOO for this species have been lost in the province of Almería. Considering the final number of polygons, this area has been fragmented 18 times since the 1950s. These results reinforce the idea that the alteration and fragmentation of habitat due to human activities is one of the most important drivers of biodiversity loss and global change. These activities are mostly intensive greenhouse agriculture and urbanization without sustainable land planning. Knowledge about the distribution of M. senegalensis subsp. europaea is of great interest for future habitat restoration. Therefore, this would be the key species to recover these damaged ecosystems.","tags":["Species distribution models","Biodiversity conservation","Ecoinformatics","Habitat loss"],"title":"Extreme habitat loss in a Mediterranean habitat: Maytenus senegalensis subsp. europaea","type":"publication"},{"authors":["José Miguel Barea-Azcón","Blas M. Benito (shared first coauthorship)","Francisco J. Olivares","Helena Ruiz","Javier Martín","Antonio L. García","Rogelio López"],"categories":null,"content":"","date":1392854400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1392854400,"objectID":"24408a853074612aafa67c0a6df22901","permalink":"/publication/2014_barea-azcon_and_benito_biodiversity_and_conservation/","publishdate":"2014-02-20T00:00:00Z","relpermalink":"/publication/2014_barea-azcon_and_benito_biodiversity_and_conservation/","section":"publication","summary":"Herein we investigate the distribution and conservation problems of a relict interaction in the Sierra Nevada mountains (southern Europe) between the butterfly *Agriades zullichi* —a rare and threatened butterfly— and its larval foodplant *Androsace vitaliana* subsp. *nevadensis*. We designed an intensive field survey to obtain a comprehensive presence dataset. This was used to calibrate species distribution models with absences taken at local and regional extents, analyze the potential distribution, evaluate the influence of environmental factors in different geographical contexts, and evaluate conservation threats for both organisms.","tags":["Biodiversity Conservation","Species Distribution Models","Ecoinformatics","Biogeography","Random Forest","Machine Learning"],"title":"Distribution and conservation of the relict interaction between the butterfly Agriades zullichi and its larval foodplant (Androsace vitaliana nevadensis)","type":"publication"},{"authors":["Francisco J. Bonet","Ramón Pérez-Pérez","Blas M. Benito","Fabio Suzart de Albuquerque","Regino Zamora"],"categories":null,"content":"","date":1391212800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1391212800,"objectID":"bf6fe82e9413557dd6e0d799c6787ba1","permalink":"/publication/2014_bonet_environmental_modelling_and_software/","publishdate":"2014-02-01T00:00:00Z","relpermalink":"/publication/2014_bonet_environmental_modelling_and_software/","section":"publication","summary":"Many of the best practices concerning the development of ecological models or analytic techniques published in the scientific literature are not fully available to modelers but rather are stored in scientists' digital or biological memories. We propose that it is time to address the problem of storing, documenting, and executing ecological models and analytical procedures. In this paper, we propose a conceptual framework to design and implement a web application that will help to meet this challenge. This tool will foster cooperation among scientists, enhancing the creation of relevant knowledge that could be transferred to environmental managers. We have implemented this conceptual framework in a tool called ModeleR. This is being used to document, share, and execute more than 200 models and analytical processes associated with a global change monitoring program that is being undertaken in the Sierra Nevada Mountains (south Spain). ModeleR uses the concept of scientific workflow to connect and execute different types of models and analytical processes. Finally, we have envisioned the creation of a federation of model repositories where models documented within a local repository could be linked and even executed by other researchers.","tags":["Ecoinformatics"],"title":"Documenting, storing, and executing models in Ecology: A conceptual framework and real implementation in a global change monitoring program","type":"publication"},{"authors":["Blas M. Benito","Juan Lorite","Ramón Pérez-Pérez","Lorena Gómez-Aparicio","Julio Peñas"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"c1e357c5f2a52ae592bcf91f774e7627","permalink":"/publication/2014_benito_diversity_and_distributions/","publishdate":"2014-01-01T00:00:00Z","relpermalink":"/publication/2014_benito_diversity_and_distributions/","section":"publication","summary":"The Mediterranean Basin is threatened by climate change, and there is an urgent need for studies to determine the risk of plant range shift and potential extinction. In this study, we simulate potential range shifts of 176 plant species to perform a detailed prognosis of critical range decline and extinction in a transformed mediterranean landscape. Particularly, we seek to answer two pivotal questions: (1) what are the general plant‐extinction patterns we should expect in mediterranean landscapes during the 21st century? and (2) does dispersal ability prevent extinction under climate change?.","tags":["Climate Change","Species Distribution Models","Ecoinformatics","Mechanistic Simulation","Random Forest","Ensemble models","Conditional Inference Trees","Plant Ecology"],"title":"Forecasting plant range collapse in a mediterranean hotspot: when dispersal uncertainties matter","type":"publication"},{"authors":["Elise S. Gornish","Jill A. Hamilton","Albert Barberán","Blas M. Benito","Amrei Binzer","Julie E. DeMeester","Robert Gruwez","Bruno Moreira","Shirin Taheri","Sara Tomiolo","Catarina Vinagre","Pauline Vurain","Jennifer Weaver"],"categories":null,"content":"","date":1366070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1366070400,"objectID":"5ee0e5600c367d4720aa53a935a5c256","permalink":"/publication/2013_gornish_eos/","publishdate":"2013-04-16T00:00:00Z","relpermalink":"/publication/2013_gornish_eos/","section":"publication","summary":"Climate change research is an interdisciplinary field, and understanding its social, political, and environmental implications requires integration across fields of research where different tools may be used to address common concerns. One of the many advantages of interdisciplinary approaches is that they open communication between complementary fields, filling knowledge gaps and facilitating progression within both individual fields and the broader field of climate change research.","tags":["Climate Change"],"title":"Interdisciplinary Climate Change Collaborations Are Essential for Early‐Career Scientists","type":"publication"},{"authors":["Mireia Valle","Marieke M. van Katwijk","Dick J. de Jong","Tjeerd J. Bouma","Aafke M. Schipper","Guillem Chust","Blas M. Benito","Joxe M. Garmendia","Ángel Borja"],"categories":null,"content":"","date":1363305600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1363305600,"objectID":"77359446d7cb7b0af132b5de61eb93b1","permalink":"/publication/2013_valle_journal_of_sea_research/","publishdate":"2013-03-15T00:00:00Z","relpermalink":"/publication/2013_valle_journal_of_sea_research/","section":"publication","summary":"A time series of 14-year distribution data of Zostera marina in the Ems estuary (The Netherlands) was used to build different data subsets: (1) total presence area; (2) a conservative estimate of the total presence area, defined as the area which had been occupied during at least 4 years; (3) core area, defined as the area which had been occupied during at least 2/3 of the total period; and (4–6) three random selections of monitoring years. On average, colonized and disappeared areas of the species in the Ems estuary showed remarkably similar transition probabilities of 12.7% and 12.9%, respectively. SDMs based upon machine-learning methods (Boosted Regression Trees and Random Forest) outperformed regression-based methods. Current velocity and wave exposure were the most important variables predicting the species presence for widely distributed data. Depth and sea floor slope were relevant to predict conservative presence area and core area.","tags":["Biodiversity Conservation","Species Distribution Models","Machine learning","Random Forest","Gradient Boosting"],"title":"Comparing the performance of species distribution models of Zostera marina: Implications for conservation","type":"publication"},{"authors":["Blas M. Benito","Luis Cayuela","Fabio S. Albuquerque"],"categories":null,"content":"","date":1362528000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1362528000,"objectID":"69d5141556741b6f7698c5bfd3796a74","permalink":"/publication/2013_benito_methods_in_ecology_and_evolution/","publishdate":"2013-03-06T00:00:00Z","relpermalink":"/publication/2013_benito_methods_in_ecology_and_evolution/","section":"publication","summary":"We generated 380 S‐SDMs of 1224 tree species in Mesoamerica by combining 19 distribution modelling methods with 20 different thresholds using presence‐only data from the Global Biodiversity Information Facility. We compared the predicted richness and composition with inventory data obtained from the BIOTREE‐NET forest plot database. We designed two indicators of predictive performance that were based on the diversity factors used to measure species turnover: a (shared species between the observed and predicted compositions), b and c (the exclusive species of the predicted and observed compositions respectively) and compared them with the Sorensen and Beta‐Simpson turnover measures. Some modelling methods – especially machine learning and ensemble model forecasting methods performed significantly better than others in minimizing the error in predicted richness and composition. Our results also indicate that restrictive thresholds (with high omission errors) lead to more accurate S‐SDMs in terms of species richness and composition. Here, we demonstrate that particular combinations of modelling methods and thresholds provide results with higher predictive performance.","tags":["Species Distribution Models","Ecoinformatics","Random Forest","Ensemble models","Machine Learning"],"title":"The impact of modelling choices in the predictive performance of richness maps derived from species‐distribution models: guidelines to build better diversity models","type":"publication"},{"authors":["Albuquerque, F.","Assunção-Albuquerque, M.J.","Cayuela, L.","Zamora, R.","Blas M. Benito"],"categories":null,"content":"","date":1358726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1358726400,"objectID":"bb2936f49fe5e9950d89f99bc84a0d90","permalink":"/publication/2013_albuquerque_biological_conservation/","publishdate":"2013-01-21T00:00:00Z","relpermalink":"/publication/2013_albuquerque_biological_conservation/","section":"publication","summary":"Our assessments showed little association between bird richness patterns and the cover of protected areas (PAs) across EU countries. The congruence between high-value richness areas of all bird species and IBS with PAs cover was moderate, suggesting that different conservation planning targets should be taken into account to safeguard IBS, or the composition of bird species. Our results also showed that 16 (3.9%) threatened species were present in gaps of PAs. The poor relationship between PAs cover and bird richness pattern found herein may provide evidence that the establishment of SPAs across Europe may not be fully accounting for richness patterns to enhance the performance of the current network.","tags":["Biodiversity Conservation"],"title":"European Bird distribution is “well” represented by Special Protected Areas: Mission accomplished?","type":"publication"},{"authors":["Ramón Pérez-Pérez","Blas M. Benito","Francisco J. Bonet"],"categories":null,"content":"","date":1328313600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1328313600,"objectID":"29fc5074a7e132bb1510f42cecbde2aa","permalink":"/publication/2012_perez-perez_expert_systems_with_applications/","publishdate":"2012-02-04T00:00:00Z","relpermalink":"/publication/2012_perez-perez_expert_systems_with_applications/","section":"publication","summary":"In this paper, we present the development of ModeleR, a repository of models accessible from the web, which enables the user to design, document, manage, and execute environmental models.","tags":["Ecoinformatics"],"title":"ModeleR: An enviromental model repository as knowledge base for experts","type":"publication"},{"authors":["Blas M. Benito","Juan Lorite","Julio Peñas"],"categories":null,"content":"","date":1296604800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1296604800,"objectID":"d94d778916672e3a2b7a6e74a2278246","permalink":"/publication/2011_benito_climate_change/","publishdate":"2011-02-02T00:00:00Z","relpermalink":"/publication/2011_benito_climate_change/","section":"publication","summary":"According to the simulations, the suitable habitat for the key species inhabiting the summit area, where most of the endemic and/or rare species are located, may disappear before the middle of the century. The other key species considered show moderate to drastic suitable habitat loss depending on the considered scenario. Climate warming should provoke a strong substitution dynamics between species, increasing spatial competition between both of them. In this study, we introduce the application of differential suitability concept into the analysis of potential impact of climate change, forest management and environmental monitoring, and discuss the limitations and uncertainties of these simulations.","tags":["Climate Change","Species Distribution Models","Ecoinformatics","Plant Ecology"],"title":"Simulating potential effects of climatic warming on altitudinal patterns of key species in Mediterranean-alpine ecosystems","type":"publication"}]