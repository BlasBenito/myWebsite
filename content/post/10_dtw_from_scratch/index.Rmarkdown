---
title: "Coding a Minimalistic Dynamic Time Warping Library with R"
author: ''
date: '2025-01-13'
slug: dynamic-time-warping-from-scratch
categories: []
tags: [Rstats]
subtitle: ''
summary: 'Tutorial on how to implement dynamic time warping in R'
authors: [admin]
lastmod: '2025-01-13T05:14:20+01:00'
featured: yes
draft: true
image:
  caption: Graph by Blas M. Benito
  focal_point: Smart
  margin: auto
projects: []
---

```{r, echo = FALSE, eval = FALSE}
install.packages("distantia")
```


# Summary

Dynamic Time Warping is a powerful method to compare univariate or multivariate time series by shape I explained in [previous post](https://www.blasbenito.com/post/dynamic-time-warping/). The objective of this post is to explain how DTW work by implementing a minimalistic yet fully functional dynamic time warping library with R. The tutorial focuses on code simplicity, and as such, it does not require any particular any particular level of competence in R.

# Design

## Example Data

Having good example data at hand is a must when developing new code. For this tutorial we use a subset of three multivariate time series of temperature, rainfall, and normalized vegetation index available in the R package [distantia](https://blasbenito.github.io/distantia/).

```{r, fig.height=3.5, fig.width=5, echo = FALSE, message=FALSE}
library(distantia, quietly = TRUE)
library(zoo, quietly = TRUE)

tsl <- tsl_initialize(
  x = fagus_dynamics,
  name_column = "name",
  time_column = "time"
) |> 
  tsl_subset(
    time = c("2010-01-01", "2011-01-01")
  ) |> 
  tsl_colnames_set(
    names = c("evi", "rain", "temp")
  )

tsl_plot(tsl)
```

To facilitate our development, each time series is stored in an object of the class [zoo](https://CRAN.R-project.org/package=zoo), which is probably the most flexible time series management library in the R ecosystem.

```{r}
zoo_sweden <- tsl$Sweden
zoo_spain <- tsl$Spain
zoo_germany <- tsl$Germany

class(zoo_sweden)
```

Each zoo object has a *core data* of the class "matrix" with one observation per row and one variable per column, and an *index*, which is a vector of dates, one per row in the data matrix.

```{r}
zoo::coredata(zoo_sweden)
```

```{r}
class(zoo::coredata(zoo_sweden))
```

```{r}
zoo::index(zoo_sweden)
```

## Required Functions

The section *DTW Step by Step* from the previous article [A Gentle Intro to Dynamic Time Warping](https://www.blasbenito.com/post/dynamic-time-warping/) shows the steps required to compute DTW. Below, these steps are broken down in sub-steps that will correspond to specific functionalities in our library:

**Pre-processing steps** 

These steps help DTW work as best as possible with the input data.

  - **Linear detrending**: forces time series to be stationary by removing any upwards or downwards trends. 
  - **Z-score normalization**: facilitates distance computation between samples multivariate time series and limits potential alignment issues in DTW.

**DTW steps**

Steps to perform DTW proper and evaluate the similarity between time series.

  - **Multivariate distance**: evaluate the distance between samples of each time series.
  - **Distance matrix**: organize the multivariate distances in a matrix.
  - **Cost matrix**: dynamic programming algorithm to accumulate distance across time.
  - **Least-cost path**: algorithm to find the path across the cost matrix that maximizes the alignment between both time series.
  - **Dissimilarity metric**: computation of a number to summarize the similarity/dissimilarity between time series.
  
**Main function**

Once all the steps above are implemented in their respective functions, we will wrap all them in a single function to streamline the DTW analysis.
  
# Implementation

In this section we will be developing the library function by function. Remember that the content of each code chunk should be added to the file `mini_dtw.R`.
    
### Linear Detrending

Applying linear detrending to a time series involves computing a linear model of each variable against time, and subtracting the result of the model prediction to the original data. This operation can be done in just two steps for a zoo object. 

First, the function `stats::lm()` can be applied to all variables in our time series at once

```{r}
model_sweden <- stats::lm(
  formula = zoo_sweden ~ stats::time(zoo_sweden)
  )

model_sweden
```

Second, the residuals of the linear model represent the differences between the prediction and the observed data, which corresponds exactly with the detrended time series. As a plus, these residuals are returned as a zoo object.

```{r, fig.width=5, fig.height=3.5}
zoo_sweden_detrended <- stats::residuals(model_sweden)
zoo_sweden_detrended

plot(
  x = zoo_sweden_detrended, 
  col = "red4",
  mar = c(0.5, 5, 0, 5)
  )
```

Then, the first function of our library could be something like this:

```{r}
#' Linear Detrending
#' @param x (required, zoo object) time series to detrend.
#' @return zoo object
ts_detrend <- function(x){
  m <- stats::lm(formula = x ~ stats::time(x))
  y <- stats::residuals(object = m)
  y
}
```

Notice that it could be more concise, but it is written to facilitate line-by-line debugging instead. I have also added minimal roxygen documentation. Future me usually appreciates this kind of extra effort.

We can now test the new function!

```{r, fig.height=3, fig.width=5}
zoo_spain_detrended <- ts_detrend(x = zoo_spain)

plot(
  x = zoo_spain_detrended, 
  col = "red4",
  mar = c(0.5, 5, 0, 5)
  )
```

The effect of our new function is not very noticeable because none of our time series have long-term trends, but let's try something different to check that our function actually detrends time series.

The code below creates a mock-up time series with an ascending trend.

```{r, fig.height=3, fig.width=5}
x <- zoo::zoo(0:10)

plot(
  x = x, 
  col = "red4",
  mar = c(0.5, 1, 0, 1)
  )
```

The detrending operation results in a horizontal line! Now we can be sure our detrending function works as expected.

```{r}
x_detrended <- ts_detrend(x = x)

plot(
  x = x_detrended, 
  col = "red4",
  ylim = range(x),
  mar = c(0.5, 5, 0, 5)
  )
```


### Z-score Normalization

The function `scale()`, from base R, already implements z-score normalization. When the library `zoo` is loaded, the method `zoo:::scale.zoo` (`:::` denotes unexported methods and functions) allows `scale()` to work seamlessly with zoo objects.

```{r}
zoo_spain_scaled <- scale(
  x = zoo_spain,
  center = TRUE,
  scale = TRUE
  )

class(zoo_spain_scaled)
```
Centering is performed by subtracting the column mean to each case, and results in a column mean equal to zero. Scaling divides each case by the standard deviation of the column, resulting in an overall standard deviation across cases equal to one.

This normalization step does not require a function in our library, but we can add it to our function `ts_detrend()` to encapsulate all pre-processing steps into a new function named `ts_preprocessing()`.

```{r}
#' Linear Detrending and Normalization
#' @param x (required, zoo object) time series to detrend.
#' @return zoo object
ts_preprocessing <- function(x){
  m <- stats::lm(formula = x ~ stats::time(x))
  y <- stats::residuals(object = m)
  y.scaled <- scale(x = y)
  y.scaled
}
```

Once we replace the old function with the new one, we can source the library and test it.

```{r, fig.height=3, fig.width=5}
source("mini_dtw.R")

zoo_spain_ready <- ts_preprocessing(x = zoo_spain)

plot(
  x = zoo_spain_ready, 
  col = "red4",
  mar = c(0.5, 5, 0, 5)
  )
```

### Distance Matrix

The computation of a distance matrix first requires a function to compute the multivariate distance between two arbitrary rows of separate zoo objects with the same number of columns.

#### Distance Function

The expression to compute Euclidean distances between two vectors `x` and `y` representing the rows of zoo objects is `sqrt(sum((x-y)^2))`. The function below implements this expression:

```{r}
#' Euclidean Distance
#' @param x (required, numeric) row of a zoo object.  
#' @param y (required, numeric) row of a zoo object.
#' @return numeric
d_euclidean <- function(x, y){
  sqrt(sum((x-y)^2))
}
```

Implementing such a simple expression in a function is not a must, but it may facilitate the addition of new distance metrics to the library in the future.

We can test it right away, and let's ignore for now that none of our zoo objects are normalized yet.

```{r}
d_euclidean(
  x = zoo::coredata(zoo_germany)[1, ],
  y = zoo::coredata(zoo_spain)[2, ]
)
```

Notice that I am using `zoo::coredata()` to extract the individual rows of each zoo object. Without this step, goofy things happen:

```{r}
d_euclidean(
  x = zoo_germany[1, ],
  y = zoo_spain[2, ]
)
```

We can also solve this quirk by using `as.numeric()` instead of `zoo::coredata()`:

```{r}
d_euclidean(
  x = as.numeric(zoo_germany[1, ]),
  y = as.numeric(zoo_spain[2, ])
)
```

Then, moving these `as.numeric()` inside `d_euclidean()` will be helpful to simplify the usage of the function:

```{r}
#' Euclidean Distance
#' @param x (required, numeric) row of a zoo object.  
#' @param y (required, numeric) row of a zoo object.
#' @return numeric
d_euclidean <- function(x, y){
  x <- as.numeric(x)
  y <- as.numeric(y)
  sqrt(sum((x-y)^2))
}

d_euclidean(
  x = zoo_germany[1, ],
  y = zoo_spain[2, ]
)
```

#### Distance Matrix

To generate the distance matrix, the new function must be applied to all pairs of rows in two zoo objects. A simple yet inefficient way to do this involves creating an empty matrix, and traversing it cell by cell to compute the euclidean distances between the corresponding pair of time series rows.

```{r}
m_dist <- matrix(
  data = NA, 
  nrow = nrow(zoo_spain), 
  ncol = nrow(zoo_germany)
)

for(i in 1:nrow(zoo_spain)){
  for(j in 1:nrow(zoo_germany)){
    
    m_dist[i, j] <- d_euclidean(
      x = zoo_spain[i, ],
      y = zoo_germany[j, ]
    )
    
  }
}
```

This code generates a matrix in which the samples of `zoo_spain` are represented in the matrix rows from top to bottom, while `zoo_germany` is represented in the columns, from left to right.

```{r}
m_dist[1:5, 1:5]
```
Now we can plot this distance matrix, but notice that the function `graphics::image()` rotates the distance matrix 90 degrees counter clock-wise before plotting, which can be pretty confusing at first:

```{r, fig.width=2.5, fig.height=2.5}
par(mar = c(4, 4, 1, 1))
graphics::image(
  x = m_dist,
  xlab = "zoo_spain",
  ylab = "zoo_germany"
  )
```

Now first column in the plot represents the first row of our original matrix `m_dist`, so now `zoo_spain` is represented in the plot columns, and `zoo_germany` in the rows.

Ok! Now, our new function, named `distance_matrix()`, would look as follows:

```{r}
#' Distance Matrix Between Time Series
#' @param x (required, zoo object) time series.
#' @param y (required, zoo object) time series with same columns as `x`
#' @return matrix
distance_matrix <- function(x, y){
  
  m_dist <- matrix(
    data = NA, 
    nrow = nrow(y), 
    ncol = nrow(x)
  )
  
  for (i in 1:nrow(y)) {
    for (j in 1:nrow(x)) {
      
      m_dist[i, j] <- d_euclidean(
        x = x[i, ],
        y = y[j, ]
      )
      
    }
  }
  
  m_dist
  
}
```

We can add it to `mini_dtw.R` and test it now!

```{r, fig.width=2.5, fig.height=2.5}
m_dist <- distance_matrix(
  x = zoo_germany,
  y = zoo_sweden
)

par(mar = c(4, 4, 1, 1))
graphics::image(
  x = m_dist,
  xlab = "zoo_sweden",
  ylab = "zoo_germany"
  )
```

### Cost Matrix

Now we are getting into the important parts of the DTW algorithm!

```{r}
m_cost <- matrix(
  data = NA, 
  nrow = nrow(m_dist), 
  ncol = ncol(m_dist)
  )
```

The first step is to accumulate the cost of the first row and column of the distance matrix.

```{r}
m_cost[1, ] <- cumsum(m_dist[1, ])
m_cost[, 1] <- cumsum(m_dist[1, ])
```


```{r}
cost_matrix <- function(m_dist) {
  yn <- nrow(m_dist)
  xn <- ncol(m_dist)
  m_cost <- matrix(0, nrow = yn, ncol = xn)
  
  m_cost[1, 1] <- m_dist[1, 1]
  
  for (i in 2:yn) {
    m_cost[i, 1] <- m_cost[i - 1, 1] + m_dist[i, 1]
  }
  
  for (j in 2:xn) {
    m_cost[1, j] <- m_cost[1, j - 1] + m_dist[1, j]
  }
  
  for (i in 2:yn) {
    for (j in 2:xn) {
      m_cost[i, j] <- min(m_cost[i - 1, j], m_cost[i, j - 1]) + m_dist[i, j]
    }
  }
  
  # Adjusting the last cell to include the return cost to the starting point
  m_cost[yn, xn] <- m_cost[yn, xn] + m_cost[1, 1]
  
  m_cost
}
```


### Least-Cost Path

### Dissimilarity Metric



## Library Source

Our library will *live* in a file named `mini_dtw.R`. We will be adding new R functions to this file as we progress with the implementation. Remember typing `source("mini_dtw.R")` everytime you add new code to this file to make the functions available in your R environment!
