<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science | Blas M. Benito, PhD</title>
    <link>https://blasbenito.com/tag/data-science/</link>
      <atom:link href="https://blasbenito.com/tag/data-science/index.xml" rel="self" type="application/rss+xml" />
    <description>Data Science</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 30 Oct 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://blasbenito.com/media/avatar.jpg</url>
      <title>Data Science</title>
      <link>https://blasbenito.com/tag/data-science/</link>
    </image>
    
    <item>
      <title>R package `collinear`</title>
      <link>https://blasbenito.com/project/post-title/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://blasbenito.com/project/post-title/</guid>
      <description>&lt;!-- badges: start --&gt;
&lt;p&gt;
&lt;a href=&#34;https://doi.org/10.5281/zenodo.10039489&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://zenodo.org/badge/DOI/10.5281/zenodo.10039489.svg&#34; alt=&#34;DOI&#34;&gt;&lt;/a&gt;

&lt;a href=&#34;https://cran.r-project.org/package=collinear&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://www.r-pkg.org/badges/version/collinear&#34; alt=&#34;CRAN status&#34;&gt;&lt;/a&gt;

&lt;a href=&#34;https://CRAN.R-project.org/package=collinear&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;http://cranlogs.r-pkg.org/badges/grand-total/collinear&#34; alt=&#34;CRAN\_Download\_Badge&#34;&gt;&lt;/a&gt;

&lt;a href=&#34;https://github.com/BlasBenito/collinear/actions/workflows/R-CMD-check.yaml&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img src=&#34;https://github.com/BlasBenito/collinear/actions/workflows/R-CMD-check.yaml/badge.svg&#34; alt=&#34;R-CMD-check&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;!-- badges: end --&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;The R package &lt;code&gt;collinear&lt;/code&gt; combines four different methods to offer a comprehensive tool for multicollinearity management:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pairwise correlation for numeric and categorical predictors&lt;/strong&gt;: computed either via Pearson or Spearman methods for numeric predictors, and Cramer&amp;rsquo;s V for categorical predictors.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Variance Inflation Factor analysis (VIF)&lt;/strong&gt;: to identify multicollinearity resulting from predictors being linear combinations of other predictors.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Target encoding of categorical predictors&lt;/strong&gt;: to convert them to numeric using a numeric variable as response (usually a response variable) and handle them as numerics during the multicollinearity filtering.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Variable prioritization&lt;/strong&gt;: method to prioritize predictors during variable selection either using expert knowledge or quantitative criteria.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These methods are integrated in the &lt;code&gt;collinear()&lt;/code&gt; function, which returns a vector of selected predictors with a controlled multicollinearity.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selected_variables &amp;lt;- collinear(
  df, #your data frame
  response, #name of your response variable
  predictors, #names of your predictors,
  preference_order, #your predictors in order of interest
  max_cor, #maximum bivariate correlation
  max_vif, #maximum variance inflation factor
  encoding_method, #method to convert categorical predictors into numerics
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The package contains other functions that may be useful during multicollinearity management:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cor_select()&lt;/code&gt;: like &lt;code&gt;collinear()&lt;/code&gt;, but only using pairwise correlations.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vif_select()&lt;/code&gt;: like &lt;code&gt;collinear()&lt;/code&gt;, but only using variance inflation factors.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;preference_order()&lt;/code&gt;: to compute preference order based on univariate models.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;target_encoding_lab()&lt;/code&gt;: to convert categorical predictors into numeric using several methods.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cor_df()&lt;/code&gt;: to generate a data frame with all pairwise correlation scores.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cor_matrix()&lt;/code&gt;: to convert a correlation data frame into matrix, or obtain a correlation matrix.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vif_df()&lt;/code&gt;: to obtain a data frame with all variance inflation factors.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you found this package useful during your research work, please cite it as:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Blas M. Benito (2023). collinear: R Package for Seamless Multicollinearity Management. Version 1.0.1. doi: 10.5281/zenodo.10039489&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;install&#34;&gt;Install&lt;/h2&gt;
&lt;p&gt;The package &lt;code&gt;collinear&lt;/code&gt; can be installed from CRAN.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;collinear&amp;quot;)
library(collinear)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The development version can be installed from GitHub.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;remotes::install_github(
  repo = &amp;quot;blasbenito/collinear&amp;quot;, 
  ref = &amp;quot;development&amp;quot;
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;multicollinearity-management-with-the-collinear-package&#34;&gt;Multicollinearity management with the &lt;code&gt;collinear&lt;/code&gt; package.&lt;/h2&gt;
&lt;p&gt;This section shows the basic usage of the package and offers a brief explanation on the methods used within.&lt;/p&gt;
&lt;h3 id=&#34;required-libraries-and-example-data&#34;&gt;Required libraries and example data&lt;/h3&gt;
&lt;p&gt;The libraries below are required to run the examples in this section.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(collinear)
library(dplyr)
library(tictoc)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The package &lt;code&gt;collinear&lt;/code&gt; is shipped with a data frame named &lt;code&gt;vi&lt;/code&gt;, with 30.000 rows and 67 columns with a mixture of numeric and categorical variables.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dplyr::glimpse(vi)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 30,000
## Columns: 67
## $ longitude                  &amp;lt;dbl&amp;gt; -114.254306, 114.845693, -122.145972, 108.3…
## $ latitude                   &amp;lt;dbl&amp;gt; 45.0540272, 26.2706940, 56.3790272, 29.9456…
## $ vi_mean                    &amp;lt;dbl&amp;gt; 0.38, 0.53, 0.45, 0.69, 0.42, 0.68, 0.70, 0…
## $ vi_max                     &amp;lt;dbl&amp;gt; 0.57, 0.67, 0.65, 0.85, 0.64, 0.78, 0.77, 0…
## $ vi_min                     &amp;lt;dbl&amp;gt; 0.12, 0.41, 0.25, 0.50, 0.25, 0.48, 0.60, 0…
## $ vi_range                   &amp;lt;dbl&amp;gt; 0.45, 0.26, 0.40, 0.34, 0.39, 0.31, 0.17, 0…
## $ koppen_zone                &amp;lt;chr&amp;gt; &amp;quot;BSk&amp;quot;, &amp;quot;Cfa&amp;quot;, &amp;quot;Dfc&amp;quot;, &amp;quot;Cfb&amp;quot;, &amp;quot;Aw&amp;quot;, &amp;quot;Cfa&amp;quot;, &amp;quot;A…
## $ koppen_group               &amp;lt;chr&amp;gt; &amp;quot;Arid&amp;quot;, &amp;quot;Temperate&amp;quot;, &amp;quot;Cold&amp;quot;, &amp;quot;Temperate&amp;quot;, &amp;quot;…
## $ koppen_description         &amp;lt;chr&amp;gt; &amp;quot;steppe, cold&amp;quot;, &amp;quot;no dry season, hot summer&amp;quot;…
## $ soil_type                  &amp;lt;chr&amp;gt; &amp;quot;Cambisols&amp;quot;, &amp;quot;Acrisols&amp;quot;, &amp;quot;Luvisols&amp;quot;, &amp;quot;Aliso…
## $ topo_slope                 &amp;lt;int&amp;gt; 6, 2, 0, 10, 0, 10, 6, 0, 2, 0, 0, 1, 0, 1,…
## $ topo_diversity             &amp;lt;int&amp;gt; 29, 24, 21, 25, 19, 30, 26, 20, 26, 22, 25,…
## $ topo_elevation             &amp;lt;int&amp;gt; 1821, 143, 765, 1474, 378, 485, 604, 1159, …
## $ swi_mean                   &amp;lt;dbl&amp;gt; 27.5, 56.1, 41.4, 59.3, 37.4, 56.3, 52.3, 2…
## $ swi_max                    &amp;lt;dbl&amp;gt; 62.9, 74.4, 81.9, 81.1, 83.2, 73.8, 55.8, 3…
## $ swi_min                    &amp;lt;dbl&amp;gt; 24.5, 33.3, 42.2, 31.3, 8.3, 28.8, 25.3, 11…
## $ swi_range                  &amp;lt;dbl&amp;gt; 38.4, 41.2, 39.7, 49.8, 74.9, 45.0, 30.5, 2…
## $ soil_temperature_mean      &amp;lt;dbl&amp;gt; 4.8, 19.9, 1.2, 13.0, 28.2, 18.1, 21.5, 23.…
## $ soil_temperature_max       &amp;lt;dbl&amp;gt; 29.9, 32.6, 20.4, 24.6, 41.6, 29.1, 26.4, 4…
## $ soil_temperature_min       &amp;lt;dbl&amp;gt; -12.4, 3.9, -16.0, -0.4, 16.8, 4.1, 17.3, 5…
## $ soil_temperature_range     &amp;lt;dbl&amp;gt; 42.3, 28.8, 36.4, 25.0, 24.8, 24.9, 9.1, 38…
## $ soil_sand                  &amp;lt;int&amp;gt; 41, 39, 27, 29, 48, 33, 30, 78, 23, 64, 54,…
## $ soil_clay                  &amp;lt;int&amp;gt; 20, 24, 28, 31, 27, 29, 40, 15, 26, 22, 23,…
## $ soil_silt                  &amp;lt;int&amp;gt; 38, 35, 43, 38, 23, 36, 29, 6, 49, 13, 22, …
## $ soil_ph                    &amp;lt;dbl&amp;gt; 6.5, 5.9, 5.6, 5.5, 6.5, 5.8, 5.2, 7.1, 7.3…
## $ soil_soc                   &amp;lt;dbl&amp;gt; 43.1, 14.6, 36.4, 34.9, 8.1, 20.8, 44.5, 4.…
## $ soil_nitrogen              &amp;lt;dbl&amp;gt; 2.8, 1.3, 2.9, 3.6, 1.2, 1.9, 2.8, 0.6, 3.1…
## $ solar_rad_mean             &amp;lt;dbl&amp;gt; 17.634, 19.198, 13.257, 14.163, 24.512, 17.…
## $ solar_rad_max              &amp;lt;dbl&amp;gt; 31.317, 24.498, 25.283, 17.237, 28.038, 22.…
## $ solar_rad_min              &amp;lt;dbl&amp;gt; 5.209, 13.311, 1.587, 9.642, 19.102, 12.196…
## $ solar_rad_range            &amp;lt;dbl&amp;gt; 26.108, 11.187, 23.696, 7.595, 8.936, 10.20…
## $ growing_season_length      &amp;lt;dbl&amp;gt; 139, 365, 164, 333, 228, 365, 365, 60, 365,…
## $ growing_season_temperature &amp;lt;dbl&amp;gt; 12.65, 19.35, 11.55, 12.45, 26.45, 17.75, 2…
## $ growing_season_rainfall    &amp;lt;dbl&amp;gt; 224.5, 1493.4, 345.4, 1765.5, 984.4, 1860.5…
## $ growing_degree_days        &amp;lt;dbl&amp;gt; 2140.5, 7080.9, 2053.2, 4162.9, 10036.7, 64…
## $ temperature_mean           &amp;lt;dbl&amp;gt; 3.65, 19.35, 1.45, 11.35, 27.55, 17.65, 22.…
## $ temperature_max            &amp;lt;dbl&amp;gt; 24.65, 33.35, 21.15, 23.75, 38.35, 30.55, 2…
## $ temperature_min            &amp;lt;dbl&amp;gt; -14.05, 3.05, -18.25, -3.55, 19.15, 2.45, 1…
## $ temperature_range          &amp;lt;dbl&amp;gt; 38.7, 30.3, 39.4, 27.3, 19.2, 28.1, 7.0, 29…
## $ temperature_seasonality    &amp;lt;dbl&amp;gt; 882.6, 786.6, 1070.9, 724.7, 219.3, 747.2, …
## $ rainfall_mean              &amp;lt;int&amp;gt; 446, 1493, 560, 1794, 990, 1860, 3150, 356,…
## $ rainfall_min               &amp;lt;int&amp;gt; 25, 37, 24, 29, 0, 60, 122, 1, 10, 12, 0, 0…
## $ rainfall_max               &amp;lt;int&amp;gt; 62, 209, 87, 293, 226, 275, 425, 62, 256, 3…
## $ rainfall_range             &amp;lt;int&amp;gt; 37, 172, 63, 264, 226, 215, 303, 61, 245, 2…
## $ evapotranspiration_mean    &amp;lt;dbl&amp;gt; 78.32, 105.88, 50.03, 64.65, 156.60, 108.50…
## $ evapotranspiration_max     &amp;lt;dbl&amp;gt; 164.70, 190.86, 117.53, 115.79, 187.71, 191…
## $ evapotranspiration_min     &amp;lt;dbl&amp;gt; 13.67, 50.44, 3.53, 28.01, 128.59, 51.39, 8…
## $ evapotranspiration_range   &amp;lt;dbl&amp;gt; 151.03, 140.42, 113.99, 87.79, 59.13, 139.9…
## $ cloud_cover_mean           &amp;lt;int&amp;gt; 31, 48, 42, 64, 38, 52, 60, 13, 53, 20, 11,…
## $ cloud_cover_max            &amp;lt;int&amp;gt; 39, 61, 49, 71, 58, 67, 77, 18, 60, 27, 23,…
## $ cloud_cover_min            &amp;lt;int&amp;gt; 16, 34, 33, 54, 19, 39, 45, 6, 45, 14, 2, 1…
## $ cloud_cover_range          &amp;lt;int&amp;gt; 23, 27, 15, 17, 38, 27, 32, 11, 15, 12, 21,…
## $ aridity_index              &amp;lt;dbl&amp;gt; 0.54, 1.27, 0.90, 2.08, 0.55, 1.67, 2.88, 0…
## $ humidity_mean              &amp;lt;dbl&amp;gt; 55.56, 62.14, 59.87, 69.32, 51.60, 62.76, 7…
## $ humidity_max               &amp;lt;dbl&amp;gt; 63.98, 65.00, 68.19, 71.90, 67.07, 65.68, 7…
## $ humidity_min               &amp;lt;dbl&amp;gt; 48.41, 58.97, 53.75, 67.21, 33.89, 59.92, 7…
## $ humidity_range             &amp;lt;dbl&amp;gt; 15.57, 6.03, 14.44, 4.69, 33.18, 5.76, 3.99…
## $ biogeo_ecoregion           &amp;lt;chr&amp;gt; &amp;quot;South Central Rockies forests&amp;quot;, &amp;quot;Jian Nan …
## $ biogeo_biome               &amp;lt;chr&amp;gt; &amp;quot;Temperate Conifer Forests&amp;quot;, &amp;quot;Tropical &amp;amp; Su…
## $ biogeo_realm               &amp;lt;chr&amp;gt; &amp;quot;Nearctic&amp;quot;, &amp;quot;Indomalayan&amp;quot;, &amp;quot;Nearctic&amp;quot;, &amp;quot;Pal…
## $ country_name               &amp;lt;chr&amp;gt; &amp;quot;United States of America&amp;quot;, &amp;quot;China&amp;quot;, &amp;quot;Canad…
## $ country_population         &amp;lt;dbl&amp;gt; 313973000, 1338612970, 33487208, 1338612970…
## $ country_gdp                &amp;lt;dbl&amp;gt; 15094000, 7973000, 1300000, 7973000, 15860,…
## $ country_income             &amp;lt;chr&amp;gt; &amp;quot;1. High income: OECD&amp;quot;, &amp;quot;3. Upper middle in…
## $ continent                  &amp;lt;chr&amp;gt; &amp;quot;North America&amp;quot;, &amp;quot;Asia&amp;quot;, &amp;quot;North America&amp;quot;, &amp;quot;…
## $ region                     &amp;lt;chr&amp;gt; &amp;quot;Americas&amp;quot;, &amp;quot;Asia&amp;quot;, &amp;quot;Americas&amp;quot;, &amp;quot;Asia&amp;quot;, &amp;quot;Af…
## $ subregion                  &amp;lt;chr&amp;gt; &amp;quot;Northern America&amp;quot;, &amp;quot;Eastern Asia&amp;quot;, &amp;quot;Northe…
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The response variables are &amp;ldquo;vi_mean&amp;rdquo;, &amp;ldquo;vi_max&amp;rdquo;, &amp;ldquo;vi_min&amp;rdquo;, and &amp;ldquo;vi_range&amp;rdquo;, with statistics of a vegetation index named NDVI. The predictors are stored in the character vector &lt;code&gt;vi_predictors&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;vi_predictors
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;koppen_zone&amp;quot;                &amp;quot;koppen_group&amp;quot;              
##  [3] &amp;quot;koppen_description&amp;quot;         &amp;quot;soil_type&amp;quot;                 
##  [5] &amp;quot;topo_slope&amp;quot;                 &amp;quot;topo_diversity&amp;quot;            
##  [7] &amp;quot;topo_elevation&amp;quot;             &amp;quot;swi_mean&amp;quot;                  
##  [9] &amp;quot;swi_max&amp;quot;                    &amp;quot;swi_min&amp;quot;                   
## [11] &amp;quot;swi_range&amp;quot;                  &amp;quot;soil_temperature_mean&amp;quot;     
## [13] &amp;quot;soil_temperature_max&amp;quot;       &amp;quot;soil_temperature_min&amp;quot;      
## [15] &amp;quot;soil_temperature_range&amp;quot;     &amp;quot;soil_sand&amp;quot;                 
## [17] &amp;quot;soil_clay&amp;quot;                  &amp;quot;soil_silt&amp;quot;                 
## [19] &amp;quot;soil_ph&amp;quot;                    &amp;quot;soil_soc&amp;quot;                  
## [21] &amp;quot;soil_nitrogen&amp;quot;              &amp;quot;solar_rad_mean&amp;quot;            
## [23] &amp;quot;solar_rad_max&amp;quot;              &amp;quot;solar_rad_min&amp;quot;             
## [25] &amp;quot;solar_rad_range&amp;quot;            &amp;quot;growing_season_length&amp;quot;     
## [27] &amp;quot;growing_season_temperature&amp;quot; &amp;quot;growing_season_rainfall&amp;quot;   
## [29] &amp;quot;growing_degree_days&amp;quot;        &amp;quot;temperature_mean&amp;quot;          
## [31] &amp;quot;temperature_max&amp;quot;            &amp;quot;temperature_min&amp;quot;           
## [33] &amp;quot;temperature_range&amp;quot;          &amp;quot;temperature_seasonality&amp;quot;   
## [35] &amp;quot;rainfall_mean&amp;quot;              &amp;quot;rainfall_min&amp;quot;              
## [37] &amp;quot;rainfall_max&amp;quot;               &amp;quot;rainfall_range&amp;quot;            
## [39] &amp;quot;evapotranspiration_mean&amp;quot;    &amp;quot;evapotranspiration_max&amp;quot;    
## [41] &amp;quot;evapotranspiration_min&amp;quot;     &amp;quot;evapotranspiration_range&amp;quot;  
## [43] &amp;quot;cloud_cover_mean&amp;quot;           &amp;quot;cloud_cover_max&amp;quot;           
## [45] &amp;quot;cloud_cover_min&amp;quot;            &amp;quot;cloud_cover_range&amp;quot;         
## [47] &amp;quot;aridity_index&amp;quot;              &amp;quot;humidity_mean&amp;quot;             
## [49] &amp;quot;humidity_max&amp;quot;               &amp;quot;humidity_min&amp;quot;              
## [51] &amp;quot;humidity_range&amp;quot;             &amp;quot;biogeo_ecoregion&amp;quot;          
## [53] &amp;quot;biogeo_biome&amp;quot;               &amp;quot;biogeo_realm&amp;quot;              
## [55] &amp;quot;country_name&amp;quot;               &amp;quot;country_population&amp;quot;        
## [57] &amp;quot;country_gdp&amp;quot;                &amp;quot;country_income&amp;quot;            
## [59] &amp;quot;continent&amp;quot;                  &amp;quot;region&amp;quot;                    
## [61] &amp;quot;subregion&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;collinear&#34;&gt;&lt;code&gt;collinear()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;collinear()&lt;/code&gt; function applies a multicollinearity filtering to numeric and categorical variables via pairwise correlations (with &lt;code&gt;cor_select()&lt;/code&gt;) and variance inflation factors (with &lt;code&gt;vif_select()&lt;/code&gt;). Categorical variables are converted into numeric via target-encoding (with &lt;code&gt;target_encoding_lab()&lt;/code&gt;) using a &lt;code&gt;response&lt;/code&gt; variable as reference. If the response variable is not provided, categorical variables are ignored.&lt;/p&gt;
&lt;h4 id=&#34;input-arguments&#34;&gt;Input arguments&lt;/h4&gt;
&lt;p&gt;The function takes these inputs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;df&lt;/code&gt;: a data frame with predictors, and preferably, a response (more about this later).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;response&lt;/code&gt;: the name of the response variable, only relevant &lt;strong&gt;and highly recommended&lt;/strong&gt; if there are categorical variables within the predictors.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;predictors&lt;/code&gt;: names of predictors involved in the multicollinearity analysis.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;preference_order&lt;/code&gt;: names of the predictors in the user&amp;rsquo;s order of preference. Does not need to name all predictors in &lt;code&gt;predictors&lt;/code&gt;!&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cor_method&lt;/code&gt;: usually &amp;ldquo;pearson&amp;rdquo;, but also &amp;ldquo;spearman&amp;rdquo; is accepted.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max_cor&lt;/code&gt;: maximum correlation allowed between two predictors.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max_vif&lt;/code&gt;: maximum VIF allowed in a predictor.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;encoding_method&lt;/code&gt;: method used to convert categorical variables into numeric. Only relevant when a &lt;code&gt;response&lt;/code&gt; is provided. By default, each group of the categorical variable is encoded with the mean of the &lt;code&gt;response&lt;/code&gt; across the group.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The code below shows a quick example. Notice that the argument &lt;code&gt;preference_order&lt;/code&gt; was left as NULL, but will be explained later.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selected_predictors &amp;lt;- collinear(
  df = vi,
  response = &amp;quot;vi_mean&amp;quot;,
  predictors = vi_predictors,
  preference_order = NULL,
  max_cor = 0.75,
  max_vif = 5,
  encoding_method = &amp;quot;mean&amp;quot;
)

selected_predictors
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;country_income&amp;quot;             &amp;quot;topo_diversity&amp;quot;            
##  [3] &amp;quot;topo_slope&amp;quot;                 &amp;quot;humidity_range&amp;quot;            
##  [5] &amp;quot;topo_elevation&amp;quot;             &amp;quot;country_gdp&amp;quot;               
##  [7] &amp;quot;country_population&amp;quot;         &amp;quot;soil_soc&amp;quot;                  
##  [9] &amp;quot;region&amp;quot;                     &amp;quot;soil_type&amp;quot;                 
## [11] &amp;quot;soil_clay&amp;quot;                  &amp;quot;subregion&amp;quot;                 
## [13] &amp;quot;biogeo_realm&amp;quot;               &amp;quot;soil_sand&amp;quot;                 
## [15] &amp;quot;swi_min&amp;quot;                    &amp;quot;soil_nitrogen&amp;quot;             
## [17] &amp;quot;swi_range&amp;quot;                  &amp;quot;cloud_cover_range&amp;quot;         
## [19] &amp;quot;rainfall_min&amp;quot;               &amp;quot;growing_season_temperature&amp;quot;
## [21] &amp;quot;solar_rad_max&amp;quot;              &amp;quot;solar_rad_min&amp;quot;             
## [23] &amp;quot;rainfall_range&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function has returned a list of predictors that should have a correlation lower than 0.75 with each other, and a VIF lower than 5. Let&amp;rsquo;s see if that&amp;rsquo;s true.&lt;/p&gt;
&lt;p&gt;The function &lt;code&gt;cor_df()&lt;/code&gt; returns a data frame with pairwise correlations, arranged by the absolute value of the correlation.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selected_predictors_cor &amp;lt;- cor_df(
  df = vi,
  response = &amp;quot;vi_mean&amp;quot;,
  predictors = selected_predictors
)
head(selected_predictors_cor)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 3
##   x             y                          correlation
##   &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt;                            &amp;lt;dbl&amp;gt;
## 1 solar_rad_min growing_season_temperature       0.744
## 2 soil_nitrogen soil_soc                         0.729
## 3 soil_nitrogen swi_min                          0.673
## 4 soil_sand     soil_clay                       -0.666
## 5 solar_rad_max soil_type                       -0.652
## 6 biogeo_realm  soil_type                        0.62
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data frame above shows that the maximum correlation between two of the selected predictors is below 0.75, so here &lt;code&gt;collinear()&lt;/code&gt; worked as expected.&lt;/p&gt;
&lt;p&gt;The function &lt;code&gt;vif_df()&lt;/code&gt; returns a data frame with the VIF scores of all predictors.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selected_predictors_vif &amp;lt;- vif_df(
  df = vi,
  response = &amp;quot;vi_mean&amp;quot;,
  predictors = selected_predictors
)
selected_predictors_vif
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                      variable   vif
## 1              country_income 1.211
## 2              topo_diversity 1.635
## 3                  topo_slope 1.928
## 4              humidity_range 1.959
## 5              topo_elevation 2.073
## 6                 country_gdp 2.157
## 7          country_population 2.169
## 8                rainfall_min 2.256
## 9           cloud_cover_range 2.393
## 10             rainfall_range 2.716
## 11                   soil_soc 2.744
## 12                     region 2.846
## 13                  subregion 2.870
## 14                  soil_type 2.874
## 15                  soil_clay 2.966
## 16               biogeo_realm 3.120
## 17              solar_rad_max 3.126
## 18                    swi_min 3.138
## 19                  soil_sand 3.170
## 20                  swi_range 3.263
## 21              soil_nitrogen 3.372
## 22 growing_season_temperature 4.271
## 23              solar_rad_min 4.287
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output shows that the maximum VIF is 4.2, so here &lt;code&gt;collinear()&lt;/code&gt; did its work as expected.&lt;/p&gt;
&lt;h4 id=&#34;arguments-max_cor-and-max_vif&#34;&gt;Arguments &lt;code&gt;max_cor&lt;/code&gt; and &lt;code&gt;max_vif&lt;/code&gt;&lt;/h4&gt;
&lt;p&gt;The arguments &lt;code&gt;max_cor&lt;/code&gt; and &lt;code&gt;max_vif&lt;/code&gt; control the intensity of the multicollinearity filtering.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#restrictive setup
selected_predictors_restrictive &amp;lt;- collinear(
  df = vi,
  response = &amp;quot;vi_mean&amp;quot;,
  predictors = vi_predictors,
  max_cor = 0.5,
  max_vif = 2.5
)

#permissive setup
selected_predictors_permissive &amp;lt;- collinear(
  df = vi,
  response = &amp;quot;vi_mean&amp;quot;,
  predictors = vi_predictors,
  max_cor = 0.9,
  max_vif = 10
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These are the variables selected under a restrictive setup:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selected_predictors_restrictive
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;country_income&amp;quot;             &amp;quot;soil_clay&amp;quot;                 
##  [3] &amp;quot;country_population&amp;quot;         &amp;quot;region&amp;quot;                    
##  [5] &amp;quot;soil_soc&amp;quot;                   &amp;quot;topo_slope&amp;quot;                
##  [7] &amp;quot;growing_season_temperature&amp;quot; &amp;quot;humidity_range&amp;quot;            
##  [9] &amp;quot;cloud_cover_range&amp;quot;          &amp;quot;topo_elevation&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These are the variables selected under a more permissive setup:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selected_predictors_permissive
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;country_income&amp;quot;             &amp;quot;topo_diversity&amp;quot;            
##  [3] &amp;quot;topo_slope&amp;quot;                 &amp;quot;country_population&amp;quot;        
##  [5] &amp;quot;country_gdp&amp;quot;                &amp;quot;soil_soc&amp;quot;                  
##  [7] &amp;quot;region&amp;quot;                     &amp;quot;soil_type&amp;quot;                 
##  [9] &amp;quot;soil_nitrogen&amp;quot;              &amp;quot;subregion&amp;quot;                 
## [11] &amp;quot;topo_elevation&amp;quot;             &amp;quot;biogeo_realm&amp;quot;              
## [13] &amp;quot;koppen_group&amp;quot;               &amp;quot;biogeo_biome&amp;quot;              
## [15] &amp;quot;country_name&amp;quot;               &amp;quot;soil_ph&amp;quot;                   
## [17] &amp;quot;growing_season_temperature&amp;quot; &amp;quot;aridity_index&amp;quot;             
## [19] &amp;quot;soil_temperature_max&amp;quot;       &amp;quot;rainfall_min&amp;quot;              
## [21] &amp;quot;rainfall_range&amp;quot;             &amp;quot;swi_mean&amp;quot;                  
## [23] &amp;quot;temperature_max&amp;quot;            &amp;quot;solar_rad_mean&amp;quot;            
## [25] &amp;quot;soil_clay&amp;quot;                  &amp;quot;soil_silt&amp;quot;                 
## [27] &amp;quot;cloud_cover_min&amp;quot;            &amp;quot;swi_range&amp;quot;                 
## [29] &amp;quot;humidity_range&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As expected, the restrictive setup resulted in a smaller set of selected predictors. There are no hard rules for &lt;code&gt;max_cor&lt;/code&gt; and &lt;code&gt;max_vif&lt;/code&gt;, and their selection will depend on the objective of the analysis and the nature of the predictors.&lt;/p&gt;
&lt;h4 id=&#34;the-response-argument&#34;&gt;The &lt;code&gt;response&lt;/code&gt; argument&lt;/h4&gt;
&lt;p&gt;The response argument is used to encode categorical variables as numeric. When omitted, the &lt;code&gt;collinear()&lt;/code&gt; function ignores categorical variables. However, the function &lt;code&gt;cor_select()&lt;/code&gt; can help when there is not a suitable &lt;code&gt;response&lt;/code&gt; variable in a data frame. This option is discussed at the end of this section.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selected_predictors_response &amp;lt;- collinear(
  df = vi,
  response = &amp;quot;vi_mean&amp;quot;,
  predictors = vi_predictors
)

selected_predictors_no_response &amp;lt;- collinear(
  df = vi,
  predictors = vi_predictors
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When the argument &lt;code&gt;response&lt;/code&gt; is used, the output may contain categorical predictors (tagged with &lt;code&gt;&amp;lt;chr&amp;gt;&lt;/code&gt;, from &amp;ldquo;character&amp;rdquo; below).&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dplyr::glimpse(vi[, selected_predictors_response])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 30,000
## Columns: 23
## $ country_income             &amp;lt;chr&amp;gt; &amp;quot;1. High income: OECD&amp;quot;, &amp;quot;3. Upper middle in…
## $ topo_diversity             &amp;lt;int&amp;gt; 29, 24, 21, 25, 19, 30, 26, 20, 26, 22, 25,…
## $ topo_slope                 &amp;lt;int&amp;gt; 6, 2, 0, 10, 0, 10, 6, 0, 2, 0, 0, 1, 0, 1,…
## $ humidity_range             &amp;lt;dbl&amp;gt; 15.57, 6.03, 14.44, 4.69, 33.18, 5.76, 3.99…
## $ topo_elevation             &amp;lt;int&amp;gt; 1821, 143, 765, 1474, 378, 485, 604, 1159, …
## $ country_gdp                &amp;lt;dbl&amp;gt; 15094000, 7973000, 1300000, 7973000, 15860,…
## $ country_population         &amp;lt;dbl&amp;gt; 313973000, 1338612970, 33487208, 1338612970…
## $ soil_soc                   &amp;lt;dbl&amp;gt; 43.1, 14.6, 36.4, 34.9, 8.1, 20.8, 44.5, 4.…
## $ region                     &amp;lt;chr&amp;gt; &amp;quot;Americas&amp;quot;, &amp;quot;Asia&amp;quot;, &amp;quot;Americas&amp;quot;, &amp;quot;Asia&amp;quot;, &amp;quot;Af…
## $ soil_type                  &amp;lt;chr&amp;gt; &amp;quot;Cambisols&amp;quot;, &amp;quot;Acrisols&amp;quot;, &amp;quot;Luvisols&amp;quot;, &amp;quot;Aliso…
## $ soil_clay                  &amp;lt;int&amp;gt; 20, 24, 28, 31, 27, 29, 40, 15, 26, 22, 23,…
## $ subregion                  &amp;lt;chr&amp;gt; &amp;quot;Northern America&amp;quot;, &amp;quot;Eastern Asia&amp;quot;, &amp;quot;Northe…
## $ biogeo_realm               &amp;lt;chr&amp;gt; &amp;quot;Nearctic&amp;quot;, &amp;quot;Indomalayan&amp;quot;, &amp;quot;Nearctic&amp;quot;, &amp;quot;Pal…
## $ soil_sand                  &amp;lt;int&amp;gt; 41, 39, 27, 29, 48, 33, 30, 78, 23, 64, 54,…
## $ swi_min                    &amp;lt;dbl&amp;gt; 24.5, 33.3, 42.2, 31.3, 8.3, 28.8, 25.3, 11…
## $ soil_nitrogen              &amp;lt;dbl&amp;gt; 2.8, 1.3, 2.9, 3.6, 1.2, 1.9, 2.8, 0.6, 3.1…
## $ swi_range                  &amp;lt;dbl&amp;gt; 38.4, 41.2, 39.7, 49.8, 74.9, 45.0, 30.5, 2…
## $ cloud_cover_range          &amp;lt;int&amp;gt; 23, 27, 15, 17, 38, 27, 32, 11, 15, 12, 21,…
## $ rainfall_min               &amp;lt;int&amp;gt; 25, 37, 24, 29, 0, 60, 122, 1, 10, 12, 0, 0…
## $ growing_season_temperature &amp;lt;dbl&amp;gt; 12.65, 19.35, 11.55, 12.45, 26.45, 17.75, 2…
## $ solar_rad_max              &amp;lt;dbl&amp;gt; 31.317, 24.498, 25.283, 17.237, 28.038, 22.…
## $ solar_rad_min              &amp;lt;dbl&amp;gt; 5.209, 13.311, 1.587, 9.642, 19.102, 12.196…
## $ rainfall_range             &amp;lt;int&amp;gt; 37, 172, 63, 264, 226, 215, 303, 61, 245, 2…
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, when the argument &lt;code&gt;response&lt;/code&gt; is ignored, all categorical predictors are ignored.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;dplyr::glimpse(vi[, selected_predictors_no_response])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 30,000
## Columns: 18
## $ topo_diversity             &amp;lt;int&amp;gt; 29, 24, 21, 25, 19, 30, 26, 20, 26, 22, 25,…
## $ humidity_range             &amp;lt;dbl&amp;gt; 15.57, 6.03, 14.44, 4.69, 33.18, 5.76, 3.99…
## $ country_population         &amp;lt;dbl&amp;gt; 313973000, 1338612970, 33487208, 1338612970…
## $ country_gdp                &amp;lt;dbl&amp;gt; 15094000, 7973000, 1300000, 7973000, 15860,…
## $ topo_slope                 &amp;lt;int&amp;gt; 6, 2, 0, 10, 0, 10, 6, 0, 2, 0, 0, 1, 0, 1,…
## $ topo_elevation             &amp;lt;int&amp;gt; 1821, 143, 765, 1474, 378, 485, 604, 1159, …
## $ swi_range                  &amp;lt;dbl&amp;gt; 38.4, 41.2, 39.7, 49.8, 74.9, 45.0, 30.5, 2…
## $ soil_soc                   &amp;lt;dbl&amp;gt; 43.1, 14.6, 36.4, 34.9, 8.1, 20.8, 44.5, 4.…
## $ soil_clay                  &amp;lt;int&amp;gt; 20, 24, 28, 31, 27, 29, 40, 15, 26, 22, 23,…
## $ soil_sand                  &amp;lt;int&amp;gt; 41, 39, 27, 29, 48, 33, 30, 78, 23, 64, 54,…
## $ swi_min                    &amp;lt;dbl&amp;gt; 24.5, 33.3, 42.2, 31.3, 8.3, 28.8, 25.3, 11…
## $ soil_nitrogen              &amp;lt;dbl&amp;gt; 2.8, 1.3, 2.9, 3.6, 1.2, 1.9, 2.8, 0.6, 3.1…
## $ cloud_cover_range          &amp;lt;int&amp;gt; 23, 27, 15, 17, 38, 27, 32, 11, 15, 12, 21,…
## $ growing_season_temperature &amp;lt;dbl&amp;gt; 12.65, 19.35, 11.55, 12.45, 26.45, 17.75, 2…
## $ rainfall_min               &amp;lt;int&amp;gt; 25, 37, 24, 29, 0, 60, 122, 1, 10, 12, 0, 0…
## $ solar_rad_max              &amp;lt;dbl&amp;gt; 31.317, 24.498, 25.283, 17.237, 28.038, 22.…
## $ solar_rad_min              &amp;lt;dbl&amp;gt; 5.209, 13.311, 1.587, 9.642, 19.102, 12.196…
## $ rainfall_range             &amp;lt;int&amp;gt; 37, 172, 63, 264, 226, 215, 303, 61, 245, 2…
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If there are categorical variables in a data frame, but there is no suitable &lt;code&gt;response&lt;/code&gt; variable, then the function &lt;code&gt;cor_select()&lt;/code&gt; can handle the multicollinearity management via pairwise correlations, but at a MUCH higher computational cost, and with different results, as shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tictoc::tic()
selected_predictors_response &amp;lt;- cor_select(
  df = vi,
  response = &amp;quot;vi_mean&amp;quot;,
  predictors = vi_predictors
)
tictoc::toc()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0.48 sec elapsed
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tictoc::tic()
selected_predictors_no_response &amp;lt;- cor_select(
  df = vi,
  predictors = vi_predictors
)
tictoc::toc()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 41.254 sec elapsed
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selected_predictors_response
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;country_population&amp;quot;         &amp;quot;topo_elevation&amp;quot;            
##  [3] &amp;quot;country_income&amp;quot;             &amp;quot;country_gdp&amp;quot;               
##  [5] &amp;quot;topo_slope&amp;quot;                 &amp;quot;humidity_range&amp;quot;            
##  [7] &amp;quot;soil_clay&amp;quot;                  &amp;quot;topo_diversity&amp;quot;            
##  [9] &amp;quot;soil_sand&amp;quot;                  &amp;quot;cloud_cover_range&amp;quot;         
## [11] &amp;quot;region&amp;quot;                     &amp;quot;growing_season_temperature&amp;quot;
## [13] &amp;quot;solar_rad_min&amp;quot;              &amp;quot;soil_soc&amp;quot;                  
## [15] &amp;quot;rainfall_min&amp;quot;               &amp;quot;swi_range&amp;quot;                 
## [17] &amp;quot;soil_nitrogen&amp;quot;              &amp;quot;rainfall_range&amp;quot;            
## [19] &amp;quot;swi_min&amp;quot;                    &amp;quot;subregion&amp;quot;                 
## [21] &amp;quot;biogeo_realm&amp;quot;               &amp;quot;cloud_cover_min&amp;quot;           
## [23] &amp;quot;soil_type&amp;quot;                  &amp;quot;aridity_index&amp;quot;             
## [25] &amp;quot;solar_rad_max&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selected_predictors_no_response
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;topo_elevation&amp;quot;             &amp;quot;topo_slope&amp;quot;                
##  [3] &amp;quot;country_population&amp;quot;         &amp;quot;topo_diversity&amp;quot;            
##  [5] &amp;quot;soil_clay&amp;quot;                  &amp;quot;humidity_range&amp;quot;            
##  [7] &amp;quot;soil_sand&amp;quot;                  &amp;quot;country_gdp&amp;quot;               
##  [9] &amp;quot;cloud_cover_range&amp;quot;          &amp;quot;country_income&amp;quot;            
## [11] &amp;quot;rainfall_min&amp;quot;               &amp;quot;soil_soc&amp;quot;                  
## [13] &amp;quot;swi_range&amp;quot;                  &amp;quot;growing_season_temperature&amp;quot;
## [15] &amp;quot;rainfall_range&amp;quot;             &amp;quot;soil_nitrogen&amp;quot;             
## [17] &amp;quot;solar_rad_min&amp;quot;              &amp;quot;aridity_index&amp;quot;             
## [19] &amp;quot;cloud_cover_min&amp;quot;            &amp;quot;temperature_max&amp;quot;           
## [21] &amp;quot;region&amp;quot;                     &amp;quot;swi_min&amp;quot;                   
## [23] &amp;quot;solar_rad_max&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The variable selection results differ because the numeric representations of the categorical variables are rather different between the two options. When no &lt;code&gt;response&lt;/code&gt; is provided, the function &lt;code&gt;cor_select()&lt;/code&gt; compares categorical predictors against numeric ones by encoding each categorical after each numeric, and compares pairs of categoricals using Cramer&amp;rsquo;s V, implemented in the function &lt;code&gt;cramer_v()&lt;/code&gt;. Additionally, Cramer&amp;rsquo;s V values are not directly comparable with Pearson or Spearman correlation scores, and having them together in the same analysis might induce bias during the variable selection. Not using the &lt;code&gt;response&lt;/code&gt; argument should always be the last option.&lt;/p&gt;
&lt;h4 id=&#34;preference-order&#34;&gt;Preference order&lt;/h4&gt;
&lt;p&gt;The argument &lt;code&gt;preference_order&lt;/code&gt; gives the user some control on what predictors should be removed first and what predictors should be kept during the multicollinearity filtering. This argument accepts a vector of predictor names in the order of interest, or the result of the function &lt;code&gt;preference_order()&lt;/code&gt;, which allows to define preference order following a quantitative criteria.&lt;/p&gt;
&lt;h5 id=&#34;manual-preference-order&#34;&gt;Manual preference order&lt;/h5&gt;
&lt;p&gt;Let&amp;rsquo;s start with the former option. Below, the argument &lt;code&gt;preference_order&lt;/code&gt; names several predictors that are of importance for a hypothetical analysis. The &lt;code&gt;predictors&lt;/code&gt; not in &lt;code&gt;preference_order&lt;/code&gt; are ranked by the absolute sum of their correlations with other predictors during the pairwise correlation filtering, and by their VIF during the VIF-based filtering.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selected_predictors &amp;lt;- cor_select(
  df = vi,
  response = &amp;quot;vi_mean&amp;quot;,
  predictors = vi_predictors,
  preference_order = c(
    &amp;quot;soil_temperature_mean&amp;quot;,
    &amp;quot;soil_temperature_max&amp;quot;,
    &amp;quot;soil_type&amp;quot;
  )
)

selected_predictors
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;soil_temperature_mean&amp;quot; &amp;quot;soil_temperature_max&amp;quot;  &amp;quot;soil_type&amp;quot;            
##  [4] &amp;quot;country_population&amp;quot;    &amp;quot;topo_elevation&amp;quot;        &amp;quot;country_income&amp;quot;       
##  [7] &amp;quot;country_gdp&amp;quot;           &amp;quot;topo_slope&amp;quot;            &amp;quot;humidity_range&amp;quot;       
## [10] &amp;quot;soil_clay&amp;quot;             &amp;quot;topo_diversity&amp;quot;        &amp;quot;soil_sand&amp;quot;            
## [13] &amp;quot;cloud_cover_range&amp;quot;     &amp;quot;region&amp;quot;                &amp;quot;soil_soc&amp;quot;             
## [16] &amp;quot;rainfall_min&amp;quot;          &amp;quot;swi_range&amp;quot;             &amp;quot;soil_nitrogen&amp;quot;        
## [19] &amp;quot;rainfall_range&amp;quot;        &amp;quot;subregion&amp;quot;             &amp;quot;biogeo_realm&amp;quot;         
## [22] &amp;quot;aridity_index&amp;quot;         &amp;quot;solar_rad_max&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that in the output, two of the variables in &lt;code&gt;preference_order&lt;/code&gt; are selected (&amp;ldquo;soil_temperature_mean&amp;rdquo; and &amp;ldquo;soil_type&amp;rdquo;), but one was removed (&amp;ldquo;soil_temperature_max&amp;rdquo;). This happens because at some point in the selection, the VIF of &amp;ldquo;soil_temperature_mean&amp;rdquo; and &amp;ldquo;soil_temperature_max&amp;rdquo; was higher than &lt;code&gt;max_vif&lt;/code&gt;, and the one with lower preference was removed.&lt;/p&gt;
&lt;h5 id=&#34;quantitative-preference-order&#34;&gt;Quantitative preference order&lt;/h5&gt;
&lt;p&gt;The function &lt;code&gt;preference_order()&lt;/code&gt; requires the &lt;code&gt;response&lt;/code&gt; argument, and takes a function &lt;code&gt;f&lt;/code&gt; that returns a value of association between the response and any predictor. This value is then located in the &amp;ldquo;preference&amp;rdquo; column of the function&amp;rsquo;s output.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;preference_rsquared &amp;lt;- preference_order(
  df = vi,
  response = &amp;quot;vi_mean&amp;quot;,
  predictors = vi_predictors,
  f = f_rsquared,
  workers = 1 #requires package future and future.apply for more workers
)

preference_rsquared
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                     predictor   preference
## 1            biogeo_ecoregion 0.8971347093
## 2       growing_season_length 0.8076216576
## 3                 koppen_zone 0.8050280970
## 4          koppen_description 0.7903458680
## 5                     soil_ph 0.7664428862
## 6                    swi_mean 0.7286901614
## 7               humidity_mean 0.7141389404
## 8                koppen_group 0.6996959734
## 9                biogeo_biome 0.6515724588
## 10               country_name 0.6448346803
## 11           cloud_cover_mean 0.6338773126
## 12                  soil_type 0.6318025761
## 13              rainfall_mean 0.6005761078
## 14               humidity_max 0.5876622545
## 15       soil_temperature_max 0.5827628810
## 16                    swi_max 0.5813558512
## 17            cloud_cover_max 0.5758002449
## 18               humidity_min 0.5705720164
## 19    growing_season_rainfall 0.5697006759
## 20     soil_temperature_range 0.5523074848
## 21               biogeo_realm 0.5031101984
## 22              solar_rad_max 0.4905225950
## 23     evapotranspiration_max 0.4814731607
## 24               rainfall_max 0.4783927311
## 25              aridity_index 0.4506424015
## 26                  subregion 0.4469207404
## 27                  swi_range 0.4217411381
## 28            cloud_cover_min 0.4135724066
## 29   evapotranspiration_range 0.4042241481
## 30          temperature_range 0.3753489250
## 31             rainfall_range 0.3545446680
## 32    temperature_seasonality 0.2499469281
## 33               rainfall_min 0.2484813976
## 34                    swi_min 0.2406964836
## 35             solar_rad_mean 0.2140860965
## 36              soil_nitrogen 0.1872886789
## 37                  continent 0.1818717607
## 38            temperature_max 0.1589418736
## 39                     region 0.1505256024
## 40                   soil_soc 0.1493958026
## 41    evapotranspiration_mean 0.1455828419
## 42            solar_rad_range 0.1300751363
## 43            temperature_min 0.1222051434
## 44          cloud_cover_range 0.1216812855
## 45       soil_temperature_min 0.1018471531
## 46             topo_diversity 0.0925948262
## 47                  soil_clay 0.0769366113
## 48             humidity_range 0.0575393339
## 49             country_income 0.0489946403
## 50                  soil_sand 0.0427943817
## 51             topo_elevation 0.0424759731
## 52 growing_season_temperature 0.0239161476
## 53                 topo_slope 0.0203697134
## 54      soil_temperature_mean 0.0170527033
## 55           temperature_mean 0.0067479780
## 56                  soil_silt 0.0059316757
## 57        growing_degree_days 0.0047849144
## 58     evapotranspiration_min 0.0009965488
## 59                country_gdp 0.0008850479
## 60              solar_rad_min 0.0005751350
## 61         country_population 0.0002513147
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result of &lt;code&gt;preference_order()&lt;/code&gt; can be plugged right away into the &lt;code&gt;preference_order&lt;/code&gt; argument of collinear.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selected_predictors &amp;lt;- collinear(
  df = vi,
  response = &amp;quot;vi_mean&amp;quot;,
  predictors = vi_predictors,
  preference_order = preference_rsquared
)
selected_predictors
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;biogeo_ecoregion&amp;quot;       &amp;quot;soil_temperature_range&amp;quot; &amp;quot;rainfall_min&amp;quot;          
##  [4] &amp;quot;solar_rad_mean&amp;quot;         &amp;quot;soil_nitrogen&amp;quot;          &amp;quot;continent&amp;quot;             
##  [7] &amp;quot;soil_soc&amp;quot;               &amp;quot;cloud_cover_range&amp;quot;      &amp;quot;topo_diversity&amp;quot;        
## [10] &amp;quot;soil_clay&amp;quot;              &amp;quot;humidity_range&amp;quot;         &amp;quot;country_income&amp;quot;        
## [13] &amp;quot;soil_sand&amp;quot;              &amp;quot;topo_elevation&amp;quot;         &amp;quot;topo_slope&amp;quot;            
## [16] &amp;quot;country_gdp&amp;quot;            &amp;quot;country_population&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This variable selection satisfies three conditions at once: maximum correlation between each predictor and the response, maximum pairwise correlation, and maximum VIF.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;f&lt;/code&gt; argument used by default is the function &lt;code&gt;f_rsquared()&lt;/code&gt;, that returns the R-squared between the response and any predictor.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;f_rsquared(
  x = &amp;quot;growing_season_length&amp;quot;,
  y = &amp;quot;vi_mean&amp;quot;,
  df = vi
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8076217
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are two other &lt;code&gt;f&lt;/code&gt; functions implemented:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;f_ga_deviance()&lt;/code&gt;: returns the explained deviance of a univariate GAM model between the response and each predictor, fitted with the function &lt;code&gt;mgcv::gam()&lt;/code&gt;. Only if the R package &lt;code&gt;mgcv&lt;/code&gt; is installed in the system.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f_rf_deviance()&lt;/code&gt;: returns the explained deviance of a univariate Random Forest model between the response and each predictor, fitted with the function &lt;code&gt;ranger::ranger()&lt;/code&gt;. Only if the R package &lt;code&gt;ranger&lt;/code&gt; is installed in the system.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Custom functions created by the user are also accepted as input, as long as they have the &lt;code&gt;x&lt;/code&gt;, &lt;code&gt;y&lt;/code&gt;, and &lt;code&gt;df&lt;/code&gt; arguments, and they return a single numeric value.&lt;/p&gt;
&lt;p&gt;These can be run in parallel across predictors by increasing the value of the &lt;code&gt;workers&lt;/code&gt; argument if the R packages &lt;code&gt;future&lt;/code&gt; and &lt;code&gt;future.apply&lt;/code&gt; are installed in the system.&lt;/p&gt;
&lt;h3 id=&#34;cor_select-and-vif_select&#34;&gt;&lt;code&gt;cor_select()&lt;/code&gt; and &lt;code&gt;vif_select()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The functions &lt;code&gt;cor_select()&lt;/code&gt; and &lt;code&gt;vif_select()&lt;/code&gt;, called within &lt;code&gt;collinear()&lt;/code&gt;, perform the pairwise correlation filtering, and the VIF-based filtering. The main difference between them is that &lt;code&gt;cor_select()&lt;/code&gt; can handle categorical predictors even when the &lt;code&gt;response&lt;/code&gt; is omitted, while &lt;code&gt;vif_select()&lt;/code&gt; ignores them entirely in such case.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selected_predictors_cor &amp;lt;- cor_select(
  df = vi,
  response = &amp;quot;vi_mean&amp;quot;,
  predictors = vi_predictors,
  preference_order = preference_rsquared
)

selected_predictors_vif &amp;lt;- vif_select(
  df = vi,
  response = &amp;quot;vi_mean&amp;quot;,
  predictors = vi_predictors,
  preference_order = preference_rsquared
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selected_predictors_cor
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;biogeo_ecoregion&amp;quot;       &amp;quot;soil_temperature_range&amp;quot; &amp;quot;rainfall_min&amp;quot;          
##  [4] &amp;quot;solar_rad_mean&amp;quot;         &amp;quot;soil_nitrogen&amp;quot;          &amp;quot;continent&amp;quot;             
##  [7] &amp;quot;soil_soc&amp;quot;               &amp;quot;cloud_cover_range&amp;quot;      &amp;quot;topo_diversity&amp;quot;        
## [10] &amp;quot;soil_clay&amp;quot;              &amp;quot;humidity_range&amp;quot;         &amp;quot;country_income&amp;quot;        
## [13] &amp;quot;soil_sand&amp;quot;              &amp;quot;topo_elevation&amp;quot;         &amp;quot;topo_slope&amp;quot;            
## [16] &amp;quot;country_gdp&amp;quot;            &amp;quot;country_population&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;selected_predictors_vif
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;biogeo_ecoregion&amp;quot;   &amp;quot;soil_type&amp;quot;          &amp;quot;rainfall_mean&amp;quot;     
##  [4] &amp;quot;biogeo_realm&amp;quot;       &amp;quot;solar_rad_max&amp;quot;      &amp;quot;subregion&amp;quot;         
##  [7] &amp;quot;soil_nitrogen&amp;quot;      &amp;quot;continent&amp;quot;          &amp;quot;soil_soc&amp;quot;          
## [10] &amp;quot;topo_diversity&amp;quot;     &amp;quot;soil_clay&amp;quot;          &amp;quot;country_income&amp;quot;    
## [13] &amp;quot;soil_sand&amp;quot;          &amp;quot;topo_slope&amp;quot;         &amp;quot;country_gdp&amp;quot;       
## [16] &amp;quot;country_population&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;target_encoding_lab&#34;&gt;&lt;code&gt;target_encoding_lab()&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The function &lt;code&gt;target_encoding_lab()&lt;/code&gt; is used within all other functions in the package to encode categorical variables as numeric. It implements four target encoding methods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;mean&amp;rdquo; (in &lt;code&gt;target_encoding_mean()&lt;/code&gt;): replaces each category with the mean of the response across the category. White noise can be added to this option to increase data variability.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;rank&amp;rdquo; (in &lt;code&gt;target_encoding_rank()&lt;/code&gt;): replaces each category with the rank of the mean of the response across the category.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;rnorm&amp;rdquo; (in &lt;code&gt;target_encoding_rnorm()&lt;/code&gt;): replaces each value in a category with a number generated by &lt;code&gt;stats::rnorm()&lt;/code&gt; from a normal distribution with the mean and the standard deviation of the response over the category.&lt;/li&gt;
&lt;li&gt;&amp;ldquo;loo&amp;rdquo; (in &lt;code&gt;target_encoding_loo()&lt;/code&gt;): replaces each value in a category with the mean of the response across all the other cases within the category. White noise can be added to this option to increase data variability.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The method &amp;ldquo;mean&amp;rdquo; is used as default throughout all functions in the package, but can be changed via the argument &lt;code&gt;encoding_method&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Below we use all methods to generate different numeric encodings for the categorical variable &amp;ldquo;koppen_zone&amp;rdquo;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;df &amp;lt;- target_encoding_lab(
  df = vi,
  response = &amp;quot;vi_mean&amp;quot;,
  predictors = &amp;quot;koppen_zone&amp;quot;,
  encoding_methods = c(
    &amp;quot;mean&amp;quot;,
    &amp;quot;rank&amp;quot;,
    &amp;quot;rnorm&amp;quot;,
    &amp;quot;loo&amp;quot;
  ),
  seed = 1,
  rnorm_sd_multiplier = c(0, 0.01, 0.1),
  white_noise = c(0, 0.01, 0.1),
  verbose = TRUE
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Encoding the variables:
## koppen_zone
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## New encoded predictor: &#39;koppen_zone__encoded_rank&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## New encoded predictor: &#39;koppen_zone__encoded_mean&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## New encoded predictor: &#39;koppen_zone__encoded_loo&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## New encoded predictor: &#39;koppen_zone__encoded_mean__white_noise_0.01&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## New encoded predictor: &#39;koppen_zone__encoded_loo__white_noise_0.01&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## New encoded predictor: &#39;koppen_zone__encoded_mean__white_noise_0.1&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## New encoded predictor: &#39;koppen_zone__encoded_loo__white_noise_0.1&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## New encoded predictor: &#39;koppen_zone__encoded_rnorm&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## New encoded predictor: &#39;koppen_zone__encoded_rnorm__sd_multiplier_0.01&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## New encoded predictor: &#39;koppen_zone__encoded_rnorm__sd_multiplier_0.1&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The relationship between these encoded versions of &amp;ldquo;koppen_zone&amp;rdquo; and the response are shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#get names of encoded variables
koppen_zone_encoded &amp;lt;- grep(
  pattern = &amp;quot;*__encoded*&amp;quot;,
  x = colnames(df),
  value = TRUE
)

#record the user&#39;s graphical parameters
user.par &amp;lt;- par(no.readonly = TRUE)

#modify graphical parameters for the plot
par(mfrow = c(4, 3))

#plot target encoding
x &amp;lt;- lapply(
  X = koppen_zone_encoded,
  FUN = function(x) plot(
    x = df[[x]],
    y = df$vi_mean,
    xlab = x,
    ylab = &amp;quot;vi_mean&amp;quot;,
    cex = 0.5
    )
)

#reset the user&#39;s graphical parameters
par(user.par)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function implementing each method can be used directly as well. The example below shows the &amp;ldquo;mean&amp;rdquo; method with the option &lt;code&gt;replace = FALSE&lt;/code&gt;, which replaces the categorical values with the numeric ones in the output data frame.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;head(vi[, c(&amp;quot;vi_mean&amp;quot;, &amp;quot;koppen_zone&amp;quot;)], n = 10)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    vi_mean koppen_zone
## 1     0.38         BSk
## 2     0.53         Cfa
## 3     0.45         Dfc
## 4     0.69         Cfb
## 5     0.42          Aw
## 6     0.68         Cfa
## 7     0.70          Af
## 8     0.26         BSh
## 9     0.55         Cwa
## 10    0.16         BWh
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;df &amp;lt;- target_encoding_mean(
  df = vi,
  response = &amp;quot;vi_mean&amp;quot;,
  predictor = &amp;quot;koppen_zone&amp;quot;,
  replace = TRUE
)

head(df[, c(&amp;quot;vi_mean&amp;quot;, &amp;quot;koppen_zone&amp;quot;)], n = 10)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    vi_mean koppen_zone
## 1     0.38   0.2487370
## 2     0.53   0.5661689
## 3     0.45   0.4338492
## 4     0.69   0.5889908
## 5     0.42   0.5275241
## 6     0.68   0.5661689
## 7     0.70   0.6708994
## 8     0.26   0.3230049
## 9     0.55   0.5218936
## 10    0.16   0.1330452
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you got here, thank you for your interest in the R package &lt;code&gt;collinear&lt;/code&gt;, I hope it can serve you well.&lt;/p&gt;
&lt;p&gt;And that&amp;rsquo;s a wrap!&lt;/p&gt;
&lt;p&gt;Blas M. Benito, PhD&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multicollinearity Hinders Model Interpretability</title>
      <link>https://blasbenito.com/post/multicollinearity-model-interpretability/</link>
      <pubDate>Sun, 29 Oct 2023 00:00:00 +0000</pubDate>
      <guid>https://blasbenito.com/post/multicollinearity-model-interpretability/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    This post is written for beginner to intermediate R users wishing to learn what multicollinearity is and how it can turn model interpretation into a challenge.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;
&lt;p&gt;In this post, I delve into the intricacies of model interpretation under the influence of multicollinearity, and use R and a toy data set to demonstrate how this phenomenon impacts both linear and machine learning models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The section &lt;em&gt;Multicollinearity Explained&lt;/em&gt; explains the origin of the word and the nature of the problem.&lt;/li&gt;
&lt;li&gt;The section &lt;em&gt;Model Interpretation Challenges&lt;/em&gt; describes how to create the toy data set, and applies it to &lt;em&gt;Linear Models&lt;/em&gt; and &lt;em&gt;Random Forest&lt;/em&gt; to explain how multicollinearity can make model interpretation a challenge.&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;Appendix&lt;/em&gt; shows extra examples of linear and machine learning models affected by multicollinearity.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I hope you&amp;rsquo;ll enjoy it!&lt;/p&gt;
&lt;h1 id=&#34;r-packages&#34;&gt;R packages&lt;/h1&gt;
&lt;p&gt;This tutorial requires the newly released R package 
&lt;a href=&#34;https://blasbenito.github.io/collinear/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;collinear&lt;/code&gt;&lt;/a&gt;, and a few more listed below. The optional ones are used only in the &lt;em&gt;Appendix&lt;/em&gt; at the end of the post.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#required
install.packages(&amp;quot;collinear&amp;quot;)
install.packages(&amp;quot;ranger&amp;quot;)
install.packages(&amp;quot;dplyr&amp;quot;)

#optional
install.packages(&amp;quot;nlme&amp;quot;)
install.packages(&amp;quot;glmnet&amp;quot;)
install.packages(&amp;quot;xgboost&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;multicollinearity-explained&#34;&gt;Multicollinearity Explained&lt;/h1&gt;
&lt;p&gt;This cute word comes from the amalgamation of these three Latin terms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;multus&lt;/em&gt;: adjective meaning &lt;em&gt;many&lt;/em&gt; or &lt;em&gt;multiple&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;con&lt;/em&gt;: preposition often converted to &lt;em&gt;co-&lt;/em&gt; (as in &lt;em&gt;co-worker&lt;/em&gt;) meaning &lt;em&gt;together&lt;/em&gt; or &lt;em&gt;mutually&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;linealis&lt;/em&gt; (later converted to &lt;em&gt;linearis&lt;/em&gt;): from &lt;em&gt;linea&lt;/em&gt; (line), adjective meaning &amp;ldquo;resembling a line&amp;rdquo; or &amp;ldquo;belonging to a line&amp;rdquo;, among others.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After looking at these serious words, we can come up with a (VERY) liberal translation: &amp;ldquo;several things together in the same line&amp;rdquo;. From here, we just have to replace the word &amp;ldquo;things&amp;rdquo; with &amp;ldquo;predictors&amp;rdquo; (or &amp;ldquo;features&amp;rdquo;, or &amp;ldquo;independent variables&amp;rdquo;, whatever rocks your boat) to build an intuition of the whole meaning of the word in the context of statistical and machine learning modeling.&lt;/p&gt;
&lt;p&gt;If I lost you there, we can move forward with this idea instead: &lt;strong&gt;multicollinearity happens when there are redundant predictors in a modeling dataset&lt;/strong&gt;. A predictor can be redundant because it shows a high pairwise correlation with other predictors, or because it is a linear combination of other predictors. For example, in a data frame with the columns &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, and &lt;code&gt;c&lt;/code&gt;, if the correlation between &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; is high, we can say that &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are mutually redundant and there is multicollinearity. But also, if &lt;code&gt;c&lt;/code&gt; is the result of a linear operation between &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;, like &lt;code&gt;c &amp;lt;- a + b&lt;/code&gt;, or &lt;code&gt;c &amp;lt;- a * 1 + b * 0.5&lt;/code&gt;, then we can also say that there is multicollinearity between &lt;code&gt;c&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt;, and &lt;code&gt;b&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Multicollinearity is a fact of life that lurks in most data sets. For example, in climate data, variables like temperature, humidity and air pressure are closely intertwined, leading to multicollinearity. That&amp;rsquo;s the case as well in medical research, where parameters like blood pressure, heart rate, and body mass index frequently display common patterns. Economic analysis is another good example, as variables such as Gross Domestic Product (GDP), unemployment rate, and consumer spending often exhibit multicollinearity.&lt;/p&gt;
&lt;h1 id=&#34;model-interpretation-challenges&#34;&gt;Model Interpretation Challenges&lt;/h1&gt;
&lt;p&gt;Multicollinearity isn&amp;rsquo;t inherently problematic, but it can be a real buzz kill when the goal is interpreting predictor importance in explanatory models. In the presence of highly correlated predictors, most modelling methods, from the veteran linear models to the fancy gradient boosting, attribute a large part of the importance to only one of the predictors and not the others. In such cases, neglecting multicollinearity will certainly lead to underestimate the relevance of certain predictors.&lt;/p&gt;
&lt;p&gt;Let me go ahead and develop a toy data set to showcase this issue. But let&amp;rsquo;s load the required libraries first.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#load the collinear package and its example data
library(collinear)
data(vi)

#other required libraries
library(ranger)
library(dplyr)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the &lt;code&gt;vi&lt;/code&gt; data frame shipped with the 
&lt;a href=&#34;https://blasbenito.github.io/collinear/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;collinear&lt;/code&gt;&lt;/a&gt; package, the variables &amp;ldquo;soil_clay&amp;rdquo; and &amp;ldquo;humidity_range&amp;rdquo; are not correlated at all (Pearson correlation = -0.06).&lt;/p&gt;
&lt;p&gt;In the code block below, the &lt;code&gt;dplyr::transmute()&lt;/code&gt; command selects and renames them as &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;. After that, the two variables are scaled and centered, and &lt;code&gt;dplyr::mutate()&lt;/code&gt; generates a few new columns:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;y&lt;/code&gt;: response variable resulting from a linear model where &lt;code&gt;a&lt;/code&gt; has a slope of 0.75, &lt;code&gt;b&lt;/code&gt; has a slope of 0.25, plus a bit of white noise generated with &lt;code&gt;runif()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;c&lt;/code&gt;: a new predictor highly correlated with &lt;code&gt;a&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;d&lt;/code&gt;: a new predictor resulting from a linear combination of &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(1)
df &amp;lt;- vi |&amp;gt;
  dplyr::slice_sample(n = 2000) |&amp;gt;
  dplyr::transmute(
    a = soil_clay,
    b = humidity_range
  ) |&amp;gt;
  scale() |&amp;gt;
  as.data.frame() |&amp;gt; 
  dplyr::mutate(
    y = a * 0.75 + b * 0.25 + runif(n = dplyr::n(), min = -0.5, max = 0.5),
    c = a + runif(n = dplyr::n(), min = -0.5, max = 0.5),
    d = (a + b)/2 + runif(n = dplyr::n(), min = -0.5, max = 0.5)
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Pearson correlation between all pairs of these predictors is shown below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;collinear::cor_df(
  df = df,
  predictors = c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;, &amp;quot;d&amp;quot;)
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 3
##   x     y     correlation
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 c     a           0.962
## 2 d     b           0.639
## 3 d     a           0.636
## 4 d     c           0.615
## 5 b     a          -0.047
## 6 c     b          -0.042
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this point, we have are two groups of predictors useful to understand how multicollinearity muddles model interpretation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Predictors with &lt;strong&gt;no&lt;/strong&gt; multicollinearity: &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Predictors with multicollinearity: &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;c&lt;/code&gt;, and &lt;code&gt;d&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the next two sections and the &lt;em&gt;Appendix&lt;/em&gt;, I show how and why model interpretation becomes challenging when multicollinearity is high. Let&amp;rsquo;s start with linear models.&lt;/p&gt;
&lt;h3 id=&#34;linear-models&#34;&gt;Linear Models&lt;/h3&gt;
&lt;p&gt;The code below fits &lt;em&gt;multiple linear regression models&lt;/em&gt; for both groups of predictors.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#non-collinear predictors
lm_ab &amp;lt;- lm(
  formula = y ~ a + b,
  data = df
  )

#collinear predictors
lm_abcd &amp;lt;- lm(
  formula = y ~ a + b + c + d,
  data = df
  )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I would like you to pay attention to the estimates of the predictors &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; for both models. The estimates are the slopes in the linear model, a direct indication of the effect of a predictor over the response.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;coefficients(lm_ab)[2:3] |&amp;gt; 
  round(4)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      a      b 
## 0.7477 0.2616
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;coefficients(lm_abcd)[2:5] |&amp;gt; 
  round(4)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      a      b      c      d 
## 0.7184 0.2596 0.0273 0.0039
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On one hand, the model with no multicollinearity (&lt;code&gt;lm_ab&lt;/code&gt;) achieved a pretty good solution for the coefficients of &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;. Remember that we created &lt;code&gt;y&lt;/code&gt; as &lt;code&gt;a * 0.75 + b * 0.25&lt;/code&gt; plus some noise, and that&amp;rsquo;s exactly what the model is telling us here, so the interpretation is pretty straightforward.&lt;/p&gt;
&lt;p&gt;On the other hand, the model with multicollinearity (&lt;code&gt;lm_abcd&lt;/code&gt;) did well with &lt;code&gt;b&lt;/code&gt;, but there are a few things in there that make the interpretation harder.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The coefficient of &lt;code&gt;a&lt;/code&gt; (0.7165) is slightly smaller than the true one (0.75), which could lead us to downplay its relationship with &lt;code&gt;y&lt;/code&gt; by a tiny bit. This is kinda OK though, as long as one is not using the model&amp;rsquo;s results to build nukes in the basement.&lt;/li&gt;
&lt;li&gt;The coefficient of &lt;code&gt;c&lt;/code&gt; is so small that it could led us to believe that this predictor not important at all to explain &lt;code&gt;y&lt;/code&gt;. But we know that &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;c&lt;/code&gt; are almost identical copies, so model interpretation here is being definitely muddled by multicollinearity.&lt;/li&gt;
&lt;li&gt;The coefficient of &lt;code&gt;d&lt;/code&gt; is tiny. Since &lt;code&gt;d&lt;/code&gt; results from the sum of &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt;, we could expect this predictor to be important in explaining &lt;code&gt;y&lt;/code&gt;, but it got the shorter end of the stick in this case.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is not that the model it&amp;rsquo;s wrong though. This behavior of the linear model results from the &lt;em&gt;QR decomposition&lt;/em&gt; (also &lt;em&gt;QR factorization&lt;/em&gt;) applied by functions like &lt;code&gt;lm()&lt;/code&gt;, &lt;code&gt;glm()&lt;/code&gt;, &lt;code&gt;glmnet::glmnet()&lt;/code&gt;, and &lt;code&gt;nlme::gls()&lt;/code&gt; to improve numerical stability and computational efficiency, and to&amp;hellip; address multicollinearity in the model predictors.&lt;/p&gt;
&lt;p&gt;The QR decomposition transforms the original predictors into a set of orthogonal predictors with no multicollinearity. This is the &lt;em&gt;Q matrix&lt;/em&gt;, created in a fashion that resembles the way in which a Principal Components Analysis generates uncorrelated components from a set of correlated variables.&lt;/p&gt;
&lt;p&gt;The code below applies QR decomposition to our multicollinear predictors, extracts the Q matrix, and shows the correlation between the new versions of &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;c&lt;/code&gt;, and &lt;code&gt;d&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#predictors names
predictors &amp;lt;- c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;, &amp;quot;d&amp;quot;)

#QR decomposition of predictors
df.qr &amp;lt;- qr(df[, predictors])

#extract Q matrix
df.q &amp;lt;- qr.Q(df.qr)
colnames(df.q) &amp;lt;- predictors

#correlation between transformed predictors
collinear::cor_df(df = df.q)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 3
##   x     y     correlation
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 d     c               0
## 2 c     b               0
## 3 d     b               0
## 4 d     a               0
## 5 c     a               0
## 6 b     a               0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new set of predictors we are left with after the QR decomposition have exactly zero correlation! And now they are not our original predictors anymore, and have a different interpretation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;a&lt;/code&gt; is now &amp;ldquo;the part of &lt;code&gt;a&lt;/code&gt; not in &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;c&lt;/code&gt;, and &lt;code&gt;d&lt;/code&gt;&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;b&lt;/code&gt; is now &amp;ldquo;the part of &lt;code&gt;b&lt;/code&gt; not in &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;c&lt;/code&gt;, and &lt;code&gt;d&lt;/code&gt;&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;&amp;hellip;and so on&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The result of the QR decomposition can be plugged into the &lt;code&gt;solve()&lt;/code&gt; function along with the response vector to estimate the coefficients of the linear model.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;solve(a = df.qr, b = df$y) |&amp;gt; 
  round(4)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      a      b      c      d 
## 0.7189 0.2595 0.0268 0.0040
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These are almost exactly the ones we got for our model with multicollinearity. In the end, the coefficients resulting from a linear model are not those of the original predictors, but the ones of their uncorrelated versions generated by the QR decomposition.&lt;/p&gt;
&lt;p&gt;But this is not the only issue of model interpretability under multicollinearity. Let&amp;rsquo;s take a look at the standard errors of the estimates. These are a measure of the coefficient estimation uncertainty, and are used to compute the p-values of the estimates. As such, they are directly linked with the &amp;ldquo;statistical significance&amp;rdquo; (whatever that means) of the predictors within the model.&lt;/p&gt;
&lt;p&gt;The code below shows the standard errors of the model without and with multicollinearity.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(lm_ab)$coefficients[, &amp;quot;Std. Error&amp;quot;][2:3] |&amp;gt; 
  round(4)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      a      b 
## 0.0066 0.0066
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;summary(lm_abcd)$coefficients[, &amp;quot;Std. Error&amp;quot;][2:5] |&amp;gt; 
  round(4)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      a      b      c      d 
## 0.0267 0.0134 0.0232 0.0230
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These standard errors of the model with multicollinearity are an order of magnitude higher than the ones of the model without multicollinearity.&lt;/p&gt;
&lt;p&gt;Since our toy dataset is relatively large (2000 cases) and the relationship between the response and a few of the predictors pretty robust, there are no real issues arising, as these differences in estimation precision are not enough to change the p-values of the estimates. However, in a small data set with high multicollinearity and a weaker relationship between the response and the predictors, standard errors of the estimate become wide, which increases p-values and reduces &amp;ldquo;significance&amp;rdquo;. Such a situation might lead us to believe that a predictor does not explain the response, when in fact it does. And this, again, is a model interpretability issue caused by multicollinearity.&lt;/p&gt;
&lt;p&gt;At the end of this post there is an appendix with code examples of other types of linear models that use QR decomposition and become challenging to interpret in the presence of multicollinearity. Play with them as you please!&lt;/p&gt;
&lt;p&gt;Now, let&amp;rsquo;s take a look at how multicollinearity can also mess up the interpretation of a commonly used machine learning algorithm.&lt;/p&gt;
&lt;h3 id=&#34;random-forest&#34;&gt;Random Forest&lt;/h3&gt;
&lt;p&gt;It is not uncommon to hear something like &amp;ldquo;random forest is insensitive to multicollinearity&amp;rdquo;. Actually, I cannot confirm nor deny that I have said that before. Anyway, it is kind of true if one is focused on prediction problmes. However, when the aim is interpreting predictor importance scores, then one has to be mindful about multicollinearity as well.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s see an example. The code below fits two random forest models with our two sets of predictors.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#non-collinear predictors
rf_ab &amp;lt;- ranger::ranger(
  formula = y ~ a + b,
  data = df,
  importance = &amp;quot;permutation&amp;quot;,
  seed = 1 #for reproducibility
)

#collinear predictors
rf_abcd &amp;lt;- ranger::ranger(
  formula = y ~ a + b + c + d,
  data = df,
  importance = &amp;quot;permutation&amp;quot;,
  seed = 1
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&amp;rsquo;s take a look at the prediction error the two models on the out-of-bag data. While building each regression tree, Random Forest leaves a random subset of the data out. Then, each case gets a prediction from all trees that had it in the out-of-bag data, and the prediction error is averaged across all cases to get the numbers below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rf_ab$prediction.error
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1026779
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rf_abcd$prediction.error
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1035678
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to these numbers, these two models are basically equivalent in their ability to predict our response &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;But now, you noticed that I set the argument &lt;code&gt;importance&lt;/code&gt; to &amp;ldquo;permutation&amp;rdquo;. Permutation importance quantifies how the out-of-bag error increases when a predictor is permuted across all trees where the predictor is used. It is pretty robust importance metric that bears no resemblance whatsoever with the coefficients of a linear model. Think of it as a very different way to answer the question &amp;ldquo;what variables are important in this model?&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;The permutation importance scores of the two random forest models are show below.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rf_ab$variable.importance |&amp;gt; round(4)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      a      b 
## 1.0702 0.1322
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rf_abcd$variable.importance |&amp;gt; round(4)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      a      b      c      d 
## 0.5019 0.0561 0.1662 0.0815
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is one interesting detail here. The predictor &lt;code&gt;a&lt;/code&gt; has a permutation error three times higher than &lt;code&gt;c&lt;/code&gt; in the second model, even though we could expect them to be similar due to their very high correlation. There are two reasons for this mismatch:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Random Forest is much more sensitive to the white noise in &lt;code&gt;c&lt;/code&gt; than linear models, especially in the deep parts of the regression trees, due to local (within-split data) decoupling with the response &lt;code&gt;y&lt;/code&gt;. In consequence, it does not get selected as often as &lt;code&gt;a&lt;/code&gt; in these deeper areas of the trees, and has less overall importance.&lt;/li&gt;
&lt;li&gt;The predictor &lt;code&gt;c&lt;/code&gt; competes with &lt;code&gt;d&lt;/code&gt;, that has around 50% of the information in &lt;code&gt;c&lt;/code&gt; (and &lt;code&gt;a&lt;/code&gt;). If we remove &lt;code&gt;d&lt;/code&gt; from the model, then the permutation importance of &lt;code&gt;c&lt;/code&gt; doubles up. Then, with &lt;code&gt;d&lt;/code&gt; in the model, we underestimate the real importance of &lt;code&gt;c&lt;/code&gt; due to multicollinearity alone.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;rf_abc &amp;lt;- ranger::ranger(
  formula = y ~ a + b + c,
  data = df,
  importance = &amp;quot;permutation&amp;quot;,
  seed = 1
)
rf_abc$variable.importance |&amp;gt; round(4)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      a      b      c 
## 0.5037 0.1234 0.3133
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With all that in mind, we can conclude that interpreting importance scores in Random Forest models is challenging when multicollinearity is high. But Random Forest is not the only machine learning affected by this issue. In the Appendix below I have left an example with Extreme Gradient Boosting so you can play with it.&lt;/p&gt;
&lt;p&gt;And that&amp;rsquo;s all for now, folks, I hope you found this post useful!&lt;/p&gt;
&lt;h1 id=&#34;appendix&#34;&gt;Appendix&lt;/h1&gt;
&lt;p&gt;This section shows several extra examples of linear and machine learning models you can play with.&lt;/p&gt;
&lt;h2 id=&#34;other-linear-models-using-qr-decomposition&#34;&gt;Other linear models using QR decomposition&lt;/h2&gt;
&lt;p&gt;As I commented above, many linear modeling functions use QR decomposition, and you will have to be careful interpreting model coefficients in the presence of strong multicollinearity in the predictors.&lt;/p&gt;
&lt;p&gt;Here I show several examples with &lt;code&gt;glm()&lt;/code&gt; (Generalized Linear Models), &lt;code&gt;nlme::gls()&lt;/code&gt; (Generalized Least Squares), and &lt;code&gt;glmnet::cv.glmnet()&lt;/code&gt; (Elastic Net Regularization). In all them, no matter how fancy, the interpretation of coefficients becomes tricky when multicollinearity is high.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Generalized Linear Models with glm()&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#Generalized Linear Models
#non-collinear predictors
glm_ab &amp;lt;- glm(
  formula = y ~ a + b,
  data = df
  )

round(coefficients(glm_ab), 4)[2:3]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      a      b 
## 0.7477 0.2616
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#collinear predictors
glm_abcd &amp;lt;- glm(
  formula = y ~ a + b + c + d,
  data = df
  )

round(coefficients(glm_abcd), 4)[2:5]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      a      b      c      d 
## 0.7184 0.2596 0.0273 0.0039
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Generalized Least Squares with nlme::gls()&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(nlme)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &#39;nlme&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &#39;package:dplyr&#39;:
## 
##     collapse
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#Generalized Least Squares
#non-collinear predictors
gls_ab &amp;lt;- nlme::gls(
  model = y ~ a + b,
  data = df
  )

round(coefficients(gls_ab), 4)[2:3]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      a      b 
## 0.7477 0.2616
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#collinear predictors
gls_abcd &amp;lt;- nlme::gls(
  model = y ~ a + b + c + d,
  data = df
  )

round(coefficients(gls_abcd), 4)[2:5]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      a      b      c      d 
## 0.7184 0.2596 0.0273 0.0039
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Elastic Net Regularization and Lasso penalty with glmnet::glmnet()&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(glmnet)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: Matrix
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loaded glmnet 4.1-8
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#Elastic net regularization with Lasso penalty
#non-collinear predictors
glmnet_ab &amp;lt;- glmnet::cv.glmnet(
  x = as.matrix(df[, c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;)]),
  y = df$y,
  alpha = 1 #lasso penalty
)

round(coef(glmnet_ab$glmnet.fit, s = glmnet_ab$lambda.min), 4)[2:3]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7438 0.2578
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#collinear predictors
glmnet_abcd &amp;lt;- glmnet::cv.glmnet(
  x = as.matrix(df[, c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;, &amp;quot;d&amp;quot;)]),
  y = df$y,
  alpha = 1 
)

#notice that the lasso regularization nuked the coefficients of predictors b and c
round(coef(glmnet_abcd$glmnet.fit, s = glmnet_abcd$lambda.min), 4)[2:5]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.7101 0.2507 0.0267 0.0149
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;extreme-gradient-boosting-under-multicollinearity&#34;&gt;Extreme Gradient Boosting under multicollinearity&lt;/h2&gt;
&lt;p&gt;Gradient Boosting models trained with multicollinear predictors behave in a way similar to linear models with QR decomposition. When two variables are highly correlated, one of them is going to have an importance much higher than the other.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(xgboost)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &#39;xgboost&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &#39;package:dplyr&#39;:
## 
##     slice
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#without multicollinearity
gb_ab &amp;lt;- xgboost::xgboost(
  data = as.matrix(df[, c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;)]),
  label = df$y,
  objective = &amp;quot;reg:squarederror&amp;quot;,
  nrounds = 100,
  verbose = FALSE
  )

#with multicollinearity
gb_abcd &amp;lt;- xgboost::xgboost(
  data = as.matrix(df[, c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;, &amp;quot;d&amp;quot;)]),
  label = df$y,
  objective = &amp;quot;reg:squarederror&amp;quot;,
  nrounds = 100,
  verbose = FALSE
)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;xgb.importance(model = gb_ab)[, c(1:2)]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Feature      Gain
## 1:       a 0.8463005
## 2:       b 0.1536995
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;xgb.importance(model = gb_abcd)[, c(1:2)] |&amp;gt; 
  dplyr::arrange(Feature)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Feature       Gain
## 1:       a 0.78129661
## 2:       b 0.07386393
## 3:       c 0.03595619
## 4:       d 0.10888327
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But there is a twist too. When two variables are perfectly correlated, one of them is removed right away from the model!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#replace c with perfect copy of a
df$c &amp;lt;- df$a

#with multicollinearity
gb_abcd &amp;lt;- xgboost::xgboost(
  data = as.matrix(df[, c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;, &amp;quot;d&amp;quot;)]),
  label = df$y,
  objective = &amp;quot;reg:squarederror&amp;quot;,
  nrounds = 100,
  verbose = FALSE
)

xgb.importance(model = gb_abcd)[, c(1:2)] |&amp;gt; 
  dplyr::arrange(Feature)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Feature       Gain
## 1:       a 0.79469959
## 2:       b 0.07857141
## 3:       d 0.12672900
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
