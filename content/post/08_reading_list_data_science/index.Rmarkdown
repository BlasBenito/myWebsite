---
title: "My Reading List: Data Science"
author: ''
date: '2024-01-09'
slug: my-reading-list-data-science
categories: []
tags: [Data Science, Data Preprocessing, Machine Learning, Model Explainability, Model Interpretability]
subtitle: ''
summary: 'Live post with a curated list of high-quality data science posts and videos I found enlightening.'
authors: [admin]
lastmod: '2024-01-09T08:14:23+02:00'
featured: no
draft: false
image:
  caption: Image generated by [craiyon.com](https://www.craiyon.com)
  focal_point: Smart
  margin: auto
projects: []
---

This is a live post listing links to Data Science related posts and videos I consider to be interesting, high-quality, or even essential to better understand particular topics within such a wide field. 

# Data Preprocessing

## Target Encoding

[**Extending Target Encoding**](https://towardsdatascience.com/extending-target-encoding-443aa9414cae): post by [Daniele Micci-Barreca](https://www.aitimejournal.com/interview-with-daniele-micci-barreca-product-analytics-lead-data-science-google/30110/) explaining how he came up with the idea of target encoding, and its possible extensions.

[**Target encoding done the right way**](https://maxhalford.github.io/blog/target-encoding/): post by [Max Halford](https://maxhalford.github.io/bio/), Head of Data at [Carbonfact](https://www.carbonfact.com/), explaining in detail how to combine additive smoothing and target encoding.

# Analysis and Modeling

## Modeling Methods

[**Generalized Additive Models**](https://m-clark.github.io/generalized-additive-models/): A good online book on Generalized Additive Models by [Michael Clark](https://m-clark.github.io/about.html), Senior Machine Learning Scientist at [Strong Analytics](https://www.strong.io/).

## Model Explainability

[**Model-Independent Score Explanation**](https://towardsdatascience.com/a-simple-model-independent-score-explanation-method-c17002d66da7): Post by [Daniele Micci-Barreca](https://www.aitimejournal.com/interview-with-daniele-micci-barreca-product-analytics-lead-data-science-google/30110/) on model explainability. It also explains a very clever method to better understand any model just from it's predictions.

[**AI Explanations whitepaper**](https://storage.googleapis.com/cloud-ai-whitepapers/AI%20Explainability%20Whitepaper.pdf): White paper of Google's "AI Explanations" product with a pretty good overall view of the state of the art of model explainability.

[**Towards A Rigorous Science of Interpretable Machine Learning**](https://arxiv.org/abs/1702.08608): Pre-print by Finale Doshi-Velez and Been Kim offering a rigorous definition and evaluation of model interpretability.

## Spatial Analysis

[PostGEESE? Introducing The DuckDB Spatial Extension](https://duckdb.org/2023/04/28/spatial.html): In this post, the authors of [DuckDB](https://duckdb.org/) present the new PostGIS-like *spatial* extension for this popular in-process data base engine.

[Geocomputation with Python](https://py.geocompx.org/): A very nice book on geographic data analysis with Python.

# Coding

## General Concepts

[Why You Shouldn't Nest Your Code](https://youtu.be/CFRhGnuXG-4?si=7Xr3E9L7GFvoRJqA): In this wonderful video, [CodeAesthetic](https://www.youtube.com/@CodeAesthetic) explains in detail (and beautiful graphics!) a couple of methods to reduce the level of nesting in our code to improve readability and maintainability. This video has truly changed how I code in R!

## R

[Taking R to its limits: 70+ tips](https://peerj.com/preprints/26605v1/): This pre-print (not peer-reviewed AFAIK) by Tsagris and Papadakis offers a long list of tips to speed-up computation with the R language. I think a few of these tips lack enough context or are poorly explained, but it's still a good resource to help optimize our R code.

[Code Smell: Error Handling Eclipse ](https://www.njtierney.com/post/2023/12/06/long-errors-smell/): This post by [Nick Tierney](https://fosstodon.org/@njtierney@aus.social) explains how to address these situations when *error checking code totally eclipses the intent of the code*.

[Building a team of internal R packages](https://www.emilyriederer.com/post/team-of-packages/): This post by [Emily Riederer](https://www.emilyriederer.com/about) delves into the particularities of building a team of R packages to do jobs helping a organization answer impactful questions.

## Python

[Python Rgonomics](https://www.emilyriederer.com/post/py-rgo/): In this post, [Emily Riederer](https://www.emilyriederer.com/about) offers a list of Python libraries with an "R feeling".


# Other Fancy Things

[What is Retrieval-Augmented Generation (RAG)?](https://youtu.be/T-D1OfcDW1M?si=sAZO-5NGD8yF2WYe): In this video, Marina Danilevsky, Senior Data Scientist at IBM, offers a pretty good explanation on how the [Retrieval-Augmented Generation](https://research.ibm.com/blog/retrieval-augmented-generation-RAG?utm_id=YT-101-What-is-RAG&_gl=1*p6ef17*_ga*MTQwMzQ5NjMwMi4xNjkxNDE2MDc0*_ga_FYECCCS21D*MTY5MjcyMjgyNy40My4xLjE2OTI3MjMyMTcuMC4wLjA.) method can improve the credibility of large language models.

[A novel framework for spatio-temporal prediction of environmental data using deep learning](https://www.nature.com/articles/s41598-020-79148-7): This paper by [Federico Amato](https://www.linkedin.com/in/federico-amato-66208637) and collaborators describes an intriguing regression method combining a feedforward neural network with empirical orthogonal functions for spatio-temporal interpolation. Regrettably, the paper offers no code or data at all, but it's still an interesting read.

[Large Models for Time Series and
Spatio-Temporal Data A Survey and Outlook](https://arxiv.org/pdf/2310.10196.pdf): This pre-print by Weng and collaborators reviews the current state of the art in spatio-temporal modelling with Large Language Models and Pre-Trained Foundation Models.

