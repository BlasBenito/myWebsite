---
title: "{distantia} Demo: Covid-19 Prevalence in California"
author: ""
date: '2025-01-25'
slug: distantia-showcase-covid
categories: []
tags:
- Rstats
- Dynamic Time Warping
- Data Science
- Time Series Analysis
- Tutorial
subtitle: ''
summary: "Showcase with real examples of the analytical capabilities implemented in the R package 'distantia'."
authors: [admin]
lastmod: '2025-01-25T07:28:01+01:00'
featured: no
draft: true
image:
  caption: ''
  focal_point: Smart
  margin: auto
projects: []
toc: true
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  fig.width = 8, 
  fig.height = 6
)
```


## Summary

This post showcases the capabilities of the R package [`distantia`](https://blasbenito.github.io/distantia/) to load, explore, and analyze epidemiological time series.

## Setup

This tutorial requires the following packages:

  - [`distantia`](https://blasbenito.github.io/distantia/): time series analysis via dynamic time warping.
  - [`dtw`](https://dynamictimewarping.github.io/): dynamic time warping library.
  - [`future`](https://future.futureverse.org/): parallelized execution.
  - [`zoo`](https://cran.r-project.org/web/packages/zoo/index.html): management of regular and irregular time series.
  - [`dplyr`](https://dplyr.tidyverse.org/): data frame manipulation.
  - [`mapview`](https://r-spatial.github.io/mapview/): easy to use interactive map visualization.
  - [`reactable`](https://glin.github.io/reactable/): interactive tables.
  - [`factoextra`](https://rpkgs.datanovia.com/factoextra/index.html): plot results of hierarchical clustering.
  - [`visreg`](https://CRAN.R-project.org/package=visreg): response curves of statistical models.

```{r, message = FALSE, warning = FALSE}
library(distantia, quietly = TRUE)
library(dtw)
library(zoo)
library(dplyr)
library(mapview)
library(reactable)
library(factoextra, quietly = TRUE)
library(collinear)
library(coefplot)
library(visreg)
```

## Example Data

This demo focuses on two example data frames shipped with the package `distantia`: `covid_counties` and `covid_prevalence`.

### `covid_counties`

Stored as a [`simple features`](https://r-spatial.github.io/sf/) data frame, `covid_counties` contains county polygons and several socioeconomic variables. It is connected to `covid_prevalence` by county name, which is stored in the column `name`.

```{r, echo = FALSE, cache=TRUE}
la_population <- mapview(
  covid_counties, 
  zcol = "population",
  label = "name"
  )

htmlwidgets::saveWidget(
  la_population@map, 
  file = "la_population.html", 
  selfcontained = TRUE
  )
```

<iframe src="la_population.html" name="LA_Population"
  width="600" height="600" scrolling="auto" frameborder="0">
   <p>California counties represented in the Covid-19 dataset.</p>
</iframe>

```{r, echo = FALSE}
rm(la_population)
```


The socioeconomic variables available in `covid_counties` are:

  - `area_hectares`: county surface.
  - `population`: county population.
  - `poverty_percentage`: population percentage below the poverty line.
  - `median_income`: median county income in dollars.
  - `domestic_product`: yearly domestic product in **b**illions (not a typo) of dollars.
  - `daily_miles_traveled`: daily miles traveled by the average inhabitant.
  - `employed_percentage`: percentage of the county population under employment.
  
Please, take in mind that these variables were included in the dataset because they were easy to capture from on-line sources, not because of their importance for epidemiological analyses.

### `covid_prevalence`

This data frame contains weekly Covid-19 prevalence in 36 California counties between 2020-03-16 and 2023-12-18. It is derived from a daily prevalence dataset available [here](https://github.com/BlasBenito/distantia/blob/main/data_full/covid_prevalence.rda).
  
The prevalence time series has the columns `name`, `time`, with the date of the first day of the week each data point represents, and `prevalence`, expressed as proportion of positive tests. The table below shows the first rows of this data frame.
  
```{r, echo = FALSE}
covid_prevalence |> 
  reactable::reactable(
    pagination = TRUE,
    searchable = TRUE,
    sortable = TRUE,
    showSortable = TRUE,
    filterable = TRUE,
    resizable = TRUE,
    defaultPageSize = 10,
    showPageSizeOptions = TRUE,
    striped = TRUE,
    compact = TRUE,
    wrap = FALSE,
    fullWidth = FALSE
  )
```

## Objective

This post focuses on the Covid-19 dataset described above to showcase the applications of `distantia` to the analysis of epidemiological time series. 

  - **Prepare**: transform the `covid_prevalence` data frame into a format compatible with `distantia`.
  - **Explore**: time series visualization and computation of descriptive statistics.
  - **Compare**: 
  - **Analyze**:
  
**DISCLAIMER:** I am not an epidemiologist, so I will refrain from interpreting any results, and will focus on technical details about the usage of `distantia` insted.

## Data Preparation

This section shows how to transform the data frame `covid_prevalence` into a format compatible with `distantia`.

A **time series list**, or `tsl` for short, is a list of [`zoo`](https://cran.r-project.org/web/packages/zoo/index.html) time series representing unique realizations of the same phenomena observed in different sites, times, or individuals. All [data manipulation](https://blasbenito.github.io/distantia/articles/time_series_lists.html) and analysis functions in `distantia` are designed to be applied to all time series in a `tsl` at once.

The function `tsl_initialize()` transforms time series stored as long data frames into time series lists.

```{r tsl_init, cache=TRUE, cache.path="cache/"}
tsl <- distantia::tsl_initialize(
  x = covid_prevalence,
  name_column = "name",
  time_column = "time"
)
```

Each element in `tsl` is named after the county the data belongs to.

```{r}
names(tsl)
```

The `zoo` objects within `tsl` also have the attribute `name` to help track the data in case it is extracted from the time series list.

```{r}
attributes(tsl[[1]])$name
attributes(tsl[[2]])$name
```

Each individual `zoo` object comprises a time index and a data matrix.

```{r}
zoo::index(tsl[["Alameda"]]) |> 
  head()
```

```{r}
zoo::coredata(tsl[["Alameda"]]) |> 
  head()
```

## Exploration

This section describes the tools in `distantia` that may help develop an intuition on the properties of the data at hand, either via visualization or descriptive analysis.

### Visualization

The function `tsl_plot()` provides a static multipanel visualization of a large number of time series at once.

```{r, fig.height=12}
distantia::tsl_plot(
  tsl = tsl,
  columns = 3,
  guide = FALSE,
  text_cex = 1.2
)
```

Combined with `tsl_subset()`, it can help focus on particular counties and zoom-in over specific time periods.

```{r, fig.height=3}
distantia::tsl_plot(
  tsl = tsl_subset(
    tsl = tsl,
    names = c("Los_Angeles", "Kings"),
    time = c("2021-09-01", "2022-01-31")
  ),
  guide = FALSE
)
```

### Descriptive Stats

Time series have at least two dimensions of interest: *time*, and the variable/s of interest, such as prevalence in this case.

Having a good understanding of the time features of a time series is important, because some data management decisions depend on it. Details like length, resolution, time units, or regularity may define how we design an analysis. In `distantia`, the function `tsl_time()` provides all relevant details about the time in your time series list. 

```{r}
df_time <- distantia::tsl_time(
  tsl = tsl
)
```

The table below shows the first five rows of `df_time`, with the name of the time series, the class of the time index in each zoo object, the units, length and resolution, and their time ranges.

```{r, echo = FALSE}
df_time |> 
  dplyr::select(name, class, units, length, resolution, begin, end) |> 
  reactable::reactable(
    pagination = TRUE,
    searchable = TRUE,
    sortable = TRUE,
    showSortable = TRUE,
    filterable = TRUE,
    resizable = TRUE,
    defaultPageSize = 10,
    showPageSizeOptions = TRUE,
    striped = TRUE,
    compact = TRUE,
    wrap = FALSE,
    fullWidth = FALSE
  )
```

Here, all time series are regular and have the same time resolution and range, which makes the table above rightfully boring.

Once acquainted with time, having a summary of the values in each time series also helps make sense of the main properties of the data. The function `tsl_stats()` summarizes several important statistical properties of the time series in `tsl`.
  
```{r}
df_stats <- distantia::tsl_stats(
  tsl = tsl,
  lags = 1:6 #weeks
)
```

The first part of the output corresponds with common statistical descriptors, such as centrality and dispersion metrics, and higher moments.

```{r, echo=FALSE}
df_stats |> 
  dplyr::select(name, min, q1, median, q3, max, sd, range, iq_range, skewness, kurtosis) |> 
  dplyr::mutate(dplyr::across(dplyr::where(is.numeric), ~ round(.x, 2))) |> 
  reactable::reactable(
    pagination = TRUE,
    searchable = TRUE,
    sortable = TRUE,
    showSortable = TRUE,
    filterable = TRUE,
    resizable = TRUE,
    defaultPageSize = 10,
    showPageSizeOptions = TRUE,
    striped = TRUE,
    compact = TRUE,
    wrap = FALSE,
    fullWidth = FALSE
  )
```

The second part of the output, produced by the `lags` argument, shows time series autocorrelation (Moran's I) for different time lags. Since the resolution of all time series is 7 days per data-point, each time lag represents a week. A value of 0.9 for the lag 1 indicates the Pearson correlation between the prevalence of each data point and its precedent neighbor.

```{r, echo = FALSE}
df_stats |> 
  select(name, dplyr::contains("lag")) |> 
  dplyr::mutate(dplyr::across(dplyr::where(is.numeric), ~ round(.x, 2))) |> 
  dplyr::rename_with(~ gsub("ac_", "", .)) |> 
  dplyr::rename_with(~ gsub("_", "", .)) |> 
  reactable::reactable(
    pagination = TRUE,
    searchable = TRUE,
    sortable = TRUE,
    showSortable = TRUE,
    filterable = TRUE,
    resizable = TRUE,
    defaultPageSize = 10,
    showPageSizeOptions = TRUE,
    striped = TRUE,
    compact = TRUE,
    wrap = FALSE,
    fullWidth = TRUE
  )
```

The stats produced by `tsl_stats()` can be joined to the spatial data frame `covid_counties` using their common column `name` to link cases.

```{r}
sf_stats <- dplyr::inner_join(
  x = covid_counties[, "name"],
  y = df_stats,
  by = "name"
)
```

This join facilitates mapping any of the descriptive stats. For example, the map below shows the maximum prevalence per county across the complete time period. 

```{r, eval = FALSE, warning = FALSE}
mapview::mapview(
  sf_stats, 
  zcol = "q3",
  layer.name = "Max prevalence",
  label = "name",
  col.regions = distantia::color_continuous()
  )
```

```{r, echo = FALSE, cache=TRUE, warning = FALSE}
max_prevalence <- mapview(
  sf_stats, 
  zcol = "max",
  label = "name",
  col.regions = distantia::color_continuous()
  )

htmlwidgets::saveWidget(
  max_prevalence@map, 
  file = "max_prevalence.html", 
  selfcontained = TRUE
  )

rm(max_prevalence)
```

<iframe src="max_prevalence.html" name="Max_prevalence"
  width="600" height="600" scrolling="auto" frameborder="0">
   <p>Maximum Covid-19 prevalence in California counties.</p>
</iframe>

The functions `tsl_subset()` and `tsl_stats()` can be combined to generate stats focused in a given period of time or sub-group of time series. As example, the code below illustrates how to generate the stats for the year 2021.

```{r, eval = FALSE}
df_stats_2021 <- distantia::tsl_stats(
  tsl = tsl_subset(
    tsl = tsl,
    time = c("2021-01-01", "2021-12-31")
  ),
  lags = 1:6
)
```


## Computing Dissimilarity Scores

The package `distantia` is specifically designed to compare time series, and provides two general methods to do so: **Lock-Step (LS)**  and [**Dynamic time warping (DTW)**](https://www.blasbenito.com/post/dynamic-time-warping/). [This article](https://blasbenito.github.io/distantia/articles/dynamic_time_warping_and_lock_step.html) provides a detailed guide on how to apply these methods with `distantia`. 

### Dynamic Time Warping and Lock-Step Comparison

The **LS** method directly compares samples observed at the same time in time series of the same length. It is computationally efficient and easy to interpret but cannot account for differences in outbreak speed or timing, potentially missing underlying similarities when outbreaks are not synchronized.

**DTW** warps the time axis of the compared time series to maximize shape similarity. It adjusts for differences in the speed and timing of outbreaks, such as epidemic waves peaking at different times in different regions, and works well with time series of varying lengths or temporal resolutions. However, DTW is computationally expensive for large data sets, can be harder to interpret, and is sensitive to data scaling.

Before going forward, let me show a little example to help develop a sense of how DTW and LS work on a small subset of our time series. The figure below shows two years of data for San Francisco, Napa, and Solano.

```{r, fig.height=3.5, echo = FALSE}
tsl_smol <- distantia::tsl_subset(
  tsl = tsl,
  names = c("San_Francisco", "Napa", "Solano"),
  time = c("2021-01-01", "2023-01-01")
)

distantia::tsl_plot(
  tsl = tsl_smol, 
  guide = FALSE,
  text_cex = 1.3
  )
```
At first glance, Napa and Solano seem quite well synchronized and look very similar. On the other hand, San Francisco, in spite of having the same number of events as the other two, shows a timing difference of several months.

The table below shows the **LS** comparison between these time series. The `psi` column indicates the dissimilarity between pairs of time series.

```{r}
tsl_smol |> 
  distantia::distantia_ls() |> 
  dplyr::mutate(
    psi = round(psi, 3)
  ) |> 
  reactable::reactable(
    resizable = TRUE,
    striped = TRUE,
    compact = TRUE,
    wrap = FALSE,
    fullWidth = FALSE
  )
```
As expected, LS captures the synchronicity between Napa and Solano quite well, and returns a `psi` score indicating a high similarity. Meanwhile, San Francisco shows a high `psi` score when compared with the other two time series, indicating dissimilarity due to its asynchronous pattern. So far so good!

Now, let's take a look at the **DTW** result:

```{r}
tsl_smol |> 
  distantia::distantia_dtw() |> 
  dplyr::mutate(
    psi = round(psi, 3)
  ) |> 
  reactable::reactable(
    resizable = TRUE,
    striped = TRUE,
    compact = TRUE,
    wrap = FALSE,
    fullWidth = FALSE
  )
```

Surprising, right? When cancelling out the time shift between time series, it turns out that San Francisco is more similar to Solano than Napa!

This happens because DTW ignores the dates of the observations, and can link one sample of one time series with one or several samples of the other time series. The plot below, done with `dtw::dtw()` and `dtw::dtwPlotTwoWay()`, shows first sample of San Francisco (first case of the dashed red line), with prevalence 0, is linked to all samples with prevalence 0 at the beginning of the Napa series. Since the distance of all these links is 0, this operation cancels out the difference in timing between both time series.

```{r, fig.height=3.5, echo = FALSE}
xy_dtw <- dtw::dtw(
  x = tsl_smol$Solano$prevalence,
  y = tsl_smol$San_Francisco$prevalence,
  keep = TRUE
  )

dtw::dtwPlotTwoWay(xy_dtw, offset = 0.5)
```

These DTW results indicate that, for the given period of time, San Francisco, Napa, and Solano might be parts of the same system, in spite of the time-delay between them. This is a conclusion that cannot be achieved when applying the lock-step method!

It is for this reason that DTW is preferable when outbreak timing varies significantly and shape similarity is more important than exact time alignment. On the other hand, LS is best applied when the question at hand is focused on time-series synchronization rather than shape similarity.

```{r, echo = FALSE}
rm(tsl_smol, xy_dtw)
```


### DTW and LS with `distantia`

Now that the features of LS and DTW are clear, it is time to compute the dissimilarity between all time series. But a little word of advice first: This section shows how to work with LS and DTW for the sake of completeness. However, in a real analysis with a well-defined question, the most suitable method should be selected! 
  
The most straightforward way of computing DTW and LS in `distantia`involves the functions `distantia_ls()` and `distantia_dtw()`.

The function `distantia_ls()` computes lock-step dissimilarity using euclidean distances by default. It returns a data frame with the columns `x` and `y` with the time series names, and the `psi` score.

```{r}
df_psi_ls <- distantia::distantia_ls(
  tsl = tsl,
  distance = "euclidean"
  )

str(df_psi_ls)
```

The function `distantia_dtw()` returns an output with the same structure, but in this case the column `psi` represents dissimilarity scores computed with dynamic time warping.

```{r}
df_psi_dtw <- distantia::distantia_dtw(
  tsl = tsl
  )

str(df_psi_dtw)
```

The table below combines both results to facilitate a direct comparison.

```{r, echo = FALSE}
df_table <- df_psi_dtw |> 
  dplyr::select(x, y, psi) |> 
  dplyr::inner_join(
    y = dplyr::select(df_psi_ls, x, y, psi),
    by = c("x", "y")
  ) |> 
  dplyr::transmute(
    x, y,
    `psi_dtw` = round(psi.x, 3),
    psi_ls = round(psi.y, 3)
  )

reactable::reactable(
  df_table,
  pagination = TRUE,
  searchable = TRUE,
  sortable = TRUE,
  showSortable = TRUE,
  filterable = TRUE,
  resizable = TRUE,
  defaultPageSize = 10,
  showPageSizeOptions = TRUE,
  striped = TRUE,
  compact = TRUE,
  wrap = FALSE,
  fullWidth = FALSE
)

rm(df_table)
```

## Analyzing Dissimilarity Scores

Having a dissimilarity data frame may be kinda cool, but it won't get you very far by itself. To give you a push in the right direction, this section focuses on several analyses that can help unveil the underlying structure of the data set.

For the sake of simplicity, this section focuses on the DTW results alone. But if you wish to use the LS results instead, just replace `df_psi_dtw` with `df_psi_ls` in the code below. 

```{r}
df_psi <- df_psi_dtw
```

### Summary Stats

The functions `distantia_stats()` and `distantia_boxplot()` provide alternative summarized representations of dissimilarity (a data frame and a boxplot, respectively) via aggregation of `psi` values by time series.

```{r, fig.height=10, warning = FALSE, fig.width=5}
df_psi_stats <- distantia::distantia_stats(
  df = df_psi
)
```

```{r, echo = FALSE}
reactable::reactable(
  df_psi_stats |>  
    mutate_if(is.numeric, round, 3),
  pagination = FALSE,
  sortable = TRUE,
  showSortable = TRUE,
  filterable = TRUE,
  resizable = TRUE,
  defaultPageSize = nrow(df_psi_stats),
  showPageSizeOptions = TRUE,
  striped = TRUE,
  compact = TRUE,
  wrap = FALSE,
  fullWidth = TRUE
)
```

The boxplot generated by `distantia_boxplot()`, shown below, serves as a visual summary of the table displayed above.

```{r, fig.height=8, warning = FALSE, fig.width=5}
distantia::distantia_boxplot(
  df = df_psi,
  text_cex = 1.4
)
```

### Hierarchical Clustering

The functions `distantia_cluster_hclust()` and `distantia_cluster_kmeans()` are designed to apply hierarchical and K-means clustering to the data frames produced by `distantia_dtw()` and `distantia_ls()` right away. This section will be focusing on hierarchical clustering, which is more appropriate for the analysis of epidemiological time series.

By default, the function `distantia_cluster_hclust()` selects by itself the clustering method and the number of groups in the clustering solution via silhouette-width maximization (see [`distantia::utils_cluster_silhouette()`](https://blasbenito.github.io/distantia/reference/utils_cluster_silhouette.html) and [`distantia::utils_cluster_hclust_optimizer()`](https://blasbenito.github.io/distantia/reference/utils_cluster_hclust_optimizer.html) for further details).

```{r}
psi_cluster <- distantia::distantia_cluster_hclust(
  df = df_psi
)

names(psi_cluster)
```

The output is a list with several components, but these are the key ones:

  - `df`: data frame with time series names, cluster group, and silhouette width. 
  - `cluster_object`: the output of `stats::hclust()`.

The object `df` has the column `silhouette_width`, in the range [-1, 1], which informs about how well each case fits within its assigned cluster:

  - `<0`: misclassified.
  - `≈0`: near decision boundary.
  - `≈1`: well-clustered.
  
```{r, echo = FALSE}
reactable::reactable(
  psi_cluster$df |>  
    mutate(silhouette_width = round(silhouette_width, 3)),
  pagination = FALSE,
  sortable = TRUE,
  showSortable = TRUE,
  filterable = TRUE,
  resizable = TRUE,
  defaultPageSize = nrow(psi_cluster$df),
  showPageSizeOptions = TRUE,
  striped = TRUE,
  compact = TRUE,
  wrap = FALSE,
  fullWidth = TRUE
)
```

The hirarchical clustering highlights "Santa Cruz", with a silhouette score of `r round(psi_cluster$df$silhouette_width[which(psi_cluster$df$name == "Santa_Cruz")], 3)`, as the county with the most dubious cluster membership.

The cluster object can be plotted as a dendrogram with `factoextra::fviz_dend()`.

```{r, fig.height=10, warning = FALSE}
#number of clusters
k <- psi_cluster$clusters

factoextra::fviz_dend(
  x = psi_cluster$cluster_object, 
  k = k, 
  k_colors = distantia::color_discrete(n = k),
  cex = 1,
  label_cols = "gray20",
  rect = TRUE,  
  horiz = TRUE,
  main = "",
  ylab = "Dissimilarity"
  )
```

Mapping these groups may be helpful for the ones like me not fully acquainted with the distribution of counties in California. To get there we first need to join `psi_cluster$df` to the spatial data frame `covid_counties`.

```{r}
sf_cluster <- dplyr::inner_join(
  x = covid_counties[, "name"],
  y = psi_cluster$df,
  by = "name"
)
```

Now we can use `mapview::mapview()` again to plot cluster membership, but with a twist: we are going to code the silhouette score of each case as polygon transparency, with higher transparency indicating a lower silhouette width. This will help identify these cases that do not fully belong to their assigned groups. 

Notice that to do so, the code below applies `distantia::f_rescale_local()` to rescale silhouette width between 0.1 and 1 to adjust it to what the argument `alpha.regions` expects.

```{r, eval = FALSE, warning = FALSE}
mapview::mapview(
  sf_cluster, 
  zcol = "cluster",
  layer.name = "Cluster",
  label = "name",
  col.regions = distantia::color_discrete(n = k),
  alpha.regions = distantia::f_rescale_local(
    x = sf_cluster$silhouette_width, 
    new_min = 0.1
    )
  )
```



```{r, echo = FALSE, cache=TRUE, warning = FALSE}
clustering <- mapview::mapview(
  sf_cluster, 
  zcol = "cluster",
  layer.name = "Cluster",
  label = "name",
  col.regions = distantia::color_discrete(n = k),
  alpha.regions = distantia::f_rescale_local(
    x = sf_cluster$silhouette_width, 
    new_min = 0.1
    ),
  legend.position = "upperleft"
  )

htmlwidgets::saveWidget(
  clustering@map, 
  file = "clustering.html", 
  selfcontained = TRUE
  )

rm(max_prevalence)
```

<iframe src="clustering.html" name="Covid_clustering"
  width="600" height="600" scrolling="auto" frameborder="0">
   <p>California counties grouped by similarity in their Covid-19 prevalence curves.</p>
</iframe>


### Dissimilarity Modelling

Dissimilarity scores reveal the degree of interrelation between time series but do not explain the underlying reasons for their similarity or difference. 

To fill this gap, this shows how combining dissimilarity scores with meaningful variables to fit linear models may help unveil important drivers of dissimilarity between epidemiological time series. 

#### Model Frame

The function [`distantia_model_frame()`](https://blasbenito.github.io/distantia/reference/distantia_model_frame.html) helps combine dissimilarity scores (stored in `df_psi`) with other quantitative attributes of the time series locations (stored in `covid_counties`) to build a model frame.

```{r}
df_model <- distantia::distantia_model_frame(
  response_df = df_psi,
  predictors_df = covid_counties,
  scale = FALSE
)
```

Let's take a look at the output:

```{r, echo=FALSE}
df_model |> 
  dplyr::mutate(
    dplyr::across(
      dplyr::where(is.numeric), ~ round(.x, 2)
      )
    ) |> 
  reactable::reactable(
    pagination = TRUE,
    searchable = TRUE,
    sortable = TRUE,
    showSortable = TRUE,
    filterable = TRUE,
    resizable = TRUE,
    defaultPageSize = 10,
    showPageSizeOptions = TRUE,
    striped = TRUE,
    compact = TRUE,
    wrap = FALSE,
    fullWidth = TRUE
  )
```

In the model frame above, the response variable `psi`, from `df_psi`, represents time series dissimilarity. On the other hand, the predictors, from `covid_counties`, represent the difference in values for the given predictor between the two counties in the row. 

For example, the value of the column `area_hectares` for the counties Sacramento and Sonoma is `r df_model$area_hectares[which(df_model$x == "Sacramento" & df_model$y == "Sonoma")]` hectares. This is the absolute difference between the area of Sacramento (`r covid_counties[["area_hectares"]][which(covid_counties$name == "Sacramento")]` hectares) and the area of Sonoma (`r covid_counties[["area_hectares"]][which(covid_counties$name == "Sonoma")]` hectares).

Notice that the column `geographic_distance`, not in `covid_counties`, also appeared as a predictor. This only happens when the input of the argument `predictors_df` is an simple features data frame, as it is the case with `covid_counties`.

The function `distantia_model_frame()` has a neat feature: it can scale the predictors when they have different scales, and can combine different predictors into a new one. In the example below the distance between counties for the scaled predictors `poverty_percentage`, `median_income`, `employed_percentage`, `daily_miles_traveled` and `domestic_product` is encoded in the column `economy`, which represents the overall difference in economy indicators between counties. This aggregation of variables will help find out how geographic distance, economy, and population density (computed on the fly from `covid_counties` in the code below) drive the similarity between Covid-19 time series.

Notice that the code below also scales the predictors, because in `distantia` version <=2.0.2 the argument `scale` of `distantia_model_frame()` does not work as it should.

```{r}
df_model <- distantia::distantia_model_frame(
  response_df = df_psi,
  predictors_df = covid_counties |> 
    dplyr::mutate(
      density = population / area_hectares
    ),
  composite_predictors = list(
    economy = c(
      "poverty_percentage",
      "median_income",
      "domestic_product",
      "employed_percentage",
      "daily_miles_traveled"
    )
  ),
  #scale = TRUE is broken in version <= 2.0.2
  scale = FALSE 
  ) |> 
  #selecting and renaming columns
  dplyr::transmute(
    psi, 
    economy, 
    density,
    distance = geographic_distance
  ) |> 
  #scale
  dplyr::mutate(
    dplyr::across(
      dplyr::all_of(c("economy", "density", "distance")), 
      ~ as.numeric(scale(.x))
    )
  )
```

Notice how to simplify things a bit the code above renames `geographic_distance` to `connectivity` (arguing whether distance is a proxy of connectivity is beyond the point here), and shortened `population_density` to `density`.

```{r, echo=FALSE}
df_model |> 
  dplyr::mutate(
    dplyr::across(
      dplyr::where(is.numeric), ~ round(.x, 2)
      )
    ) |> 
  reactable::reactable(
    pagination = TRUE,
    searchable = TRUE,
    sortable = TRUE,
    showSortable = TRUE,
    filterable = TRUE,
    resizable = TRUE,
    defaultPageSize = 10,
    showPageSizeOptions = TRUE,
    striped = TRUE,
    compact = TRUE,
    wrap = FALSE,
    fullWidth = TRUE
  )
```


#### Model Fitting

The model frame generated above shows no multicollinearity between predictors, so it can be used right away fit a multiple regression model.

```{r}
m <- stats::lm(
  formula = psi ~ distance + economy + density,
  data = df_model
)
```

```{r, echo = FALSE}
m |> 
  summary() |> 
  broom::tidy() |> 
  dplyr::mutate(dplyr::across(dplyr::where(is.numeric), ~ round(.x, 4))) |> 
  dplyr::arrange(dplyr::desc(estimate)) |> 
  dplyr::filter(term != "(Intercept)") |> 
  reactable(
    striped = TRUE,
    fullWidth = TRUE,
    resizable = TRUE,
    sortable = TRUE,
    showSortable = TRUE
    )
```

The coefficients table shows that `distance` has a slightly larger effect than `economy`, and both have a positive effect on time series dissimilarity. On the other hand, `density` has a weaker and negative effect.


```{r, fig.height=3, fig.width=8}
par(mfrow = c(1, 3))
line_params <- list(col = "red4", lwd = 1)
visreg::visreg(
  fit = m,
  xvar = "distance",
  line = line_params
)
visreg::visreg(
  fit = m,
  xvar = "economy",
  line = line_params
)
visreg::visreg(
  fit = m,
  xvar = "density",
  line = line_params
)
```

The effect plots above paint a clear picture: counties that are closer and have similar economies are more similar than counties that are far apart or have economies of different magnitudes. However, the interpretation of the variable `density` may remain dubious due to a signal that may be mostly driven by outliers.

## Time-Delay Analysis

```{r}
df_delay <- distantia::distantia_time_delay(
  tsl = tsl,
  bandwidth = 0.125
)
```

```{r}
reactable::reactable(
  df_delay,
  pagination = TRUE,
  searchable = TRUE,
  sortable = TRUE,
  showSortable = TRUE,
  filterable = TRUE,
  resizable = TRUE,
  defaultPageSize = 10,
  showPageSizeOptions = TRUE,
  striped = TRUE,
  compact = TRUE,
  wrap = FALSE,
  fullWidth = FALSE
)
```

```{r}
distantia::distantia_dtw_plot(
  tsl = tsl[c("Napa", "San_Francisco")],
  bandwidth = 0.125
)
```

```{r}
distantia::tsl_plot(
  tsl = tsl[c("San_Francisco", "Napa")],
  xlim = c("2021-07-01", "2022-01-10")
)
```

```{r}
sf_delay <- distantia::distantia_spatial(
  df = df_delay,
  sf = covid_counties
)
```


```{r}
mapview(sf_delay |> dplyr::filter(x == "Napa", y == "San_Francisco"))
```

