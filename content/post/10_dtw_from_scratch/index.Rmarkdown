---
title: "Coding a Minimalistic Dynamic Time Warping Library with R"
author: ''
date: '2025-01-13'
slug: dynamic-time-warping-from-scratch
categories: []
tags: [Rstats]
subtitle: ''
summary: 'Tutorial on how to implement dynamic time warping in R'
authors: [admin]
lastmod: '2025-01-13T05:14:20+01:00'
featured: yes
draft: true
image:
  caption: Dynamic time warping represented as a landscape.
  focal_point: Smart
  margin: auto
projects: []
---

```{r, echo = FALSE, eval = FALSE}
install.packages("distantia")
```


# Summary

Dynamic Time Warping is a powerful method to compare univariate or multivariate time series by shape I explained in [previous post](https://www.blasbenito.com/post/dynamic-time-warping/). The objective of this post is to explain how DTW work by implementing a minimalistic yet fully functional dynamic time warping library with R. The tutorial focuses on code simplicity, and as such, it does not require any particular any particular level of competence in R.

# Design

## Example Data

Having good example data at hand is a must when developing new code. For this tutorial we use a subset of three multivariate time series of temperature, rainfall, and normalized vegetation index available in the R package [distantia](https://blasbenito.github.io/distantia/).

```{r, fig.height=3.5, fig.width=5, echo = FALSE, message=FALSE}
library(distantia, quietly = TRUE)
library(zoo, quietly = TRUE)

tsl <- tsl_initialize(
  x = fagus_dynamics,
  name_column = "name",
  time_column = "time"
) |> 
  tsl_subset(
    time = c("2010-01-01", "2011-01-01")
  ) |> 
  tsl_colnames_set(
    names = c("evi", "rain", "temp")
  )

tsl_plot(tsl)
```

To facilitate our development, each time series is stored in an object of the class [zoo](https://CRAN.R-project.org/package=zoo), which is probably the most flexible time series management library in the R ecosystem.

```{r}
zoo_sweden <- tsl$Sweden
zoo_spain <- tsl$Spain
zoo_germany <- tsl$Germany

class(zoo_sweden)
```

Each zoo object has a *core data* of the class "matrix" with one observation per row and one variable per column, and an *index*, which is a vector of dates, one per row in the data matrix.

```{r}
zoo::coredata(zoo_sweden)
```

```{r}
class(zoo::coredata(zoo_sweden))
```

```{r}
zoo::index(zoo_sweden)
```

## Required Functions

The section *DTW Step by Step* from the previous article [A Gentle Intro to Dynamic Time Warping](https://www.blasbenito.com/post/dynamic-time-warping/) shows the steps required to compute DTW. Below, these steps are broken down in sub-steps that will correspond to specific functionalities in our library:

**Pre-processing steps** 

These steps help DTW work as best as possible with the input data.

  - **Linear detrending**: forces time series to be stationary by removing any upwards or downwards trends. 
  - **Z-score normalization**: facilitates distance computation between samples multivariate time series and limits potential alignment issues in DTW.

**DTW steps**

Steps to perform DTW proper and evaluate the similarity between time series.

  - **Multivariate distance**: evaluate the distance between samples of each time series.
  - **Distance matrix**: organize the multivariate distances in a matrix.
  - **Cost matrix**: dynamic programming algorithm to accumulate distance across time.
  - **Least-cost path**: algorithm to find the path across the cost matrix that maximizes the alignment between both time series.
  - **Dissimilarity metric**: computation of a number to summarize the similarity/dissimilarity between time series.
  
**Main function**

Once all the steps above are implemented in their respective functions, we will wrap all them in a single function to streamline the DTW analysis.
  
# Implementation

In this section we will be developing the library function by function. Remember that the content of each code chunk should be added to the file `mini_dtw.R`.
    
### Linear Detrending

Applying linear detrending to a time series involves computing a linear model of each variable against time, and subtracting the result of the model prediction to the original data. This operation can be done in just two steps for a zoo object. 

First, the function `stats::lm()` can be applied to all variables in our time series at once

```{r}
model_sweden <- stats::lm(
  formula = zoo_sweden ~ stats::time(zoo_sweden)
  )

model_sweden
```

Second, the residuals of the linear model represent the differences between the prediction and the observed data, which corresponds exactly with the detrended time series. As a plus, these residuals are returned as a zoo object.

```{r, fig.width=5, fig.height=3.5}
zoo_sweden_detrended <- stats::residuals(model_sweden)
zoo_sweden_detrended

plot(
  x = zoo_sweden_detrended, 
  col = "red4",
  mar = c(0.5, 5, 0, 5)
  )
```

Then, the first function of our library could be something like this:

```{r}
#' Linear Detrending
#' @param x (required, zoo object) time series to detrend.
#' @return zoo object
ts_detrend <- function(x){
  m <- stats::lm(formula = x ~ stats::time(x))
  y <- stats::residuals(object = m)
  y
}
```

Notice that it could be more concise, but it is written to facilitate line-by-line debugging instead. I have also added minimal roxygen documentation. Future me usually appreciates this kind of extra effort.

We can now test the new function!

```{r, fig.height=3, fig.width=5}
zoo_spain_detrended <- ts_detrend(x = zoo_spain)

plot(
  x = zoo_spain_detrended, 
  col = "red4",
  mar = c(0.5, 5, 0, 5)
  )
```

The effect of our new function is not very noticeable because none of our time series have long-term trends, but let's try something different to check that our function actually detrends time series.

The code below creates a mock-up time series with an ascending trend.

```{r, fig.height=3, fig.width=5}
x <- zoo::zoo(0:10)

plot(
  x = x, 
  col = "red4",
  mar = c(0.5, 1, 0, 1)
  )
```

The detrending operation results in a horizontal line! Now we can be sure our detrending function works as expected.

```{r}
x_detrended <- ts_detrend(x = x)

plot(
  x = x_detrended, 
  col = "red4",
  ylim = range(x),
  mar = c(0.5, 5, 0, 5)
  )
```


### Z-score Normalization

The function `scale()`, from base R, already implements z-score normalization. When the library `zoo` is loaded, the method `zoo:::scale.zoo` (`:::` denotes unexported methods and functions) allows `scale()` to work seamlessly with zoo objects.

```{r}
zoo_spain_scaled <- scale(
  x = zoo_spain,
  center = TRUE,
  scale = TRUE
  )

zoo_spain_scaled
```

```{r}
class(zoo_spain_scaled)
```

Centering is performed by subtracting the column mean to each case, and results in a column mean equal to zero. Scaling divides each case by the standard deviation of the column, resulting in an overall standard deviation across cases equal to one.

This normalization step does not require a function in our library, but we can add it to our function `ts_detrend()` to encapsulate all pre-processing steps into a new function named `ts_preprocessing()`.

```{r}
#' Linear Detrending and Normalization
#' @param x (required, zoo object) time series to detrend.
#' @return zoo object
ts_preprocessing <- function(x){
  m <- stats::lm(formula = x ~ stats::time(x))
  y <- stats::residuals(object = m)
  y.scaled <- scale(x = y)
  y.scaled
}
```

Once we replace the old function with the new one, we can source the library and test it.

```{r, fig.height=3, fig.width=5}
source("mini_dtw.R")

zoo_spain_ready <- ts_preprocessing(x = zoo_spain)

plot(
  x = zoo_spain_ready, 
  col = "red4",
  mar = c(0.5, 5, 0, 5)
  )
```

### Distance Matrix

The computation of a distance matrix first requires a function to compute the multivariate distance between two arbitrary rows of separate zoo objects with the same number of columns.

#### Distance Function

The expression to compute Euclidean distances between two vectors `x` and `y` representing the rows of zoo objects is `sqrt(sum((x-y)^2))`. The function below implements this expression:

```{r}
#' Euclidean Distance
#' @param x (required, numeric) row of a zoo object.  
#' @param y (required, numeric) row of a zoo object.
#' @return numeric
d_euclidean <- function(x, y){
  d <- sqrt(sum((x-y)^2))
  d
}
```

Implementing such a simple expression in a function is not a must, but it may facilitate the addition of new distance metrics to the library in the future.

We can test it right away, and let's ignore for now that none of our zoo objects are normalized yet.

```{r}
d_euclidean(
  x = zoo::coredata(zoo_germany)[1, ],
  y = zoo::coredata(zoo_spain)[2, ]
)
```

Notice that I am using `zoo::coredata()` to extract the individual rows of each zoo object. Without this step, goofy things happen:

```{r}
d_euclidean(
  x = zoo_germany[1, ],
  y = zoo_spain[2, ]
)
```

We can also solve this quirk by using `as.numeric()` instead of `zoo::coredata()`:

```{r}
d_euclidean(
  x = as.numeric(zoo_germany[1, ]),
  y = as.numeric(zoo_spain[2, ])
)
```

Then, moving these `as.numeric()` inside `d_euclidean()` will be helpful to simplify the usage of the function:

```{r}
#' Euclidean Distance
#' @param x (required, numeric) row of a zoo object.  
#' @param y (required, numeric) row of a zoo object.
#' @return numeric
d_euclidean <- function(x, y){
  x <- as.numeric(x)
  y <- as.numeric(y)
  d <- sqrt(sum((x-y)^2))
  d
}

d_euclidean(
  x = zoo_germany[1, ],
  y = zoo_spain[2, ]
)
```

#### Distance Matrix

To generate the distance matrix, the new function must be applied to all pairs of rows in two zoo objects. A simple yet inefficient way to do this involves creating an empty matrix, and traversing it cell by cell to compute the euclidean distances between the corresponding pair of time series rows.

```{r}
m_dist <- matrix(
  data = NA, 
  nrow = nrow(zoo_spain), 
  ncol = nrow(zoo_germany)
)

for(row.i in 1:nrow(zoo_spain)){
  for(col.j in 1:nrow(zoo_germany)){
    
    m_dist[row.i, col.j] <- d_euclidean(
      x = zoo_spain[row.i, ],
      y = zoo_germany[col.j, ]
    )
    
  }
}
```

This code generates a matrix in which the samples of `zoo_spain` are represented in the matrix rows from top to bottom, while `zoo_germany` is represented in the columns, from left to right.

```{r}
m_dist[1:5, 1:5]
```

Now we can plot this distance matrix, but notice that the function `graphics::image()` rotates the distance matrix 90 degrees counter clock-wise before plotting, which can be pretty confusing at first.

```{r, fig.width=2.5, fig.height=2.5}
par(mar = c(4, 4, 1, 1))
graphics::image(
  x = m_dist,
  xlab = "zoo_spain",
  ylab = "zoo_germany"
  )
```

Now first column in the plot represents the first row of our original matrix `m_dist`, so now `zoo_spain` is represented in the plot columns, and `zoo_germany` in the rows.

We can now wrap the code above (without the plot) in a new function named `distance_matrix()`.

```{r}
#' Distance Matrix Between Time Series
#' @param x (required, zoo object) time series.
#' @param y (required, zoo object) time series with same columns as `x`
#' @return matrix
distance_matrix <- function(x, y){
  
  m_dist <- matrix(
    data = NA, 
    nrow = nrow(y), 
    ncol = nrow(x)
  )
  
  for(row.i in 1:nrow(y)){
    for(col.j in 1:nrow(x)){
      
      m_dist[row.i, col.j] <- d_euclidean(
        x = x[row.i, ],
        y = y[col.j, ]
      )
      
    }
  }
  
  m_dist
  
}
```

Let's run a little test before moving forward!

```{r, fig.width=2.5, fig.height=2.5}
m_dist <- distance_matrix(
  x = zoo_spain,
  y = zoo_sweden
)

par(mar = c(4, 4, 1, 1))
graphics::image(
  x = m_dist,
  xlab = "zoo_sweden",
  ylab = "zoo_spain"
  )
```

Darker values in the plot above indicate larger distances between time series samples.

### Cost Matrix

Now we are getting into the important parts of the DTW algorithm! 

A cost matrix is like a valley's landscape with hills in regions where the time series are very different, and ravines where they are more similar.

Such landscape is built by accumulating the values of the distance matrix cell by cell from [1, 1] at the bottom of the valley to [m, n] at the top.

Let's see how that works:

First, we use the dimensions of the distance matrix to create an empty cost matrix.

```{r, fig.width=2.5, fig.height=2.5, warning = FALSE}
m_cost <- matrix(
  data = NA, 
  nrow = nrow(m_dist), 
  ncol = ncol(m_dist)
  )
```

Second, to initialize the cost matrix we accumulate the values of first row and column of the distance matrix using `cumsum()`:

```{r}
m_cost[1, ] <- cumsum(m_dist[1, ])
m_cost[, 1] <- cumsum(m_dist[, 1])
```

This step is very important for the second part of the algorithm, as it provides the starting values.

```{r, fig.width=2.5, fig.height=2.5}
par(mar = c(4, 4, 1, 1))
graphics::image(
  x = m_cost,
  xlab = "zoo_sweden",
  ylab = "zoo_spain"
  )
```

As before, darker values in the plot above indicate larger cumulative distances.

Now, before going into the third step, let's focus for a moment on the next cell of the cost matrix we need to fill. This cell, with coordinates `m_cost[2, 2]`, shown with value `NA` below.

```{r}
m_cost[1:2, 1:2]
```

The new value of this cell must be the sum of its value in the distance matrix `m_dist`, which is `r m_dist[2, 2]`, with the minimum accumulated distance of its neighbors, which are `m_cost[1, 2]`, with value `r m_cost[1, 2]`, and `m_cost[2, 1]`, with value `r m_cost[2, 1]`. 

In summary, we have two alternative steps: sum the distance in the empty cell with the cost of the upper neighbor, or with the left one, and we have to choose the one that minimizes the value of the result.

This conundrum is easily solved with the expression below, which uses `min()` to get the value of the *smallest* neighbor, and then adds it to the target cell

```{r}
m_cost[2, 2] <- min(
  m_cost[1, 2], 
  m_cost[2, 1]
  ) + m_dist[2, 2]

m_cost[1:2, 1:2]
```

But there are many cells to fill yet!

```{r, fig.width=2.5, fig.height=2.5}
par(mar = c(4, 4, 1, 1))
graphics::image(
  x = m_cost,
  xlab = "zoo_sweden",
  ylab = "zoo_spain"
  )
```

The expression we used to fill the cell `m_cost[2, 2]` can be generalized to fill all empty cells. We just have to wrap it in a nested loop that for each new empty cell identifies the smallest neighbor and adds its cost to the distance of new cell.

```{r}
#iterate over rows of the cost matrix
for(row.i in 2:nrow(m_dist)){
  
  #iterate over columns of the cost matrix
  for(col.j in 2:ncol(m_dist)){
    
    #get cost of neighbor with minimum accumulated cost
    min_cost <- min(
      m_cost[row.i - 1, col.j], 
      m_cost[row.i, col.j - 1]
      )
    
    #add it to the distance of the target cell
    new_value <- min_cost + m_dist[row.i, col.j]
    
    #fill the empty cell with the new value
    m_cost[row.i, col.j] <- new_value
    
  }
}
```

Running the code above results in a nicely filled cost matrix!

```{r, fig.width=2.5, fig.height=2.5}
par(mar = c(4, 4, 1, 1))
graphics::image(
  x = m_cost,
  xlab = "zoo_sweden",
  ylab = "zoo_spain"
  )
```

Now that we have all the pieces together, we can define our new function to compute the cost matrix. Notice that the code within the nested loops is slightly more concise.

```{r}
#' Cost Matrix from Distance Matrix
#' @param m (required, matrix) distance matrix.
#' @return matrix
cost_matrix <- function(m){
  
  m_cost <- matrix(
    data = NA, 
    nrow = nrow(m), 
    ncol = ncol(m)
  )
  
  m_cost[1, ] <- cumsum(m[1, ])
  m_cost[, 1] <- cumsum(m[, 1])
  
  for(row.i in 2:nrow(m)){
    for(col.j in 2:ncol(m)){
      
      m_cost[row.i, col.j] <- min(
        m_cost[row.i - 1, col.j], 
        m_cost[row.i, col.j - 1]
      ) + m[row.i, col.j]
      
    }
  }
  
  m_cost
  
}
```

Let's test our new function using `m_dist` as input!

```{r, fig.width=2.5, fig.height=2.5}
m_cost <- cost_matrix(m = m_dist)

par(mar = c(4, 4, 1, 1))
graphics::image(
  x = m_cost,
  xlab = "zoo_sweden",
  ylab = "zoo_spain"
  )
```

Yay, so far so good! 

We can now move onto the last step of the DTW algorithm.

### Least-Cost Path

If we describe the least-cost matrix as a valley with its hills and ravines, then the least-cost path is a river flowing its way to the bottom. Like a river, the least-cost path finds the easiest way to cross the cost matrix from the last cell [m, n] to [1, 1].

Following the analogy, leas-cost paths are built in a direction opposed to the one used to build the cost matrix.

```{r}
dist_matrix <- m_dist
cost_matrix <- m_cost
```


```{r}
DataFrame cost_path_orthogonal_cpp(
    NumericMatrix dist_matrix,
    NumericMatrix cost_matrix
){

  int d_rows = dist_matrix.nrow();
  int d_cols = dist_matrix.ncol();

  // Initialize the path vectors
  std::vector<int> path_x;
  std::vector<int> path_y;
  std::vector<double> path_dist;
  std::vector<double> path_cost;

  // Define initial coordinates
  int x = d_cols - 1;
  int y = d_rows - 1;


  // Iterate to find the path
  while (true) {

    // Add current coordinates to the path
    // Adding 1 to convert from 0-based index to 1-based index
    path_x.push_back(x + 1);
    path_y.push_back(y + 1);
    path_dist.push_back(dist_matrix(y, x));
    path_cost.push_back(cost_matrix(y, x));

    // declare neighbors
    std::vector<int> neighbor_x = {x, x - 1};
    std::vector<int> neighbor_y = {y - 1, y};

    // Find neighbor with minimum cost
    int min_cost_neighbor = -1;
    double min_cost = std::numeric_limits<double>::max();

    for (int j = 0; j < 2; ++j) {
      if (neighbor_y[j] != -1 && neighbor_x[j] != -1) {
        if (cost_matrix(neighbor_y[j], neighbor_x[j]) < min_cost) {
          min_cost = cost_matrix(neighbor_y[j], neighbor_x[j]);
          min_cost_neighbor = j;
        }
      }
    }

    // Check for termination
    if (min_cost_neighbor == -1) {
      break;
    }

    // Update current coordinates
    x = neighbor_x[min_cost_neighbor];
    y = neighbor_y[min_cost_neighbor];

  }

  // Create output data frame
  return DataFrame::create(
    _["x"] = path_x,
    _["y"] = path_y,
    _["dist"] = path_dist,
    _["cost"] = path_cost
  );

}
```

```{r}
path <- cost_path(
  dist_matrix = m_dist,
  cost_matrix = m_cost
)
```


### Dissimilarity Metric



## Library Source

Our library will *live* in a file named `mini_dtw.R`. We will be adding new R functions to this file as we progress with the implementation. Remember typing `source("mini_dtw.R")` everytime you add new code to this file to make the functions available in your R environment!
