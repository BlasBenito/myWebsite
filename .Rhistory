parallel::stopCluster(cl = my.cluster)
#plotting result
ggplot2::ggplot(data = importance.scores) +
ggplot2::aes(
y = reorder(variable, importance),
x = importance
) +
ggplot2::geom_boxplot() +
ggplot2::ylab("")
rm(importance.scores)
#create and register cluster
my.cluster <- parallel::makeCluster(n.cores)
doParallel::registerDoParallel(cl = my.cluster)
#exporting data and functions
parallel::clusterExport(
cl = my.cluster,
varlist = c(
'penguins',
'importance_to_df'
),
envir = environment()
)
system.time(
#performing 1000 iterations in parallel
importance.scores <- foreach(
i = 1:1000,
.combine = 'rbind',
.packages = "ranger"
) %dopar% {
#fit model
m.i <- ranger::ranger(
data = penguins,
dependent.variable.name = "species",
importance = "permutation",
seed = i
)
#format importance
m.importance.i <- importance_to_df(model = m.i)
#returning output
return(m.importance.i)
}
)
#stopping cluster
parallel::stopCluster(cl = my.cluster)
#plotting result
ggplot2::ggplot(data = importance.scores) +
ggplot2::aes(
y = reorder(variable, importance),
x = importance
) +
ggplot2::geom_boxplot() +
ggplot2::ylab("")
#create and register cluster
my.cluster <- parallel::makeCluster(n.cores)
doParallel::registerDoParallel(cl = my.cluster)
#exporting data and functions
parallel::clusterExport(
cl = my.cluster,
varlist = c(
'penguins',
'importance_to_df'
),
envir = environment()
)
system.time(
#performing 1000 iterations in parallel
importance.scores <- foreach(
i = 1:1000,
.combine = 'rbind',
.packages = "ranger"
) %dopar% {
#fit model
m.i <- ranger::ranger(
data = penguins,
dependent.variable.name = "species",
importance = "permutation",
seed = i
)
#format importance
m.importance.i <- importance_to_df(model = m.i)
#returning output
return(m.importance.i)
}
)
#stopping cluster
parallel::stopCluster(cl = my.cluster)
#performing 1000 iterations sequentially
system.time(
importance.scores <- foreach(
i = 1:1000,
.combine = 'rbind',
.packages = "ranger"
) %do% {
#fit model
m.i <- ranger::ranger(
data = penguins,
dependent.variable.name = "species",
importance = "permutation",
seed = i,
num.threads = parallel::detectCores() - 1
)
#format importance
m.importance.i <- importance_to_df(model = m.i)
#returning output
return(m.importance.i)
}
)
#list to save results
importance.scores.list <- list()
#performing 1000 iterations sequentially
system.time(
for(i in 1:1000){
#fit model
m.i <- ranger::ranger(
data = penguins,
dependent.variable.name = "species",
importance = "permutation",
seed = i,
num.threads = parallel::detectCores() - 1
)
#format importance
importance.scores.list[[i]] <- importance_to_df(model = m.i)
}
)
blogdown::serve_site()
blogdown::stop_server()
#create and register cluster
my.cluster <- parallel::makeCluster(n.cores, type = "FORK")
doParallel::registerDoParallel(cl = my.cluster)
#exporting data and functions
parallel::clusterExport(
cl = my.cluster,
varlist = c(
'penguins',
'importance_to_df'
),
envir = environment()
)
system.time(
#performing 1000 iterations in parallel
importance.scores <- foreach(
i = 1:1000,
.combine = 'rbind',
.packages = "ranger"
) %dopar% {
#fit model
m.i <- ranger::ranger(
data = penguins,
dependent.variable.name = "species",
importance = "permutation",
seed = i
)
#format importance
m.importance.i <- importance_to_df(model = m.i)
#returning output
return(m.importance.i)
}
)
#stopping cluster
parallel::stopCluster(cl = my.cluster)
#create and register cluster
my.cluster <- parallel::makeCluster(n.cores)
doParallel::registerDoParallel(cl = my.cluster)
#exporting data and functions
parallel::clusterExport(
cl = my.cluster,
varlist = c(
'penguins',
'importance_to_df'
),
envir = environment()
)
system.time(
#performing 1000 iterations in parallel
importance.scores <- foreach(
i = 1:1000,
.combine = 'rbind',
.packages = "ranger"
) %dopar% {
#fit model
m.i <- ranger::ranger(
data = penguins,
dependent.variable.name = "species",
importance = "permutation",
seed = i
)
#format importance
m.importance.i <- importance_to_df(model = m.i)
#returning output
return(m.importance.i)
}
)
#stopping cluster
parallel::stopCluster(cl = my.cluster)
blogdown::serve_site()
blogdown::stop_server()
#create and register cluster
my.cluster <- parallel::makeCluster(n.cores)
doParallel::registerDoParallel(cl = my.cluster)
#exporting data and functions
# parallel::clusterExport(
#   cl = my.cluster,
#   varlist = c(
#     'penguins',
#     'importance_to_df'
#   ),
#   envir = environment()
# )
#assessing execution time
system.time(
#performing 1000 iterations in parallel
importance.scores <- foreach(
i = 1:1000,
.combine = 'rbind',
.packages = "ranger",
.export = c('penguins', 'importance_to_df')
) %dopar% {
#fit model
m.i <- ranger::ranger(
data = penguins,
dependent.variable.name = "species",
importance = "permutation",
seed = i
)
#format importance
m.importance.i <- importance_to_df(model = m.i)
#returning output
return(m.importance.i)
}
)
#stopping cluster
parallel::stopCluster(cl = my.cluster)
#automatic install of packages if they are not readily available
list.of.packages <- c(
"foreach",
"doParallel",
"ranger",
"palmerpenguins",
"ggplot2"
)
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
#installing missing packages
if(length(new.packages) > 0){
install.packages(new.packages, dep=TRUE)
}
#loading packages
for(package.i in list.of.packages){
suppressPackageStartupMessages(library(package.i, character.only = TRUE))
}
#loading example data
data("penguins")
x <- vector()
for(i in 1:10){x[i] <- sqrt(i)}
x
x <- foreach(i = 1:10) %do% {sqrt(i)}
x
x <- foreach(i = 1:10, .combine = 'c') %do% {sqrt(i)}
x
x <- foreach(i = 1:3, j = 1:3, k = 1:3, .combine = 'c') %do% {
i + j + k
}
x
x <- foreach(i = 1:10, .combine = 'c') %dopar% {sqrt(i)}
x
library(parallel)
library(doParallel)
parallel::detectCores()
n.cores <- parallel::detectCores() - 1
#create the cluster
my.cluster <- parallel::makeCluster(n.cores, type = "PSOCK")
#check cluster definition (optional)
print(my.cluster)
#register it to be used by %dopar%
doParallel::registerDoParallel(cl = my.cluster)
#check if it is registered (optional)
foreach::getDoParRegistered()
#how many workers are available? (optional)
foreach::getDoParWorkers()
x <- foreach(i = 1:10, .combine = 'c') %dopar% {sqrt(i)}
x
parallel::stopCluster(cl = my.cluster)
#define port
Sys.setenv(R_PARALLEL_PORT = 11000)
#check that it worked as intended
Sys.getenv("R_PARALLEL_PORT")
#function to generate cluster specifications from a vector of IPs, a vector with the number of cores to use on each IP, and a user name
cluster_spec <- function(
ips,
cores,
user
){
#creating initial list
spec <- list()
for(i in 1:length(ips)){
spec[[i]] <- list()
spec[[i]]$host <- ips[i]
spec[[i]]$user <- user
spec[[i]]$ncore <- cores[i]
}
#generating nodes from the list of machines
spec <- lapply(
spec,
function(spec.i) rep(
list(
list(
host = spec.i$host,
user = spec.i$user)
),
spec.i$ncore
)
)
#formating into a list of lists
spec <- unlist(
spec,
recursive = FALSE
)
return(spec)
}
#generate cluster specification
spec <- cluster_spec(
ips = c('10.42.0.1', '10.42.0.34', '10.42.0.104'),
cores = c(7, 4, 4),
user = "blas"
)
#setting up cluster
my.cluster <- parallel::makeCluster(
master = '10.42.0.1',
spec = spec,
port = Sys.getenv("R_PARALLEL_PORT"),
outfile = "",
homogeneous = TRUE
)
#check cluster definition (optional)
print(my.cluster)
#register cluster
doParallel::registerDoParallel(cl = my.cluster)
#how many workers are available? (optional)
foreach::getDoParWorkers()
x <- foreach(i = 1:20, .combine = 'c') %dopar% {sqrt(i)}
x
parallel::stopCluster(cl = my.cluster)
penguins <- as.data.frame(
na.omit(
penguins[, c(
"species",
"bill_length_mm",
"bill_depth_mm",
"flipper_length_mm",
"body_mass_g"
)]
)
)
kableExtra::kable(head(penguins))
importance_to_df <- function(model){
x <- as.data.frame(model$variable.importance)
x$variable <- rownames(x)
colnames(x)[1] <- "importance"
rownames(x) <- NULL
return(x)
}
#create and register cluster
my.cluster <- parallel::makeCluster(n.cores)
doParallel::registerDoParallel(cl = my.cluster)
#assessing execution time
system.time(
#performing 1000 iterations in parallel
importance.scores <- foreach(
i = 1:1000,
.combine = 'rbind',
.packages = "ranger",
.export = c('penguins', 'importance_to_df')
) %dopar% {
#fit model
m.i <- ranger::ranger(
data = penguins,
dependent.variable.name = "species",
importance = "permutation",
seed = i
)
#format importance
m.importance.i <- importance_to_df(model = m.i)
#returning output
return(m.importance.i)
}
)
#stopping cluster
parallel::stopCluster(cl = my.cluster)
#create and register cluster
my.cluster <- parallel::makeCluster(n.cores)
doParallel::registerDoParallel(cl = my.cluster)
#assessing execution time
system.time(
#performing 1000 iterations in parallel
importance.scores <- foreach(
i = 1:1000,
.combine = 'rbind',
.packages = "ranger",
.export = c('penguins', 'importance_to_df')
) %dopar% {
#fit model
m.i <- ranger::ranger(
data = penguins,
dependent.variable.name = "species",
importance = "permutation",
seed = i
)
#format importance
m.importance.i <- importance_to_df(model = m.i)
#returning output
return(m.importance.i)
}
)
#stopping cluster
parallel::stopCluster(cl = my.cluster)
#create and register cluster
my.cluster <- parallel::makeCluster(n.cores)
doParallel::registerDoParallel(cl = my.cluster)
#assessing execution time
system.time(
#performing 1000 iterations in parallel
importance.scores <- foreach(
i = 1:1000,
.combine = 'rbind',
.packages = "ranger"
) %dopar% {
#fit model
m.i <- ranger::ranger(
data = penguins,
dependent.variable.name = "species",
importance = "permutation",
seed = i
)
#format importance
m.importance.i <- importance_to_df(model = m.i)
#returning output
return(m.importance.i)
}
)
#stopping cluster
parallel::stopCluster(cl = my.cluster)
#create and register cluster
my.cluster <- parallel::makeCluster(n.cores)
doParallel::registerDoParallel(cl = my.cluster)
#assessing execution time
system.time(
#performing 1000 iterations in parallel
importance.scores <- foreach(
i = 1:1000,
.combine = 'rbind',
.packages = "ranger"
) %dopar% {
#fit model
m.i <- ranger::ranger(
data = penguins,
dependent.variable.name = "species",
importance = "permutation",
seed = i
)
#format importance
m.importance.i <- importance_to_df(model = m.i)
#returning output
return(m.importance.i)
}
)
#stopping cluster
parallel::stopCluster(cl = my.cluster)
ggplot2::ggplot(data = importance.scores) +
ggplot2::aes(
y = reorder(variable, importance),
x = importance
) +
ggplot2::geom_boxplot() +
ggplot2::ylab("")
#list to save results
importance.scores.list <- list()
#performing 1000 iterations sequentially
system.time(
for(i in 1:1000){
#fit model
m.i <- ranger::ranger(
data = penguins,
dependent.variable.name = "species",
importance = "permutation",
seed = i,
num.threads = parallel::detectCores() - 1
)
#format importance
importance.scores.list[[i]] <- importance_to_df(model = m.i)
}
)
#removing NA and subsetting columns
penguins <- as.data.frame(
na.omit(
penguins[, c(
"species",
"bill_length_mm",
"bill_depth_mm",
"flipper_length_mm",
"body_mass_g"
)]
)
)
kableExtra::kable(head(penguins, 10))
blogdown::serve_site()
ggplot2::ggplot(data = importance.scores) +
ggplot2::aes(
y = reorder(variable, importance),
x = importance
) +
ggplot2::geom_boxplot() +
ggplot2::ylab("")
ggsave(filename = "/home/blas/Dropbox/GITHUB/myWebsite/content/post/02_parallelizing_loops_with_r/boxplot.png", width = 5, height = 3)
